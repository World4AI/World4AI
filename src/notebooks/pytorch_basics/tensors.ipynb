{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5af35d8-f9e2-4c9e-8340-c832cc228c03",
   "metadata": {},
   "source": [
    "# PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb68d67a-8856-4927-a8fd-635bc81a411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad74f2-2d00-4fd5-823a-0da514aa1f9b",
   "metadata": {},
   "source": [
    "All of modern deep learning works with matrices. According to the PyTorch documentation, `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type. This class is at the core of PyTorch and is going to be used throughout all future tutorial series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7816a-5bcc-40b3-8555-8aa08c9c9b62",
   "metadata": {},
   "source": [
    "Tensors can live an the `cpu` or the `gpu`. To move a tensor to the gpu, we need to have an Nvidia graphics card. We can test if we have a valid graphics card, by running `torch.cuda.is_available()`. If the method returns `True` we move our calculations to the graphics card to speed up calculations. \n",
    "\n",
    "Often we want to save the result of `torch.cuda.is_available()` using a `torch.device` object. Later we can reuse that object to automatically move the calculations to the correct device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36cd6cf-52e5-45ba-9499-7b8adeb0ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda:0 represents the first nvidia device\n",
    "# theoretically you could have several graphics cars\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c1105-1156-49bf-9162-83983291d842",
   "metadata": {},
   "source": [
    "We are dealing with a system that utilizes an nvidia graphics card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5137baa9-3478-4e6c-aa7d-5b7613eac4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec49b1-c5ad-49a1-b607-26fd23312a13",
   "metadata": {},
   "source": [
    "If you want to find out if you have an Nvidia graphics card from the terminal, you can run the command `nvidia-smi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d2e99f-fc4c-4e7d-9db8-087796e7cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 25 14:54:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   54C    P8    10W /  N/A |    851MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2223      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A     13762      C   ...a3/envs/dlbook/bin/python      843MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fbcfaa-c841-4d4f-8f74-44b9650de759",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07f2b3d-75fb-4f50-9426-81f8c7aed8bf",
   "metadata": {},
   "source": [
    "The method `torch.tensor()` is the most straightforward way to create a tensor. \n",
    "\n",
    "The method has some interesting arguments, that allow us to control the properties of the tensor: `torch.tensor(data, dtype=None, device=None, requires_grad=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e41177b-825d-4015-a51c-f741a48748d6",
   "metadata": {},
   "source": [
    "The `data` argument is the input that is transformed into a tensor. Usually it is an arraylike structure: list, tuple, NumPy ndarray. If for example we use `torch.tensor(data=[[0,1,2], [3,4,5]])` we would create a two dimensional matrix with 2 rows and 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045095be-996c-4168-9c6f-42b7932fbdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[0, 1, 2], [3, 4, 5]])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e0f13-f89a-4605-89ae-8ea3c64a8715",
   "metadata": {},
   "source": [
    "The `dtype` argument determines the type of the tensor. See [PyTorch Docs](https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype) for a full list of available data types. If we do not specify the type explicitly, `dtype` is going to be `torch.int64`, if all of inputs are integers and `dtype` is going to be `torch.float32` if even one of the inputs is a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e184c332-2794-4547-a8a8-e9d7d2cd5079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[0, 1, 2], [3, 4, 5]], dtype=torch.float32)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1eb3b4-8c41-4712-a0ec-21a8e293d31a",
   "metadata": {},
   "source": [
    "The `device` argument determines if the tensor is going to live on cpu or gpu. We can use the `device` variable we determined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ac2fce-9314-46b3-b0b2-e68cf0f08b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[0, 1, 2], [3, 4, 5]], device=device)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6227ddb-68e8-4de0-b803-fa2a43ab9e5b",
   "metadata": {},
   "source": [
    "`requires_grad` determines if the tensor needs to be included in gradient descent calculations. This will be covered in more detail in future tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caae5302-154b-4540-8885-2ad1ec4e7b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[0, 1, 2], [3, 4, 5]], dtype=torch.float32, device=device, requires_grad=True)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d3b08-b63d-4d58-89df-f1a14b545934",
   "metadata": {},
   "source": [
    "If we need to change the parameters of an already initialized `Tensor`, we can do the adjustments in a later step, primarily using the `to` method of the `Tensor` class. The `to` method does not overwrite the original `Tensor`, but returns an adjusted one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944cacf0-1a2a-4ff8-8d76-d3407969ba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: dtype=torch.int64, device=cpu, requires_grad=False\n",
      "Adjusted dtype: dtype=torch.float32, device=cpu, requires_grad=False\n",
      "Adjusted device: dtype=torch.float32, device=cuda:0, requires_grad=False\n",
      "Adjusted requres_grad: dtype=torch.float32, device=cuda:0, requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[0, 1, 2], [3, 4, 5]])\n",
    "print(f'Original Tensor: dtype={tensor.dtype}, device={tensor.device}, requires_grad={tensor.requires_grad}')\n",
    "tensor = tensor.to(torch.float32)\n",
    "print(f'Adjusted dtype: dtype={tensor.dtype}, device={tensor.device}, requires_grad={tensor.requires_grad}')\n",
    "tensor = tensor.to(device)\n",
    "print(f'Adjusted device: dtype={tensor.dtype}, device={tensor.device}, requires_grad={tensor.requires_grad}')\n",
    "tensor.requires_grad = True\n",
    "print(f'Adjusted requres_grad: dtype={tensor.dtype}, device={tensor.device}, requires_grad={tensor.requires_grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe861b8-bfe5-4af3-a7a4-470f6612dfd8",
   "metadata": {},
   "source": [
    "We can use use `my_tensor.size()` or `my_tensor.shape` to find out the dimensions of the tensor. Our `Tensor` from above has 2 rows and 3 columns. In practice all deep learning framworks expect the first dimension to represent the number of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608faf68-4c3d-4a4c-96d4-0978b7b6b123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# In practice that would be a batch of 2 samples with 3 features\n",
    "print(tensor.size())\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7113ea-b66c-4f92-8352-0ba72fafafe6",
   "metadata": {},
   "source": [
    "There are many more methods to create a Tensor. The method `torch.from_numpy()` turns a numpy ndarray into a PyTorch tensor,  `torch.zeros()` returns a Tensor with all zeros, and `torch.ones()` returns a Tensor with all ones. We will see more of those methods as we go along. It makes no sense to cover all of them without any context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4d6e4-a63b-421c-bfb7-ae67533c420b",
   "metadata": {},
   "source": [
    "PyTorch, like other frameworks that work with arrays/tensors, is extremely efficient when it comes to matrix operations. These operations are done in parallel and can be transfered to the GPU if you have a cuda compatibale graphics card. We will use two tensors, $\\mathbf{A}$ and $\\mathbf{B}$ to demonstrate basic mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817dbc51-11fe-4335-b2b0-34baf5bb726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.ones(size=(2, 2), dtype=torch.float32)\n",
    "B = torch.tensor([[1, 2],[3, 4]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258c97a-d000-4fbb-9240-90d190086865",
   "metadata": {},
   "source": [
    "We can add, subtract, multiply and divide those matrices elementwise using basic mathematic operators like `+, -, *, /`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9be3e8a5-0706-4363-ae64-10568ae62e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "tensor([[ 0., -1.],\n",
      "        [-2., -3.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [0.3333, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(A + B)\n",
    "print(A - B)\n",
    "print(A * B)\n",
    "print(A / B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f38ff9-180b-4329-b04f-c28a851a11d1",
   "metadata": {},
   "source": [
    "We can achieve the same using the methods: `Tensor.add(). Tensor.subtract(), Tensor.multiply(), Tensor.divide()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "195a3ca1-ef85-43d3-8e8c-00dd2a12b9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "tensor([[ 0., -1.],\n",
      "        [-2., -3.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [0.3333, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(A.add(B))\n",
    "print(A.subtract(B))\n",
    "print(A.multiply(B))\n",
    "print(A.divide(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68b61a-6302-48dd-99a8-5645fb9d5d76",
   "metadata": {},
   "source": [
    "While the above methods do not change the original tensors, each of the methods has a corresponding method that changes the tensor in place. These methods always end with `_`: `add_()`, `subtract_()`, `multiply_()`, `divide_()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9fe487a-1732-499c-8138-096e74a712c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([[1, 2], [4, 4]], dtype=torch.float32)\n",
    "test.add_(A)\n",
    "# the test tensor was changed\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da80a2-33f7-4bb5-8156-4de95c07b2a0",
   "metadata": {},
   "source": [
    "If we want to apply matrix multiplication $ \\mathbf{A} \\mathbf{B} $ we use the `mathmul` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21b6de5e-ee0d-424d-9956-11b16f64bf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 6.],\n",
       "        [4., 6.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent to torch.matmul(A, B)\n",
    "A.matmul(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b81c3-cd5e-472c-95d7-75587142c049",
   "metadata": {},
   "source": [
    "Alternatively we can use `@` as a convenient way to use matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d5eca22-79f9-4091-ba47-9b2d58fe832e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 6.],\n",
       "        [4., 6.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062abb35-1951-4aea-bf2a-18f5c1b4c673",
   "metadata": {},
   "source": [
    "There is a lot more operations and methods that we can apply to tensors. We will utilize them as we move along. We will try to shortly explain those operations when we encounter them the first time, but if you encounter an operation that was not covered, we expect you to either use a search engine or to use the official PyTorch documentation. In practice this is what you will have to do in order to improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
