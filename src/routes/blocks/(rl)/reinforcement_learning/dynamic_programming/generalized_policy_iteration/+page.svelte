<script>
  import Container from "$lib/Container.svelte";
  import SvgContainer from "$lib/SvgContainer.svelte";
</script>

<svelte:head>
  <title>World4AI | Reinforcement Learning | Generalized Policy Iteration</title
  >
  <meta
    name="description"
    content="Policy Iteration and value iteration algorithms are implementations of generalized policy iteration algorithms. Many reinforcement learning algorithms follow a generalized policy iteration approach by switching between policy evaluation and policy improvement."
  />
</svelte:head>

<h1>Generalized Policy Iteration</h1>
<div class="separator" />

<Container>
  <p>
    Policy iteration and value iteration are both versions of generalized policy
    iteration (GPI) algorithms. Switching between policy evaluation and policy
    improvement is the core of GPI regardless of the implementation details of
    the algorithm.
  </p>
  <SvgContainer maxWidth="350px">
    <svg version="1.1" viewBox="0 0 500 500" xmlns="http://www.w3.org/2000/svg">
      <g>
        <path
          d="m247.16 252.84c1.6503 0.4422 0.21812 2.4427-0.73495 2.7428-2.5828 0.81342-4.6437-1.9064-4.7507-4.2128-0.19142-4.1255 3.8598-6.9607 7.6905-6.7586 5.6218 0.29653 9.3234 5.8313 8.7665 11.168-0.74226 7.1134-7.8083 11.704-14.646 10.774-8.6047-1.1702-14.094-9.7875-12.782-18.124 1.5889-10.096 11.768-16.489 21.602-14.79 11.589 2.0025 18.888 13.749 16.798 25.08-2.4127 13.081-15.731 21.288-28.557 18.806-14.574-2.8208-23.691-17.713-20.814-32.035 3.2273-16.067 19.696-26.094 35.513-22.822 17.56 3.6327 28.498 21.678 24.83 38.991-4.0372 19.053-23.661 30.903-42.468 26.838-20.547-4.4411-33.308-25.644-28.845-45.946 4.8445-22.04 27.627-35.714 49.424-30.853 23.534 5.2475 38.12 29.61 32.861 52.902-5.6502 25.028-31.593 40.526-56.38 34.869-26.521-6.0526-42.932-33.576-36.877-59.857 6.4547-28.015 35.56-45.339 63.335-38.885 29.509 6.8567 47.746 37.543 40.893 66.813-7.2585 31.003-39.526 50.153-70.291 42.901-32.497-7.6602-52.56-41.509-44.909-73.769 8.0617-33.99 43.493-54.967 77.246-46.916 35.484 8.4632 57.374 45.476 48.924 80.724-8.8645 36.978-47.46 59.781-84.202 50.932-38.472-9.2658-62.189-49.443-52.94-87.68 9.667-39.966 51.427-64.596 91.158-54.948 41.46 10.068 67.004 53.41 56.956 94.635-10.469 42.954-55.394 69.411-98.113 58.964-44.448-10.87-71.819-57.377-60.972-101.59 11.271-45.942 59.361-74.227 105.07-62.98 47.436 11.672 76.634 61.344 64.987 108.55-12.073 48.93-63.328 79.042-112.02 66.995-50.424-12.474-81.45-65.311-69.003-115.5 12.875-51.918 67.295-83.858 118.98-71.011 53.412 13.276 86.265 69.278 73.019 122.46-13.676 54.906-71.262 88.673-125.94 75.027-56.4-14.077-91.081-73.245-77.035-129.41 14.478-57.894 75.229-93.489 132.89-79.043 59.388 14.879 95.897 77.213 81.051 136.37-15.279 60.882-79.196 98.305-139.85 83.058-62.376-15.68-100.71-81.18-85.066-143.32 16.081-63.87 83.163-103.12 146.8-87.074 65.364 16.481 105.53 85.147 89.082 150.28-16.882 66.858-87.131 107.94-153.76 91.09-68.352-17.283-110.34-89.114-93.098-157.24 17.683-69.846 91.098-112.75 160.71-95.106 71.34 18.084 115.16 93.081 97.114 164.19-18.484 72.834-95.065 117.57-167.67 99.122-74.328-18.885-119.98-97.049-101.13-171.15 19.286-75.822 99.032-122.38 174.62-103.14 77.317 19.686 124.79 101.02 105.15 178.1-20.087 78.811-103 127.2-181.58 107.15-80.305-20.487-129.61-104.98-109.16-185.06 20.888-81.799 106.97-132.02 188.54-111.17 83.293 21.288 134.42 108.95 113.18 192.01-21.689 84.787-110.93 136.83-195.49 115.18-86.281-22.089-139.24-112.92-117.19-198.97 22.49-87.775 114.9-141.65 202.45-119.2 89.269 22.89 144.06 116.88 121.21 205.92-23.291 90.763-118.87 146.47-209.4 123.22-92.257-23.691-148.87-120.85-125.22-212.88 24.092-93.751 122.84-151.28 216.36-127.23 95.245 24.492 153.69 124.82 129.24 219.84-24.893 96.74-126.8 156.1-223.31 131.25-98.234-25.293-158.51-128.79-133.26-226.79 25.694-99.728 130.77-160.91 230.27-135.26 101.22 26.094 163.32 132.75 137.27 233.75-26.495 102.72-134.74 165.73-237.22 139.28-104.21-26.895-168.14-136.72-141.29-240.7 27.296-105.7 138.7-170.55 244.18-143.3 107.2 27.696 172.95 140.69 145.3 247.66-5.2276 20.223-13.571 39.622-24.648 57.33"
          fill="none"
          opacity=".15"
          stroke="var(--text-color)"
        />
        <path
          d="m45.004 249.99c0 53.669 22.094 107.01 60.043 144.96 37.95 37.95 91.288 60.043 144.96 60.043s107.01-22.094 144.96-60.043 60.043-91.288 60.043-144.96-22.094-107.01-60.043-144.96c-37.95-37.95-91.288-60.043-144.96-60.043s-107.01 22.094-144.96 60.043c-37.95 37.95-60.043 91.288-60.043 144.96z"
          fill="none"
          stroke="var(--text-color)"
          stroke-dasharray="2, 6"
          stroke-width="2"
        />
        <circle
          cx="250"
          cy="55.58"
          r="50"
          fill="var(--main-color-1)"
          stroke="#000"
          stroke-linecap="round"
        />
      </g>
      <text
        x="221.35901"
        y="80.349915"
        fill="#000000"
        font-family="sans-serif"
        font-size="93.851px"
        stroke-width="2.3463"
        style="line-height:1.25"
        xml:space="preserve"
        ><tspan x="215" y="80.349915" stroke-width="2.3463">Ï€</tspan></text
      >
      <circle
        cx="250"
        cy="441.5"
        r="50"
        fill="var(--main-color-1)"
        stroke="#000"
        stroke-linecap="round"
        stroke-width="1.0016"
      />
      <text
        x="222.22969"
        y="467.16315"
        fill="#000000"
        font-family="sans-serif"
        font-size="93.851px"
        stroke-width="2.3463"
        style="line-height:1.25"
        xml:space="preserve"
        ><tspan x="225" y="467.16315" stroke-width="2.3463">v</tspan></text
      >
    </svg>
  </SvgContainer>
  <p>
    Many of the reinforcement learning algorithms yet to come are based on
    generalized policy iteration. Evaluation and improvement alternate to
    eventually find optimal value and policy functions.
  </p>
  <div class="separator" />
</Container>
