
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Reinforcement Learning Applications &#8212; World4AI 0.1 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Agent and Environment" href="agent_env.html" />
    <link rel="prev" title="Reinforcement Learning" href="../index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../index.html">
<p class="title">World4AI</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  Reinforcement Learning
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/World4AI/World4AI" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Reinforcement Learning Applications
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="agent_env.html">
   Agent and Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="properties.html">
   Properties of Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="interaction.html">
   States, Actions, Rewards
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="exploration_vs_exploitation.html">
   Exploration vs Exploitation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="components.html">
   Agent and Environment Components
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Mathematics of Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../math/definition_markov_decision_process.html">
   Definition of a Markov Decision Process
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../math/to_solve_mdp.html">
   To Solve an MDP
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Dynamic Programming
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/policy_iteration.html">
   Policy Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dynamic_programming/value_iteration.html">
   Value Iteration
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Exploration Exploitation Tradeoff
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../exploration_exploitation_tradeoff/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exploration_exploitation_tradeoff/bandits.html">
   Bandits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exploration_exploitation_tradeoff/epsilon_greedy.html">
   Epsilon(
   <img alt="\epsilon" class="math" src="../../_images/math/13b33819efce3da0df3eb849f77d88d02df50c45.svg"/>
   )-Greedy
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Tabular Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tabular_reinforcement_learning/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tabular_reinforcement_learning/monte_carlo_methods.html">
   Monte Carlo Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tabular_reinforcement_learning/td_learning.html">
   Temporal Difference Learning
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Approximative Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../approximative_methods/online_td_learning.html">
   Online TD Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../approximative_methods/dqn.html">
   Deep Q-Network (DQN)
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Reinforcement Learning Libraries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../rl_libraries/motivation.html">
   Motivation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../rl_libraries/openai_gym.html">
   OpenAI Gym
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#games">
   Games
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#grid-worlds">
     Grid Worlds
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#atari-2600-games">
     Atari 2600 Games
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#board-games">
     Board Games
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modern-games">
     Modern Games
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finance">
   Finance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#robotics">
   Robotics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#healthcare">
   Healthcare
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#autonomous-vehicles">
   Autonomous Vehicles
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="reinforcement-learning-applications">
<h1>Reinforcement Learning Applications<a class="headerlink" href="#reinforcement-learning-applications" title="Permalink to this headline">¶</a></h1>
<p>It is entirely possible to introduce reinforcement learning using only formal definitions and math, but I would like to start this journey by exploring what reinforcement learning can actually achieve rather than what it is and how you can apply it. The formalism will come soon enough.</p>
<div class="section" id="games">
<h2>Games<a class="headerlink" href="#games" title="Permalink to this headline">¶</a></h2>
<div class="section" id="grid-worlds">
<h3>Grid Worlds<a class="headerlink" href="#grid-worlds" title="Permalink to this headline">¶</a></h3>
<p>Most beginner reinforcement learning problems are grid world problems. They are easy enough to understand and do not require a lot of computational power to solve. A grid world is a rectangular-shaped game with a certain number of rows and columns, where an intersection of a row and a column is a so-called cell in the grid world. A gridworld is (usually) a simple game. You have some sort of a player that can move through the gridworld, some obstacles to prevent the player from entering a certain cell and a goal the player needs to achieve, which then terminates (or restarts) the game. But of course there are grid worlds that are substantially more complex. These can for example include powerups, enemies and many levels.</p>
<div class="figure align-center" id="id1">
<img alt="../../_images/grid_world1.svg" src="../../_images/grid_world1.svg" /><p class="caption"><span class="caption-text">An example of a grid world</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>In the above example the player has to move the circle from the bottom left corner to the upper left corner. This seems like a trivial task for a human being, but it gets nontrivial if you are not allowed to hardcode the solution. Instead you have to make your computer learn the goal of the game and the strategy to achieve the goal. That is exactly where reinforcement learning comes into play. By applying reinforcement learning algorithms it becomes possible to learn the optimal behaviour, where the circle arrives at the goal in as few steps as possible (as indicated by the arrows in the cells).</p>
</div>
<div class="section" id="atari-2600-games">
<h3>Atari 2600 Games<a class="headerlink" href="#atari-2600-games" title="Permalink to this headline">¶</a></h3>
<p>Computer games have become a testing ground for reinforcement learning algorithms. Most new algorithms are tested on the Atari 2600 games in order to show how efficient the algorithms are. For a human it is not especially hard to learn the rules of the game (although it might require some time to master the game), but for computers it is an entirely different story. Due to the vast number of configurations the usual strategies that are used to solve the grid worlds break down. Usually good solutions require the use of neural networks.</p>
<div class="figure align-center" id="id2">
<img alt="../../_images/breakout.svg" src="../../_images/breakout.svg" /><p class="caption"><span class="caption-text">An example of breakout</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<p>The most known atari games are probably pong and breakout. In breakout for example you steer the paddle at the bottom of the screen. The goal of the game is to prevent the ball from falling by moving the paddle in the path of the ball. The ball bounces off the paddle and if it touches one of the blocks at the top of the screen, the block disappears, the ball starts moving in the opposite direction and you get some points. The game ends when either the ball falls on the ground or when you have destroyed all the blocks.</p>
<p>The computer receives the current frames of the game and has to decide how to act based just on the pixel values. There are of course versions of the game, where the computer receives the positions of the ball, the paddle and the boxes as coordinate values, but using that version would be essentially cheating. Looking at the pictures and behaving accordingly is not unlike how humans act. Therefore it is especially impressive that with the help of reinforcement learning it is possible to create computer programs that are able to beat human scores in all the Atari 2600 games while making decisions on the basis of the screenshots of the game.</p>
</div>
<div class="section" id="board-games">
<h3>Board Games<a class="headerlink" href="#board-games" title="Permalink to this headline">¶</a></h3>
<p>Board games, like backgammon, chess and go used to be the frontier for ai. There was an assumption that a computer would require creativity and imagination to beat a professional player at backgammon, chess and go. Essentially that meant that the computer needed to possess human characteristics in order to win against a professional player. Nevertheless in all three games professionals and even world champions were beaten by AI systems.</p>
<div class="figure align-center" id="id3">
<img alt="../../_images/game_of_go.svg" src="../../_images/game_of_go.svg" /><p class="caption"><span class="caption-text">Board configuration at move 37</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<p>Even though all solutions were an unbelievable milestone for the AI community, the win of DeepMind with their AlphaGo system against the go world champion was the most impressive for me. For a number of years the challenge of winning against the world champion was considered impossible. The number of legal board positions in the game of go is far greater than there are atoms in the observable universe. Iterating through all positions is therefore impossible. Nevertheless, not only did the algorithm win against the world champion Lee Sedol in the 4 of 5 games, but according to go experts AlphaGo showed creativity. In the second of the five games AlphaGo shocked the world with the now iconic move. This move has become known as “Move 37”.</p>
</div>
<div class="section" id="modern-games">
<h3>Modern Games<a class="headerlink" href="#modern-games" title="Permalink to this headline">¶</a></h3>
<p>Compared to Atari games, modern games have become a lot more complex and even for human players there is a steep learning curve, especially if you wish to become a professional player. In spite of that OpenAI and DeepMind have beaten top players in two of the most famous esports games, Dota II and StarCraft II.
StarCraft II for example is a so-called rts (real time strategy) game. In these types of games you have to collect resources, build workers and different types of attack vehicles, construct buildings, improve your technology, scout the area for opponents and to finally destroy the buildings and units of your opponents. Many of these decisions have tradeoffs and there is no single best strategy, the player has to adapt to the current situation.</p>
<div class="figure align-center" id="id4">
<img alt="../../_images/rts.svg" src="../../_images/rts.svg" /><p class="caption"><span class="caption-text">An example of a simplified real time strategy</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>The image above shows how an imagined rts game configuration might look like. The picture indicates how a player has to balance several decisions at the same time. What makes these types of games additionally hard is the so-called “fog of war”. The grey areas are not visible to the player, so that only a part of the map is observable. That creates an information imbalance and requires scouting the area to gain information.</p>
</div>
</div>
<div class="section" id="finance">
<h2>Finance<a class="headerlink" href="#finance" title="Permalink to this headline">¶</a></h2>
<p>Nowadays it seems that reinforcement learning is taking over the financial industry in every aspect imaginable. From valuing financial products to chatbots that communicate with prospective clients.</p>
<div class="figure align-center" id="id5">
<img alt="../../_images/finance.svg" src="../../_images/finance.svg" /><p class="caption"><span class="caption-text">An example of a reinforcement learning trading bot</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
<p>The most exciting part still seems to be portfolio management though. Imagine an artificial intelligence that decides what financial instrument to invest in and in what proportion. And the exact decisions could depend on the risk aversion of the client. There is an abundance of financial data (often free) going back sometimes a hundred of years. That data can be used to train a reinforcement learning AI to potentially perform better than humans over a long period of time. Even if the AI performs equally well to human portfolio managers, the banks could cut costs, as automated trading bots tend to be much cheaper than human portfolio managers.</p>
</div>
<div class="section" id="robotics">
<h2>Robotics<a class="headerlink" href="#robotics" title="Permalink to this headline">¶</a></h2>
<p>The field of robotics is vast. I could talk about robots on assembly lines, drones or bipedal robots. In all the above mentioned cases it is possible to apply reinforcement learning to learn the desired task for the robot.</p>
<div class="figure align-center" id="id6">
<img alt="../../_images/robots.svg" src="../../_images/robots.svg" /><p class="caption"><span class="caption-text">An example of multitask reinforcement learning</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
<p>For example the bipedal robot can be taught to walk through the means of reinforcement learning. Each good or bad step of the robot can be used as a learning experience. In fact that is partially already actively done but still remains an active research field. At the moment most successful bipedal robots, like those made by Boston Dynamics, are not actually trained through reinforcement learning, but are hardcoded to solve their task. Therefore these are great feats of pure engineering and not AI, but 10 years down the road and AI will probably replace a lot of hardcoded parts.</p>
</div>
<div class="section" id="healthcare">
<h2>Healthcare<a class="headerlink" href="#healthcare" title="Permalink to this headline">¶</a></h2>
<p>The possible advances in healthcare through the help of reinforcement learning are probably the ones that are of the greatest benefit to the general population. Several applications come to mind when I think about the intersection of healthcare and reinforcement learning.</p>
<p>Individual treatment plans for example, where drugs and treatments are adjusted quickly depending on the reaction of the patient could be developed. With each new patient the experience of the AI would increase. Unlike human doctors that have to go through medical studies, practice and have to eventually retire, the experience of AI could be centralized and made available to newer systems without loss of data. Thus the amount of mistakes and the cost of treatment should potentially decrease.</p>
<div class="figure align-center" id="id7">
<img alt="../../_images/healthcare.svg" src="../../_images/healthcare.svg" /><p class="caption"><span class="caption-text">An example of drug discovery</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<p>The development of new drugs is another exciting possible application of reinforcement learning. The abundance of medical data should allow the AI to learn to accelerate the drug discovery phase while making the overall development process safer.</p>
<p>To my knowledge both applications are experimental and are not fully implemented yet, but research in that area has been increasing.</p>
</div>
<div class="section" id="autonomous-vehicles">
<h2>Autonomous Vehicles<a class="headerlink" href="#autonomous-vehicles" title="Permalink to this headline">¶</a></h2>
<div class="figure align-center" id="id8">
<img alt="../../_images/autonomous_driving.svg" src="../../_images/autonomous_driving.svg" /><p class="caption"><span class="caption-text">Autonomous Vehicle</span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
<p>Autonomous vehicles (a.k.a. self-driving cars) are at the moment of writing the current frontier for reinforcement learning. There are many car companies that invest in self-driving cars. Newer car companies like Tesla and Google’s Waymo and old German car manufacturers like Volkswagen all invest an enormous amount of time and money in the development of autonomous vehicles. Research in the area has been going on since at least the 80’s, with demonstrations by Daimler, but the behaviour of these vehicles in edge cases made their use often dangerous for everyday use. Since the DARPA Grand Challenge (2007) great leaps have been made and reinforcement learning played a huge role in that success story. It is probably only a matter of time until autonomous vehicles become fully legalized. The advantages are tremendous. Expected lower mortality rates due to traffic accidents, lower cost for taxi fares and more efficient logistics, as drivers won’t have to sleep on overnight journeys.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>I hope you see that the problems that reinforcement learning is able to solve have gotten more and more complex and that the applications went from purely theoretical to practical. That development is expected to continue. Especially I expect the spillover effect from theory to practice to increase. Reinforcement Learning is an exciting field to participate in, even if all you want is to understand the current development.</p>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page">Reinforcement Learning</a>
    <a class='right-next' id="next-link" href="agent_env.html" title="next page">Agent and Environment</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, World4AI Team.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.0.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>