import{S as en,i as tn,s as an,e as Va,b as s,C as Y,P as ln,h as r,a8 as Fa,Q as sn,R as mn,m as C,n as L,k as W,a as d,q as u,y as _,W as on,l as R,c,r as h,z as v,N as T,A as b,g as y,d as x,B as k}from"../chunks/index.4d92b023.js";import{C as fn}from"../chunks/Container.b0705c7b.js";import{H as $n}from"../chunks/Highlight.b7c1de53.js";import{L as X}from"../chunks/Latex.e0b308c0.js";import{B as pn}from"../chunks/ButtonContainer.e9aac418.js";import{S as un}from"../chunks/StepButton.2fb0289b.js";import{F as hn,I as Na}from"../chunks/InternalLink.7deb899c.js";import{P as na}from"../chunks/PythonCode.212ba7a6.js";import{P as ra,T as Ha}from"../chunks/Ticks.45eca5c5.js";import{C as nn,r as la}from"../chunks/Contour.1bb4e19b.js";import{X as dn,Y as cn}from"../chunks/YLabel.182e66a3.js";import{P as Ye}from"../chunks/Path.7e6df014.js";import{C as rn}from"../chunks/Circle.f281e92b.js";import{L as vt}from"../chunks/Legend.de38c007.js";function Ja(o,n,a){const t=o.slice();return t[6]=n[a],t}function Ka(o){let n,a,t;return{c(){n=sn("ellipse"),this.h()},l(m){n=mn(m,"ellipse",{fill:!0,cx:!0,cy:!0,rx:!0,ry:!0,class:!0}),C(n).forEach(r),this.h()},h(){L(n,"fill",o[1]),L(n,"cx",a=o[4](o[6].x)),L(n,"cy",t=o[5](o[6].y)),L(n,"rx",o[2]),L(n,"ry",o[3]),L(n,"class","svelte-93ikzk")},m(m,p){s(m,n,p)},p(m,p){p&2&&L(n,"fill",m[1]),p&1&&a!==(a=m[4](m[6].x))&&L(n,"cx",a),p&1&&t!==(t=m[5](m[6].y))&&L(n,"cy",t),p&4&&L(n,"rx",m[2]),p&8&&L(n,"ry",m[3])},d(m){m&&r(n)}}}function gn(o){let n,a=o[0],t=[];for(let m=0;m<a.length;m+=1)t[m]=Ka(Ja(o,a,m));return{c(){for(let m=0;m<t.length;m+=1)t[m].c();n=Va()},l(m){for(let p=0;p<t.length;p+=1)t[p].l(m);n=Va()},m(m,p){for(let P=0;P<t.length;P+=1)t[P]&&t[P].m(m,p);s(m,n,p)},p(m,[p]){if(p&63){a=m[0];let P;for(P=0;P<a.length;P+=1){const $=Ja(m,a,P);t[P]?t[P].p($,p):(t[P]=Ka($),t[P].c(),t[P].m(n.parentNode,n))}for(;P<t.length;P+=1)t[P].d(1);t.length=a.length}},i:Y,o:Y,d(m){ln(t,m),m&&r(n)}}}function wn(o,n,a){let{data:t}=n,{color:m="var(--main-color-1)"}=n,{radiusX:p=5}=n,{radiusY:P=5}=n,$=Fa("xScale"),z=Fa("yScale");return o.$$set=g=>{"data"in g&&a(0,t=g.data),"color"in g&&a(1,m=g.color),"radiusX"in g&&a(2,p=g.radiusX),"radiusY"in g&&a(3,P=g.radiusY)},[t,m,p,P,$,z]}class wt extends en{constructor(n){super(),tn(this,n,wn,gn,an,{data:0,color:1,radiusX:2,radiusY:3})}}function _n(o){let n;return{c(){n=u("optimizer")},l(a){n=h(a,"optimizer")},m(a,t){s(a,n,t)},d(a){a&&r(n)}}}function vn(o){let n=String.raw`\mathbf{\nabla}_w`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function bn(o){let n;return{c(){n=u("\\alpha")},l(a){n=h(a,"\\alpha")},m(a,t){s(a,n,t)},d(a){a&&r(n)}}}function yn(o){let n=String.raw`\mathbf{w}`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function xn(o){let n=String.raw`\mathbf{w}_{t+1} := \mathbf{w}_t - \alpha \mathbf{\nabla}_w`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function kn(o){let n=String.raw`\mathbf{m_t} = \beta \mathbf{m}_{t-1} + (1 - \beta) \mathbf{\nabla}_w `+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Sn(o){let n=String.raw`t`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Pn(o){let n=String.raw`\mathbf{m}_t`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function zn(o){let n=String.raw`\mathbf{m}_{t-1}`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Tn(o){let n=String.raw`\mathbf{\nabla}_w`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function En(o){let n;return{c(){n=u("\\beta")},l(a){n=h(a,"\\beta")},m(a,t){s(a,n,t)},d(a){a&&r(n)}}}function An(o){let n=String.raw`\mathbf{m}_0`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Dn(o){let n=String.raw`\mathbf{m}_0 = \mathbf{\nabla}_w`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Mn(o){let n;return{c(){n=u("\\nabla")},l(a){n=h(a,"\\nabla")},m(a,t){s(a,n,t)},d(a){a&&r(n)}}}function Cn(o){let n=String.raw`\mathbf{w}_{t+1} := \mathbf{w}_t - \alpha \mathbf{m}_t`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Wn(o){let n,a;return n=new un({}),n.$on("click",o[4]),{c(){_(n.$$.fragment)},l(t){v(n.$$.fragment,t)},m(t,m){b(n,t,m),a=!0},p:Y,i(t){a||(y(n.$$.fragment,t),a=!0)},o(t){x(n.$$.fragment,t),a=!1},d(t){k(n,t)}}}function Rn(o){let n,a,t,m,p,P;return n=new Ha({props:{xTicks:[-3,-2,-1,0,1,2,3,4,5,6,7],yTicks:[-40,-20,0,20,40,60,80,100,120]}}),t=new Ye({props:{data:o[3]}}),p=new rn({props:{data:o[0]}}),{c(){_(n.$$.fragment),a=d(),_(t.$$.fragment),m=d(),_(p.$$.fragment)},l($){v(n.$$.fragment,$),a=c($),v(t.$$.fragment,$),m=c($),v(p.$$.fragment,$)},m($,z){b(n,$,z),s($,a,z),b(t,$,z),s($,m,z),b(p,$,z),P=!0},p($,z){const g={};z&1&&(g.data=$[0]),p.$set(g)},i($){P||(y(n.$$.fragment,$),y(t.$$.fragment,$),y(p.$$.fragment,$),P=!0)},o($){x(n.$$.fragment,$),x(t.$$.fragment,$),x(p.$$.fragment,$),P=!1},d($){k(n,$),$&&r(a),k(t,$),$&&r(m),k(p,$)}}}function jn(o){let n=String.raw`x^2 + y^2`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Gn(o){let n,a,t,m,p,P,$,z,g,M,E,w,S,j;return n=new nn({props:{f:o[5],thresholds:la(-2,2,.1).map(Fn)}}),t=new Ye({props:{data:o[6],stroke:"2",strokeDashArray:"4 4"}}),p=new Ye({props:{data:o[7],color:"var(--main-color-4)",strokeDashArray:"4 4",stroke:"2"}}),$=new dn({props:{text:"x",type:"latex",y:"580",fontSize:"15"}}),g=new cn({props:{text:"y",type:"latex",y:"300",fontSize:"15"}}),E=new vt({props:{coordinates:{x:-.9,y:-.85},legendColor:"black",text:"Vanilla Gradient Descent"}}),S=new vt({props:{coordinates:{x:-.9,y:-.9},text:"Gradient Descent With Momentum",legendColor:"var(--main-color-4)"}}),{c(){_(n.$$.fragment),a=d(),_(t.$$.fragment),m=d(),_(p.$$.fragment),P=d(),_($.$$.fragment),z=d(),_(g.$$.fragment),M=d(),_(E.$$.fragment),w=d(),_(S.$$.fragment)},l(i){v(n.$$.fragment,i),a=c(i),v(t.$$.fragment,i),m=c(i),v(p.$$.fragment,i),P=c(i),v($.$$.fragment,i),z=c(i),v(g.$$.fragment,i),M=c(i),v(E.$$.fragment,i),w=c(i),v(S.$$.fragment,i)},m(i,A){b(n,i,A),s(i,a,A),b(t,i,A),s(i,m,A),b(p,i,A),s(i,P,A),b($,i,A),s(i,z,A),b(g,i,A),s(i,M,A),b(E,i,A),s(i,w,A),b(S,i,A),j=!0},p:Y,i(i){j||(y(n.$$.fragment,i),y(t.$$.fragment,i),y(p.$$.fragment,i),y($.$$.fragment,i),y(g.$$.fragment,i),y(E.$$.fragment,i),y(S.$$.fragment,i),j=!0)},o(i){x(n.$$.fragment,i),x(t.$$.fragment,i),x(p.$$.fragment,i),x($.$$.fragment,i),x(g.$$.fragment,i),x(E.$$.fragment,i),x(S.$$.fragment,i),j=!1},d(i){k(n,i),i&&r(a),k(t,i),i&&r(m),k(p,i),i&&r(P),k($,i),i&&r(z),k(g,i),i&&r(M),k(E,i),i&&r(w),k(S,i)}}}function In(o){let n,a,t,m,p,P,$,z,g,M,E,w,S,j;return n=new wt({props:{data:[{x:0,y:0}],radiusX:"480",radiusY:"80",color:"var(--main-color-4)"}}),t=new wt({props:{data:[{x:0,y:0}],radiusX:"240",radiusY:"40",color:"none"}}),p=new wt({props:{data:[{x:0,y:0}],radiusX:"120",radiusY:"20",color:"none"}}),$=new wt({props:{data:[{x:0,y:0}],radiusX:"60",radiusY:"10",color:"none"}}),g=new wt({props:{data:[{x:0,y:0}],radiusX:"30",radiusY:"5",color:"none"}}),E=new Ye({props:{data:[{x:-.85,y:-.55},{x:-.8,y:.65},{x:-.75,y:-.6},{x:-.7,y:.62},{x:-.65,y:-.6},{x:-.6,y:.57},{x:-.5,y:-.5},{x:-.4,y:.5}],stroke:"2",strokeDashArray:"2 4"}}),S=new Ha({props:{xTicks:[-1,0,1],yTicks:[-1,0,1]}}),{c(){_(n.$$.fragment),a=d(),_(t.$$.fragment),m=d(),_(p.$$.fragment),P=d(),_($.$$.fragment),z=d(),_(g.$$.fragment),M=d(),_(E.$$.fragment),w=d(),_(S.$$.fragment)},l(i){v(n.$$.fragment,i),a=c(i),v(t.$$.fragment,i),m=c(i),v(p.$$.fragment,i),P=c(i),v($.$$.fragment,i),z=c(i),v(g.$$.fragment,i),M=c(i),v(E.$$.fragment,i),w=c(i),v(S.$$.fragment,i)},m(i,A){b(n,i,A),s(i,a,A),b(t,i,A),s(i,m,A),b(p,i,A),s(i,P,A),b($,i,A),s(i,z,A),b(g,i,A),s(i,M,A),b(E,i,A),s(i,w,A),b(S,i,A),j=!0},p:Y,i(i){j||(y(n.$$.fragment,i),y(t.$$.fragment,i),y(p.$$.fragment,i),y($.$$.fragment,i),y(g.$$.fragment,i),y(E.$$.fragment,i),y(S.$$.fragment,i),j=!0)},o(i){x(n.$$.fragment,i),x(t.$$.fragment,i),x(p.$$.fragment,i),x($.$$.fragment,i),x(g.$$.fragment,i),x(E.$$.fragment,i),x(S.$$.fragment,i),j=!1},d(i){k(n,i),i&&r(a),k(t,i),i&&r(m),k(p,i),i&&r(P),k($,i),i&&r(z),k(g,i),i&&r(M),k(E,i),i&&r(w),k(S,i)}}}function Yn(o){let n=String.raw`\mathbf{d_t} = \beta_2 \mathbf{d}_{t-1} + (1 - \beta_2) \mathbf{\nabla}_w^2`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Xn(o){let n=String.raw`\mathbf{d}`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function qn(o){let n=String.raw`\mathbf{w}_{t+1} := \mathbf{w}_t - \alpha \dfrac{\mathbf{\nabla}_w}{\sqrt{\mathbf{d}_t} + \epsilon}`+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Bn(o){let n;return{c(){n=u("\\epsilon")},l(a){n=h(a,"\\epsilon")},m(a,t){s(a,n,t)},d(a){a&&r(n)}}}function On(o){let n,a,t,m,p,P,$,z,g,M,E,w,S,j,i,A,G,B;return n=new nn({props:{f:o[8],thresholds:la(-16,16.1,.5).map(Nn)}}),t=new Ha({props:{xTicks:la(-2,2),yTicks:la(-2,2)}}),p=new Ye({props:{data:o[9],stroke:"4",strokeDashArray:"3 6"}}),$=new Ye({props:{data:o[10],color:"var(--main-color-2)",stroke:"4",strokeDashArray:"3 6"}}),g=new Ye({props:{data:o[11],color:"var(--main-color-3)",stroke:"4",strokeDashArray:"3 6"}}),E=new rn({props:{data:[{x:0,y:0}]}}),S=new vt({props:{coordinates:{x:-.9,y:-.85},legendColor:"black",text:"Vanilla Gradient Descent"}}),i=new vt({props:{coordinates:{x:-.9,y:-.9},text:"Gradient Descent With Momentum",legendColor:"var(--main-color-2)"}}),G=new vt({props:{coordinates:{x:-.9,y:-.95},text:"RMSProp",legendColor:"var(--main-color-3)"}}),{c(){_(n.$$.fragment),a=d(),_(t.$$.fragment),m=d(),_(p.$$.fragment),P=d(),_($.$$.fragment),z=d(),_(g.$$.fragment),M=d(),_(E.$$.fragment),w=d(),_(S.$$.fragment),j=d(),_(i.$$.fragment),A=d(),_(G.$$.fragment)},l(f){v(n.$$.fragment,f),a=c(f),v(t.$$.fragment,f),m=c(f),v(p.$$.fragment,f),P=c(f),v($.$$.fragment,f),z=c(f),v(g.$$.fragment,f),M=c(f),v(E.$$.fragment,f),w=c(f),v(S.$$.fragment,f),j=c(f),v(i.$$.fragment,f),A=c(f),v(G.$$.fragment,f)},m(f,D){b(n,f,D),s(f,a,D),b(t,f,D),s(f,m,D),b(p,f,D),s(f,P,D),b($,f,D),s(f,z,D),b(g,f,D),s(f,M,D),b(E,f,D),s(f,w,D),b(S,f,D),s(f,j,D),b(i,f,D),s(f,A,D),b(G,f,D),B=!0},p:Y,i(f){B||(y(n.$$.fragment,f),y(t.$$.fragment,f),y(p.$$.fragment,f),y($.$$.fragment,f),y(g.$$.fragment,f),y(E.$$.fragment,f),y(S.$$.fragment,f),y(i.$$.fragment,f),y(G.$$.fragment,f),B=!0)},o(f){x(n.$$.fragment,f),x(t.$$.fragment,f),x(p.$$.fragment,f),x($.$$.fragment,f),x(g.$$.fragment,f),x(E.$$.fragment,f),x(S.$$.fragment,f),x(i.$$.fragment,f),x(G.$$.fragment,f),B=!1},d(f){k(n,f),f&&r(a),k(t,f),f&&r(m),k(p,f),f&&r(P),k($,f),f&&r(z),k(g,f),f&&r(M),k(E,f),f&&r(w),k(S,f),f&&r(j),k(i,f),f&&r(A),k(G,f)}}}function Ln(o){let n=String.raw`
  \begin{aligned}
    \mathbf{m_t} &= \beta_1 \mathbf{m}_{t-1} + (1 - \beta_1) \mathbf{\nabla}_w \\
    \mathbf{d_t} &= \beta_2 \mathbf{d}_{t-1} + (1 - \beta_2) \mathbf{\nabla}_w^2 \\
    \mathbf{w}_{t+1} & := \mathbf{w}_t - \alpha \dfrac{\mathbf{m}_t}{\sqrt{\mathbf{d}_t} + \epsilon}
  \end{aligned}
    `+"",a;return{c(){a=u(n)},l(t){a=h(t,n)},m(t,m){s(t,a,m)},p:Y,d(t){t&&r(a)}}}function Hn(o){let n,a,t,m,p,P,$,z,g,M,E,w,S,j,i,A,G,B,f,D,V,F,N,Xe,I,H,U,ia,bt,qe,sa,yt,Be,ma,xt,Z,kt,q,oa,ee,fa,te,$a,ae,pa,ne,ua,re,ha,le,da,St,ie,Pt,se,ca,me,ga,zt,oe,Tt,fe,wa,Ze,_a,va,Et,ze,At,Oe,ba,Dt,$e,Mt,pe,Ct,ue,ya,he,xa,Wt,de,Rt,Le,jt,He,ka,Gt,ce,Sa,Te,Pa,It,ge,Yt,Ve,za,Xt,Fe,Ta,qt,we,Bt,_e,Ea,ve,Aa,Ot,be,Lt,ye,Da,xe,Ma,Ht,Ne,Ca,Vt,ke,Ft,K,Wa,et,Ra,ja,tt,Ga,Ia,Nt,Ee,Jt,Je,Kt,Ke,Ya,Qt,Se,Xa,Ae,qa,Ut,Pe,Zt,Qe,Ba,ea,Ue,Oa,ta,De,aa;return t=new $n({props:{$$slots:{default:[_n]},$$scope:{ctx:o}}}),g=new na({props:{code:"optimizer = optim.SGD(model.parameters(), lr=0.01)"}}),S=new X({props:{$$slots:{default:[vn]},$$scope:{ctx:o}}}),i=new X({props:{$$slots:{default:[bn]},$$scope:{ctx:o}}}),G=new X({props:{$$slots:{default:[yn]},$$scope:{ctx:o}}}),D=new X({props:{$$slots:{default:[xn]},$$scope:{ctx:o}}}),Z=new X({props:{$$slots:{default:[kn]},$$scope:{ctx:o}}}),ee=new X({props:{$$slots:{default:[Sn]},$$scope:{ctx:o}}}),te=new X({props:{$$slots:{default:[Pn]},$$scope:{ctx:o}}}),ae=new X({props:{$$slots:{default:[zn]},$$scope:{ctx:o}}}),ne=new X({props:{$$slots:{default:[Tn]},$$scope:{ctx:o}}}),re=new X({props:{$$slots:{default:[En]},$$scope:{ctx:o}}}),le=new X({props:{$$slots:{default:[An]},$$scope:{ctx:o}}}),ie=new X({props:{$$slots:{default:[Dn]},$$scope:{ctx:o}}}),me=new X({props:{$$slots:{default:[Mn]},$$scope:{ctx:o}}}),oe=new X({props:{$$slots:{default:[Cn]},$$scope:{ctx:o}}}),ze=new na({props:{code:"optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"}}),$e=new pn({props:{$$slots:{default:[Wn]},$$scope:{ctx:o}}}),pe=new ra({props:{width:"450",height:"450",maxWidth:"500",domain:[-3,7],range:[-40,120],padding:{top:20,right:20,bottom:20,left:25},$$slots:{default:[Rn]},$$scope:{ctx:o}}}),he=new X({props:{$$slots:{default:[jn]},$$scope:{ctx:o}}}),de=new ra({props:{width:"600",height:"600",maxWidth:"700",domain:[-1,1],range:[-1,1],padding:{top:0,right:0,bottom:0,left:0},$$slots:{default:[Gn]},$$scope:{ctx:o}}}),Te=new Na({props:{type:"note",id:"1"}}),ge=new ra({props:{width:"1000",height:"200",maxWidth:"700",domain:[-1,1],range:[-1,1],padding:{top:5,right:5,bottom:20,left:30},$$slots:{default:[In]},$$scope:{ctx:o}}}),we=new X({props:{$$slots:{default:[Yn]},$$scope:{ctx:o}}}),ve=new X({props:{$$slots:{default:[Xn]},$$scope:{ctx:o}}}),be=new X({props:{$$slots:{default:[qn]},$$scope:{ctx:o}}}),xe=new X({props:{$$slots:{default:[Bn]},$$scope:{ctx:o}}}),ke=new ra({props:{width:"600",height:"600",maxWidth:"700",domain:[-1,1],range:[-1,1],padding:{top:5,right:5,bottom:20,left:30},$$slots:{default:[On]},$$scope:{ctx:o}}}),Ee=new na({props:{code:"optimizer = optim.RMSprop(model.parameters(), lr=0.01)"}}),Ae=new Na({props:{id:"1",type:"reference"}}),Pe=new X({props:{$$slots:{default:[Ln]},$$scope:{ctx:o}}}),De=new na({props:{code:"optimizer = optim.Adam(model.parameters(), lr=0.01)"}}),{c(){n=W("p"),a=u(`In deep learning the specific gradient descent algorithm is called an
    `),_(t.$$.fragment),m=u(`. So far we have only really looked at the
    plain vanilla gradient descent optimizer called `),p=W("code"),P=u("SGD"),$=u(`, short for
    stochastic gradient descent.`),z=d(),_(g.$$.fragment),M=d(),E=W("p"),w=u(`With each batch we use the backpropagation algorithm to calculate the
    gradient vector `),_(S.$$.fragment),j=u(`. The gradient
    descent optimizer directly subtracts the gradient, scaled by the learning
    rate `),_(i.$$.fragment),A=u(", from the weight vector "),_(G.$$.fragment),B=u(" without any further adjustments."),f=d(),_(D.$$.fragment),V=d(),F=W("p"),N=u(`As you can probably guess this is not the only and by far not the fastest
    approach available. Other optimizers have been developed over time that
    generally converge a lot faster.`),Xe=d(),I=W("div"),H=d(),U=W("h2"),ia=u("Momentum"),bt=d(),qe=W("p"),sa=u(`The plain vanilla gradient descent algorithm lacks any form of memory. This
    optimizer only takes the gradient direction from the current batch into
    consideration and disregards any past gradient calculations.`),yt=d(),Be=W("p"),ma=u(`When we use stochastic gradient descent with momentum on the other hand, we
    keep a moving average of the past directions and use that average
    additionally to the current gradient to adjust the weights.`),xt=d(),_(Z.$$.fragment),kt=d(),q=W("p"),oa=u("At each timestep "),_(ee.$$.fragment),fa=u(` we calculate the momentum vector
    `),_(te.$$.fragment),$a=u(` as a weighted average of the previous
    momentum `),_(ae.$$.fragment),pa=u(` and the current gradient
    `),_(ne.$$.fragment),ua=u(`, where
    `),_(re.$$.fragment),ha=u(" is usually around 0.9. As the initial momentum vector "),_(le.$$.fragment),da=u(` is essentially empty, deep learning frameworks like PyTorch initialize the
    vector by setting the momentum to the actual gradient vector.`),St=d(),_(ie.$$.fragment),Pt=d(),se=W("p"),ca=u("When we apply gradient descent, we do not use the gradient vector "),_(me.$$.fragment),ga=u(" directly to adjust the weights of the neural network, but use momentum instead."),zt=d(),_(oe.$$.fragment),Tt=d(),fe=W("p"),wa=u(`In PyTorch we can use gradient descent with momentum by passing an
    additional argument to the `),Ze=W("code"),_a=u("SGD"),va=u(" object."),Et=d(),_(ze.$$.fragment),At=d(),Oe=W("p"),ba=u(`But why is momentum actually useful? Below we see the same example with the
    local minimum, that we studied the first time we encountered gradient
    descent. The example showed, that gradient descent will get stuck in a local
    minimum. Gradient descent with momentum on the other has a chance to escape
    the local minimum.`),Dt=d(),_($e.$$.fragment),Mt=d(),_(pe.$$.fragment),Ct=d(),ue=W("p"),ya=u(`Even when we are dealing with a direct path towards the minimum without any
    saddle points and local minima, the momentum optimizer will build
    acceleration and converge faster towards the minimum. Below we compare the
    convergence speed between simple stochastic gradient descent and momentum
    for `),_(he.$$.fragment),xa=u(`. The momentum based approach
    arrives faster at the optimum.`),Wt=d(),_(de.$$.fragment),Rt=d(),Le=W("div"),jt=d(),He=W("h2"),ka=u("RMSProp"),Gt=d(),ce=W("p"),Sa=u("Adaptive optimizers, like RMSProp"),_(Te.$$.fragment),Pa=u(`, do not
    adjust speed per se, but determine a better direction for gradient descent.
    If we are dealing with a bowl shaped loss function for example, the
    gradients will not be symmetrical. That means that we will approach the
    optimal value not in a direct line, but rather in a zig zagging manner.`),It=d(),_(ge.$$.fragment),Yt=d(),Ve=W("p"),za=u(`We would like to move more in a the x direction and less in the y direction,
    which would result in a straight line towards the optimium. Theoretically we
    could offset the zig zag by using an individual learning rate for each of
    the weights, but given that there are million of weights in modern deep
    learning, this approach is not feasable. Adaptive optimizers scale each
    gradient in such a way, that we approach the optimum in a much straighter
    line. These optimizers allow to use a single learning rate for the whole
    neural network.`),Xt=d(),Fe=W("p"),Ta=u(`Similar to momentum, RMSProp (root mean squared prop) calcualtes a moving
    average, but instead of tracking the gradient, we track the squared
    gradient.`),qt=d(),_(we.$$.fragment),Bt=d(),_e=W("p"),Ea=u("This root of the vector "),_(ve.$$.fragment),Aa=u(` is used to scale
    the gradient. This causes the gradients to get similar in magnitute (which creates
    a straighter line), while still following the general direction that is encoded
    in the moving average.`),Ot=d(),_(be.$$.fragment),Lt=d(),ye=W("p"),Da=u("The "),_(xe.$$.fragment),Ma=u(` varialble is a very small positive number that is
    used in order to avoid divisions by 0.`),Ht=d(),Ne=W("p"),Ca=u(`Below we compare vanilla gradient descent, gradient descent with momentum
    and RMSProp on a loss function with an elongated form. While the simple
    gradient descent and momentum gradient descent approach the optimum in a
    curved manner, RMSProp takes basically a straight route. Also notice, that
    momentum can overshoot due to gained speed and needs some time to reverse
    direction.`),Vt=d(),_(ke.$$.fragment),Ft=d(),K=W("p"),Wa=u(`The api for all optimizers in PyTorch is identical, so we can simply replace
    the `),et=W("code"),Ra=u("SGD"),ja=u(" object with the "),tt=W("code"),Ga=u("RMSprop"),Ia=u(` object and we are good
    to go.`),Nt=d(),_(Ee.$$.fragment),Jt=d(),Je=W("div"),Kt=d(),Ke=W("h2"),Ya=u("Adam"),Qt=d(),Se=W("p"),Xa=u("Adam"),_(Ae.$$.fragment),qa=u(` is the combination of momentum and
    adaptive learning. If you look at the equations below, you will not find any
    new concepts. We calculate moving averages of the gradients and the squared gradients.
    The RMSProp style scaling is not applied directly to the gradient vector, instead
    we scale the momentum vector and use the result to adjust the weights.`),Ut=d(),_(Pe.$$.fragment),Zt=d(),Qe=W("p"),Ba=u(`Adam (and its derivatives) is probably the most used optimizer at this point
    in time. If you don't have any specific reason to use a different optimizer,
    use adam.`),ea=d(),Ue=W("p"),Oa=u("We can implement the adam optimizer in PyTorch the following way."),ta=d(),_(De.$$.fragment),this.h()},l(e){n=R(e,"P",{});var l=C(n);a=h(l,`In deep learning the specific gradient descent algorithm is called an
    `),v(t.$$.fragment,l),m=h(l,`. So far we have only really looked at the
    plain vanilla gradient descent optimizer called `),p=R(l,"CODE",{});var at=C(p);P=h(at,"SGD"),at.forEach(r),$=h(l,`, short for
    stochastic gradient descent.`),l.forEach(r),z=c(e),v(g.$$.fragment,e),M=c(e),E=R(e,"P",{});var J=C(E);w=h(J,`With each batch we use the backpropagation algorithm to calculate the
    gradient vector `),v(S.$$.fragment,J),j=h(J,`. The gradient
    descent optimizer directly subtracts the gradient, scaled by the learning
    rate `),v(i.$$.fragment,J),A=h(J,", from the weight vector "),v(G.$$.fragment,J),B=h(J," without any further adjustments."),J.forEach(r),f=c(e),v(D.$$.fragment,e),V=c(e),F=R(e,"P",{});var nt=C(F);N=h(nt,`As you can probably guess this is not the only and by far not the fastest
    approach available. Other optimizers have been developed over time that
    generally converge a lot faster.`),nt.forEach(r),Xe=c(e),I=R(e,"DIV",{class:!0}),C(I).forEach(r),H=c(e),U=R(e,"H2",{});var rt=C(U);ia=h(rt,"Momentum"),rt.forEach(r),bt=c(e),qe=R(e,"P",{});var lt=C(qe);sa=h(lt,`The plain vanilla gradient descent algorithm lacks any form of memory. This
    optimizer only takes the gradient direction from the current batch into
    consideration and disregards any past gradient calculations.`),lt.forEach(r),yt=c(e),Be=R(e,"P",{});var it=C(Be);ma=h(it,`When we use stochastic gradient descent with momentum on the other hand, we
    keep a moving average of the past directions and use that average
    additionally to the current gradient to adjust the weights.`),it.forEach(r),xt=c(e),v(Z.$$.fragment,e),kt=c(e),q=R(e,"P",{});var O=C(q);oa=h(O,"At each timestep "),v(ee.$$.fragment,O),fa=h(O,` we calculate the momentum vector
    `),v(te.$$.fragment,O),$a=h(O,` as a weighted average of the previous
    momentum `),v(ae.$$.fragment,O),pa=h(O,` and the current gradient
    `),v(ne.$$.fragment,O),ua=h(O,`, where
    `),v(re.$$.fragment,O),ha=h(O," is usually around 0.9. As the initial momentum vector "),v(le.$$.fragment,O),da=h(O,` is essentially empty, deep learning frameworks like PyTorch initialize the
    vector by setting the momentum to the actual gradient vector.`),O.forEach(r),St=c(e),v(ie.$$.fragment,e),Pt=c(e),se=R(e,"P",{});var Me=C(se);ca=h(Me,"When we apply gradient descent, we do not use the gradient vector "),v(me.$$.fragment,Me),ga=h(Me," directly to adjust the weights of the neural network, but use momentum instead."),Me.forEach(r),zt=c(e),v(oe.$$.fragment,e),Tt=c(e),fe=R(e,"P",{});var Ce=C(fe);wa=h(Ce,`In PyTorch we can use gradient descent with momentum by passing an
    additional argument to the `),Ze=R(Ce,"CODE",{});var st=C(Ze);_a=h(st,"SGD"),st.forEach(r),va=h(Ce," object."),Ce.forEach(r),Et=c(e),v(ze.$$.fragment,e),At=c(e),Oe=R(e,"P",{});var mt=C(Oe);ba=h(mt,`But why is momentum actually useful? Below we see the same example with the
    local minimum, that we studied the first time we encountered gradient
    descent. The example showed, that gradient descent will get stuck in a local
    minimum. Gradient descent with momentum on the other has a chance to escape
    the local minimum.`),mt.forEach(r),Dt=c(e),v($e.$$.fragment,e),Mt=c(e),v(pe.$$.fragment,e),Ct=c(e),ue=R(e,"P",{});var We=C(ue);ya=h(We,`Even when we are dealing with a direct path towards the minimum without any
    saddle points and local minima, the momentum optimizer will build
    acceleration and converge faster towards the minimum. Below we compare the
    convergence speed between simple stochastic gradient descent and momentum
    for `),v(he.$$.fragment,We),xa=h(We,`. The momentum based approach
    arrives faster at the optimum.`),We.forEach(r),Wt=c(e),v(de.$$.fragment,e),Rt=c(e),Le=R(e,"DIV",{class:!0}),C(Le).forEach(r),jt=c(e),He=R(e,"H2",{});var ot=C(He);ka=h(ot,"RMSProp"),ot.forEach(r),Gt=c(e),ce=R(e,"P",{});var Re=C(ce);Sa=h(Re,"Adaptive optimizers, like RMSProp"),v(Te.$$.fragment,Re),Pa=h(Re,`, do not
    adjust speed per se, but determine a better direction for gradient descent.
    If we are dealing with a bowl shaped loss function for example, the
    gradients will not be symmetrical. That means that we will approach the
    optimal value not in a direct line, but rather in a zig zagging manner.`),Re.forEach(r),It=c(e),v(ge.$$.fragment,e),Yt=c(e),Ve=R(e,"P",{});var ft=C(Ve);za=h(ft,`We would like to move more in a the x direction and less in the y direction,
    which would result in a straight line towards the optimium. Theoretically we
    could offset the zig zag by using an individual learning rate for each of
    the weights, but given that there are million of weights in modern deep
    learning, this approach is not feasable. Adaptive optimizers scale each
    gradient in such a way, that we approach the optimum in a much straighter
    line. These optimizers allow to use a single learning rate for the whole
    neural network.`),ft.forEach(r),Xt=c(e),Fe=R(e,"P",{});var $t=C(Fe);Ta=h($t,`Similar to momentum, RMSProp (root mean squared prop) calcualtes a moving
    average, but instead of tracking the gradient, we track the squared
    gradient.`),$t.forEach(r),qt=c(e),v(we.$$.fragment,e),Bt=c(e),_e=R(e,"P",{});var je=C(_e);Ea=h(je,"This root of the vector "),v(ve.$$.fragment,je),Aa=h(je,` is used to scale
    the gradient. This causes the gradients to get similar in magnitute (which creates
    a straighter line), while still following the general direction that is encoded
    in the moving average.`),je.forEach(r),Ot=c(e),v(be.$$.fragment,e),Lt=c(e),ye=R(e,"P",{});var Ge=C(ye);Da=h(Ge,"The "),v(xe.$$.fragment,Ge),Ma=h(Ge,` varialble is a very small positive number that is
    used in order to avoid divisions by 0.`),Ge.forEach(r),Ht=c(e),Ne=R(e,"P",{});var pt=C(Ne);Ca=h(pt,`Below we compare vanilla gradient descent, gradient descent with momentum
    and RMSProp on a loss function with an elongated form. While the simple
    gradient descent and momentum gradient descent approach the optimum in a
    curved manner, RMSProp takes basically a straight route. Also notice, that
    momentum can overshoot due to gained speed and needs some time to reverse
    direction.`),pt.forEach(r),Vt=c(e),v(ke.$$.fragment,e),Ft=c(e),K=R(e,"P",{});var Q=C(K);Wa=h(Q,`The api for all optimizers in PyTorch is identical, so we can simply replace
    the `),et=R(Q,"CODE",{});var ut=C(et);Ra=h(ut,"SGD"),ut.forEach(r),ja=h(Q," object with the "),tt=R(Q,"CODE",{});var ht=C(tt);Ga=h(ht,"RMSprop"),ht.forEach(r),Ia=h(Q,` object and we are good
    to go.`),Q.forEach(r),Nt=c(e),v(Ee.$$.fragment,e),Jt=c(e),Je=R(e,"DIV",{class:!0}),C(Je).forEach(r),Kt=c(e),Ke=R(e,"H2",{});var dt=C(Ke);Ya=h(dt,"Adam"),dt.forEach(r),Qt=c(e),Se=R(e,"P",{});var Ie=C(Se);Xa=h(Ie,"Adam"),v(Ae.$$.fragment,Ie),qa=h(Ie,` is the combination of momentum and
    adaptive learning. If you look at the equations below, you will not find any
    new concepts. We calculate moving averages of the gradients and the squared gradients.
    The RMSProp style scaling is not applied directly to the gradient vector, instead
    we scale the momentum vector and use the result to adjust the weights.`),Ie.forEach(r),Ut=c(e),v(Pe.$$.fragment,e),Zt=c(e),Qe=R(e,"P",{});var ct=C(Qe);Ba=h(ct,`Adam (and its derivatives) is probably the most used optimizer at this point
    in time. If you don't have any specific reason to use a different optimizer,
    use adam.`),ct.forEach(r),ea=c(e),Ue=R(e,"P",{});var gt=C(Ue);Oa=h(gt,"We can implement the adam optimizer in PyTorch the following way."),gt.forEach(r),ta=c(e),v(De.$$.fragment,e),this.h()},h(){L(I,"class","separator"),L(Le,"class","separator"),L(Je,"class","separator")},m(e,l){s(e,n,l),T(n,a),b(t,n,null),T(n,m),T(n,p),T(p,P),T(n,$),s(e,z,l),b(g,e,l),s(e,M,l),s(e,E,l),T(E,w),b(S,E,null),T(E,j),b(i,E,null),T(E,A),b(G,E,null),T(E,B),s(e,f,l),b(D,e,l),s(e,V,l),s(e,F,l),T(F,N),s(e,Xe,l),s(e,I,l),s(e,H,l),s(e,U,l),T(U,ia),s(e,bt,l),s(e,qe,l),T(qe,sa),s(e,yt,l),s(e,Be,l),T(Be,ma),s(e,xt,l),b(Z,e,l),s(e,kt,l),s(e,q,l),T(q,oa),b(ee,q,null),T(q,fa),b(te,q,null),T(q,$a),b(ae,q,null),T(q,pa),b(ne,q,null),T(q,ua),b(re,q,null),T(q,ha),b(le,q,null),T(q,da),s(e,St,l),b(ie,e,l),s(e,Pt,l),s(e,se,l),T(se,ca),b(me,se,null),T(se,ga),s(e,zt,l),b(oe,e,l),s(e,Tt,l),s(e,fe,l),T(fe,wa),T(fe,Ze),T(Ze,_a),T(fe,va),s(e,Et,l),b(ze,e,l),s(e,At,l),s(e,Oe,l),T(Oe,ba),s(e,Dt,l),b($e,e,l),s(e,Mt,l),b(pe,e,l),s(e,Ct,l),s(e,ue,l),T(ue,ya),b(he,ue,null),T(ue,xa),s(e,Wt,l),b(de,e,l),s(e,Rt,l),s(e,Le,l),s(e,jt,l),s(e,He,l),T(He,ka),s(e,Gt,l),s(e,ce,l),T(ce,Sa),b(Te,ce,null),T(ce,Pa),s(e,It,l),b(ge,e,l),s(e,Yt,l),s(e,Ve,l),T(Ve,za),s(e,Xt,l),s(e,Fe,l),T(Fe,Ta),s(e,qt,l),b(we,e,l),s(e,Bt,l),s(e,_e,l),T(_e,Ea),b(ve,_e,null),T(_e,Aa),s(e,Ot,l),b(be,e,l),s(e,Lt,l),s(e,ye,l),T(ye,Da),b(xe,ye,null),T(ye,Ma),s(e,Ht,l),s(e,Ne,l),T(Ne,Ca),s(e,Vt,l),b(ke,e,l),s(e,Ft,l),s(e,K,l),T(K,Wa),T(K,et),T(et,Ra),T(K,ja),T(K,tt),T(tt,Ga),T(K,Ia),s(e,Nt,l),b(Ee,e,l),s(e,Jt,l),s(e,Je,l),s(e,Kt,l),s(e,Ke,l),T(Ke,Ya),s(e,Qt,l),s(e,Se,l),T(Se,Xa),b(Ae,Se,null),T(Se,qa),s(e,Ut,l),b(Pe,e,l),s(e,Zt,l),s(e,Qe,l),T(Qe,Ba),s(e,ea,l),s(e,Ue,l),T(Ue,Oa),s(e,ta,l),b(De,e,l),aa=!0},p(e,l){const at={};l&4194304&&(at.$$scope={dirty:l,ctx:e}),t.$set(at);const J={};l&4194304&&(J.$$scope={dirty:l,ctx:e}),S.$set(J);const nt={};l&4194304&&(nt.$$scope={dirty:l,ctx:e}),i.$set(nt);const rt={};l&4194304&&(rt.$$scope={dirty:l,ctx:e}),G.$set(rt);const lt={};l&4194304&&(lt.$$scope={dirty:l,ctx:e}),D.$set(lt);const it={};l&4194304&&(it.$$scope={dirty:l,ctx:e}),Z.$set(it);const O={};l&4194304&&(O.$$scope={dirty:l,ctx:e}),ee.$set(O);const Me={};l&4194304&&(Me.$$scope={dirty:l,ctx:e}),te.$set(Me);const Ce={};l&4194304&&(Ce.$$scope={dirty:l,ctx:e}),ae.$set(Ce);const st={};l&4194304&&(st.$$scope={dirty:l,ctx:e}),ne.$set(st);const mt={};l&4194304&&(mt.$$scope={dirty:l,ctx:e}),re.$set(mt);const We={};l&4194304&&(We.$$scope={dirty:l,ctx:e}),le.$set(We);const ot={};l&4194304&&(ot.$$scope={dirty:l,ctx:e}),ie.$set(ot);const Re={};l&4194304&&(Re.$$scope={dirty:l,ctx:e}),me.$set(Re);const ft={};l&4194304&&(ft.$$scope={dirty:l,ctx:e}),oe.$set(ft);const $t={};l&4194304&&($t.$$scope={dirty:l,ctx:e}),$e.$set($t);const je={};l&4194305&&(je.$$scope={dirty:l,ctx:e}),pe.$set(je);const Ge={};l&4194304&&(Ge.$$scope={dirty:l,ctx:e}),he.$set(Ge);const pt={};l&4194304&&(pt.$$scope={dirty:l,ctx:e}),de.$set(pt);const Q={};l&4194304&&(Q.$$scope={dirty:l,ctx:e}),ge.$set(Q);const ut={};l&4194304&&(ut.$$scope={dirty:l,ctx:e}),we.$set(ut);const ht={};l&4194304&&(ht.$$scope={dirty:l,ctx:e}),ve.$set(ht);const dt={};l&4194304&&(dt.$$scope={dirty:l,ctx:e}),be.$set(dt);const Ie={};l&4194304&&(Ie.$$scope={dirty:l,ctx:e}),xe.$set(Ie);const ct={};l&4194304&&(ct.$$scope={dirty:l,ctx:e}),ke.$set(ct);const gt={};l&4194304&&(gt.$$scope={dirty:l,ctx:e}),Pe.$set(gt)},i(e){aa||(y(t.$$.fragment,e),y(g.$$.fragment,e),y(S.$$.fragment,e),y(i.$$.fragment,e),y(G.$$.fragment,e),y(D.$$.fragment,e),y(Z.$$.fragment,e),y(ee.$$.fragment,e),y(te.$$.fragment,e),y(ae.$$.fragment,e),y(ne.$$.fragment,e),y(re.$$.fragment,e),y(le.$$.fragment,e),y(ie.$$.fragment,e),y(me.$$.fragment,e),y(oe.$$.fragment,e),y(ze.$$.fragment,e),y($e.$$.fragment,e),y(pe.$$.fragment,e),y(he.$$.fragment,e),y(de.$$.fragment,e),y(Te.$$.fragment,e),y(ge.$$.fragment,e),y(we.$$.fragment,e),y(ve.$$.fragment,e),y(be.$$.fragment,e),y(xe.$$.fragment,e),y(ke.$$.fragment,e),y(Ee.$$.fragment,e),y(Ae.$$.fragment,e),y(Pe.$$.fragment,e),y(De.$$.fragment,e),aa=!0)},o(e){x(t.$$.fragment,e),x(g.$$.fragment,e),x(S.$$.fragment,e),x(i.$$.fragment,e),x(G.$$.fragment,e),x(D.$$.fragment,e),x(Z.$$.fragment,e),x(ee.$$.fragment,e),x(te.$$.fragment,e),x(ae.$$.fragment,e),x(ne.$$.fragment,e),x(re.$$.fragment,e),x(le.$$.fragment,e),x(ie.$$.fragment,e),x(me.$$.fragment,e),x(oe.$$.fragment,e),x(ze.$$.fragment,e),x($e.$$.fragment,e),x(pe.$$.fragment,e),x(he.$$.fragment,e),x(de.$$.fragment,e),x(Te.$$.fragment,e),x(ge.$$.fragment,e),x(we.$$.fragment,e),x(ve.$$.fragment,e),x(be.$$.fragment,e),x(xe.$$.fragment,e),x(ke.$$.fragment,e),x(Ee.$$.fragment,e),x(Ae.$$.fragment,e),x(Pe.$$.fragment,e),x(De.$$.fragment,e),aa=!1},d(e){e&&r(n),k(t),e&&r(z),k(g,e),e&&r(M),e&&r(E),k(S),k(i),k(G),e&&r(f),k(D,e),e&&r(V),e&&r(F),e&&r(Xe),e&&r(I),e&&r(H),e&&r(U),e&&r(bt),e&&r(qe),e&&r(yt),e&&r(Be),e&&r(xt),k(Z,e),e&&r(kt),e&&r(q),k(ee),k(te),k(ae),k(ne),k(re),k(le),e&&r(St),k(ie,e),e&&r(Pt),e&&r(se),k(me),e&&r(zt),k(oe,e),e&&r(Tt),e&&r(fe),e&&r(Et),k(ze,e),e&&r(At),e&&r(Oe),e&&r(Dt),k($e,e),e&&r(Mt),k(pe,e),e&&r(Ct),e&&r(ue),k(he),e&&r(Wt),k(de,e),e&&r(Rt),e&&r(Le),e&&r(jt),e&&r(He),e&&r(Gt),e&&r(ce),k(Te),e&&r(It),k(ge,e),e&&r(Yt),e&&r(Ve),e&&r(Xt),e&&r(Fe),e&&r(qt),k(we,e),e&&r(Bt),e&&r(_e),k(ve),e&&r(Ot),k(be,e),e&&r(Lt),e&&r(ye),k(xe),e&&r(Ht),e&&r(Ne),e&&r(Vt),k(ke,e),e&&r(Ft),e&&r(K),e&&r(Nt),k(Ee,e),e&&r(Jt),e&&r(Je),e&&r(Kt),e&&r(Ke),e&&r(Qt),e&&r(Se),k(Ae),e&&r(Ut),k(Pe,e),e&&r(Zt),e&&r(Qe),e&&r(ea),e&&r(Ue),e&&r(ta),k(De,e)}}}function Vn(o){let n,a,t,m,p,P,$,z,g,M,E;return z=new fn({props:{$$slots:{default:[Hn]},$$scope:{ctx:o}}}),M=new hn({props:{references:o[1],notes:o[2]}}),{c(){n=W("meta"),a=d(),t=W("h1"),m=u("Optimizers"),p=d(),P=W("div"),$=d(),_(z.$$.fragment),g=d(),_(M.$$.fragment),this.h()},l(w){const S=on("svelte-8vv9um",document.head);n=R(S,"META",{name:!0,content:!0}),S.forEach(r),a=c(w),t=R(w,"H1",{});var j=C(t);m=h(j,"Optimizers"),j.forEach(r),p=c(w),P=R(w,"DIV",{class:!0}),C(P).forEach(r),$=c(w),v(z.$$.fragment,w),g=c(w),v(M.$$.fragment,w),this.h()},h(){document.title="Optimizers - World4AI",L(n,"name","description"),L(n,"content","Optimizers like momentum gradient descent, RMSProp and adam have several advantages over vanilla gradient descent and can speed up training significantly. Switching out optimizers in PyTorch is relatively easy and usually requires switching just a single line of code."),L(P,"class","separator")},m(w,S){T(document.head,n),s(w,a,S),s(w,t,S),T(t,m),s(w,p,S),s(w,P,S),s(w,$,S),b(z,w,S),s(w,g,S),b(M,w,S),E=!0},p(w,[S]){const j={};S&4194305&&(j.$$scope={dirty:S,ctx:w}),z.$set(j)},i(w){E||(y(z.$$.fragment,w),y(M.$$.fragment,w),E=!0)},o(w){x(z.$$.fragment,w),x(M.$$.fragment,w),E=!1},d(w){r(n),w&&r(a),w&&r(t),w&&r(p),w&&r(P),w&&r($),k(z,w),w&&r(g),k(M,w)}}}let Qa=.01,Ua=.9,Za=250,La=100;function _t(o,n,a,t,m,p,P=!1,$=!1,z=.9,g=.9,M=1e-4){let E=[];E.push({x:t,y:m});let w,S,j,i,A,G;P&&(A={x:0,y:0}),$&&(G={x:0,y:0});for(let B=0;B<o;B++){w=E[B].x,S=E[B].y,j=a(w,S).x,i=a(w,S).y;let f=j,D=i;if(P){f=A.x=A.x*z+j*(1-z),D=A.y=A.y*z+i*(1-z);let N=1/(1-z**(B+1));f*=N,D*=N}let V=1,F=1;if($){V=G.x=G.x*g+j**2*(1-g),F=G.y=G.y*g+i**2*(1-g);let N=1/(1-g**(B+1));V*=N,F*=N,V=Math.sqrt(V)+M,F=Math.sqrt(F)+M}w-=p*f/V,S-=p*D/F,E.push({x:w,y:S})}return E}const Fn=o=>o,Nn=o=>o;function Jn(o,n,a){let t,m;const p=[{author:"Diederik Kingma and Jimmy Ba",title:"Adam: A Method for Stochastic Optimization",journal:"",year:"2014",pages:"",volume:"",issue:""}],P=["RMSProp was developed by Geoffrey Hinton for a deep learning course on the Coursera plattform. You can access the original materials at https://www.cs.toronto.edu/~hinton/. Lecture 6 is the relevant one."];let $=[],z=7,g=7,M=[];for(let I=-6;I<=7;I+=.1){let H=I,U=H**3-5*H**2+10;M.push({x:H,y:U})}function E(){a(0,$=[]),$.push({x:z,y:t}),$.push({x:g,y:m})}function w(){let I=3*z**2-10*z;a(12,z=z-Qa*I)}let S=null;function j(){let I=3*g**2-10*g;S===null?S=I:S=S*Ua+I*(1-Ua),a(13,g=g-Qa*S)}function i(){w(),j()}let A=(I,H)=>I**2+H**2,G=(I,H)=>({x:2*I,y:2*H}),B=_t(Za,A,G,-20,20,.01),f=_t(Za,A,G,20,20,.01,!0),D=(I,H)=>I**2+9*H**2,V=(I,H)=>({x:2*I,y:18*H}),F=_t(La,D,V,-1,-1,.01),N=_t(La,D,V,1,1,.01,!0,!1),Xe=_t(La,D,V,-1,1,.01,!1,!0);return o.$$.update=()=>{o.$$.dirty&4096&&a(15,t=z**3-5*z**2+10),o.$$.dirty&8192&&a(14,m=g**3-5*g**2+10),o.$$.dirty&49152&&(t||m)&&E()},[$,p,P,M,i,A,B,f,D,F,N,Xe,z,g,m,t]}class fr extends en{constructor(n){super(),tn(this,n,Jn,Vn,an,{})}}export{fr as default};
