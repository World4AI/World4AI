import{S as vn,i as wn,s as kn,k as P,a as w,y as m,W as xn,l as T,h as s,c as k,z as c,n as v,N,b as h,A as p,g as _,d,B as g,q as x,m as b,r as y,L as yn,C as st,Q as fe,R as he,P as Pe,e as Ae}from"../chunks/index.4d92b023.js";import{C as bn}from"../chunks/Container.b0705c7b.js";import{F as zn,I as Nn}from"../chunks/InternalLink.7deb899c.js";import{S as lt}from"../chunks/SvgContainer.f70b5745.js";import{L as at}from"../chunks/Latex.e0b308c0.js";import{H as Yt}from"../chunks/Highlight.b7c1de53.js";import{P as jt}from"../chunks/PythonCode.212ba7a6.js";import{B as At}from"../chunks/ButtonContainer.e9aac418.js";import{P as Pt}from"../chunks/PlayButton.85103c5a.js";import{B as $e}from"../chunks/Block.059eddcd.js";import{P as Ut}from"../chunks/Plus.fc904b16.js";import{M as Jt}from"../chunks/Multiply.cec66028.js";import{A as R}from"../chunks/Arrow.ae91874c.js";const Cn=""+new URL("../assets/generated_images.8d1cf45f.webp",import.meta.url).href;function Xt(o,n,r){const e=o.slice();return e[9]=n[r],e[11]=r,e}function Zt(o,n,r){const e=o.slice();return e[9]=n[r],e[13]=r,e}function en(o,n,r){const e=o.slice();return e[9]=n[r],e[11]=r,e}function tn(o,n,r){const e=o.slice();return e[9]=n[r],e[13]=r,e}function nn(o,n,r){const e=o.slice();return e[9]=n[r],e[11]=r,e}function rn(o,n,r){const e=o.slice();return e[9]=n[r],e[13]=r,e}function ln(o,n,r){const e=o.slice();return e[9]=n[r],e[11]=r,e}function an(o,n,r){const e=o.slice();return e[9]=n[r],e[13]=r,e}function An(o){let n;return{c(){n=x("Gated PixelCNN")},l(r){n=y(r,"Gated PixelCNN")},m(r,e){h(r,n,e)},d(r){r&&s(n)}}}function Pn(o){let n,r;return n=new Pt({props:{f:o[5]}}),{c(){m(n.$$.fragment)},l(e){c(n.$$.fragment,e)},m(e,l){p(n,e,l),r=!0},p:st,i(e){r||(_(n.$$.fragment,e),r=!0)},o(e){d(n.$$.fragment,e),r=!1},d(e){g(n,e)}}}function sn(o){let n,r;return{c(){n=fe("rect"),this.h()},l(e){n=he(e,"rect",{x:!0,y:!0,width:!0,height:!0,class:!0,fill:!0}),b(n).forEach(s),this.h()},h(){v(n,"x",q+o[11]*(H+q)),v(n,"y",q+o[13]*(H+q)),v(n,"width",H),v(n,"height",H),v(n,"class","stroke-black"),v(n,"fill",r=pn(o[11],o[13],o[0]))},m(e,l){h(e,n,l)},p(e,l){l&1&&r!==(r=pn(e[11],e[13],e[0]))&&v(n,"fill",r)},d(e){e&&s(n)}}}function on(o){let n,r=Array(S),e=[];for(let l=0;l<r.length;l+=1)e[l]=sn(an(o,r,l));return{c(){for(let l=0;l<e.length;l+=1)e[l].c();n=Ae()},l(l){for(let f=0;f<e.length;f+=1)e[f].l(l);n=Ae()},m(l,f){for(let a=0;a<e.length;a+=1)e[a]&&e[a].m(l,f);h(l,n,f)},p(l,f){if(f&1){r=Array(S);let a;for(a=0;a<r.length;a+=1){const $=an(l,r,a);e[a]?e[a].p($,f):(e[a]=sn($),e[a].c(),e[a].m(n.parentNode,n))}for(;a<e.length;a+=1)e[a].d(1);e.length=r.length}},d(l){Pe(e,l),l&&s(n)}}}function Tn(o){let n,r=Array(S),e=[];for(let l=0;l<r.length;l+=1)e[l]=on(ln(o,r,l));return{c(){n=fe("svg");for(let l=0;l<e.length;l+=1)e[l].c();this.h()},l(l){n=he(l,"svg",{viewBox:!0});var f=b(n);for(let a=0;a<e.length;a+=1)e[a].l(f);f.forEach(s),this.h()},h(){v(n,"viewBox","0 0 250 250")},m(l,f){h(l,n,f);for(let a=0;a<e.length;a+=1)e[a]&&e[a].m(n,null)},p(l,f){if(f&1){r=Array(S);let a;for(a=0;a<r.length;a+=1){const $=ln(l,r,a);e[a]?e[a].p($,f):(e[a]=on($),e[a].c(),e[a].m(n,null))}for(;a<e.length;a+=1)e[a].d(1);e.length=r.length}},d(l){l&&s(n),Pe(e,l)}}}function Mn(o){let n,r;return n=new Pt({props:{f:o[6]}}),{c(){m(n.$$.fragment)},l(e){c(n.$$.fragment,e)},m(e,l){p(n,e,l),r=!0},p:st,i(e){r||(_(n.$$.fragment,e),r=!0)},o(e){d(n.$$.fragment,e),r=!1},d(e){g(n,e)}}}function fn(o){let n,r;return{c(){n=fe("rect"),this.h()},l(e){n=he(e,"rect",{x:!0,y:!0,width:!0,height:!0,class:!0,fill:!0}),b(n).forEach(s),this.h()},h(){v(n,"x",q+o[11]*(H+q)),v(n,"y",q+o[13]*(H+q)),v(n,"width",H),v(n,"height",H),v(n,"class","stroke-black"),v(n,"fill",r=_n(o[11],o[13],o[1]))},m(e,l){h(e,n,l)},p(e,l){l&2&&r!==(r=_n(e[11],e[13],e[1]))&&v(n,"fill",r)},d(e){e&&s(n)}}}function hn(o){let n,r=Array(S),e=[];for(let l=0;l<r.length;l+=1)e[l]=fn(rn(o,r,l));return{c(){for(let l=0;l<e.length;l+=1)e[l].c();n=Ae()},l(l){for(let f=0;f<e.length;f+=1)e[f].l(l);n=Ae()},m(l,f){for(let a=0;a<e.length;a+=1)e[a]&&e[a].m(l,f);h(l,n,f)},p(l,f){if(f&2){r=Array(S);let a;for(a=0;a<r.length;a+=1){const $=rn(l,r,a);e[a]?e[a].p($,f):(e[a]=fn($),e[a].c(),e[a].m(n.parentNode,n))}for(;a<e.length;a+=1)e[a].d(1);e.length=r.length}},d(l){Pe(e,l),l&&s(n)}}}function En(o){let n,r=Array(S),e=[];for(let l=0;l<r.length;l+=1)e[l]=hn(nn(o,r,l));return{c(){n=fe("svg");for(let l=0;l<e.length;l+=1)e[l].c();this.h()},l(l){n=he(l,"svg",{viewBox:!0});var f=b(n);for(let a=0;a<e.length;a+=1)e[a].l(f);f.forEach(s),this.h()},h(){v(n,"viewBox","0 0 250 250")},m(l,f){h(l,n,f);for(let a=0;a<e.length;a+=1)e[a]&&e[a].m(n,null)},p(l,f){if(f&2){r=Array(S);let a;for(a=0;a<r.length;a+=1){const $=nn(l,r,a);e[a]?e[a].p($,f):(e[a]=hn($),e[a].c(),e[a].m(n,null))}for(;a<e.length;a+=1)e[a].d(1);e.length=r.length}},d(l){l&&s(n),Pe(e,l)}}}function Dn(o){let n;return{c(){n=x("vertical stack")},l(r){n=y(r,"vertical stack")},m(r,e){h(r,n,e)},d(r){r&&s(n)}}}function Sn(o){let n;return{c(){n=x("horizontal stack")},l(r){n=y(r,"horizontal stack")},m(r,e){h(r,n,e)},d(r){r&&s(n)}}}function Bn(o){let n,r;return n=new Pt({props:{f:o[7]}}),{c(){m(n.$$.fragment)},l(e){c(n.$$.fragment,e)},m(e,l){p(n,e,l),r=!0},p:st,i(e){r||(_(n.$$.fragment,e),r=!0)},o(e){d(n.$$.fragment,e),r=!1},d(e){g(n,e)}}}function un(o){let n,r;return{c(){n=fe("rect"),this.h()},l(e){n=he(e,"rect",{x:!0,y:!0,width:!0,height:!0,stroke:!0,fill:!0}),b(n).forEach(s),this.h()},h(){v(n,"x",q+o[11]*(H+q)),v(n,"y",q+o[13]*(H+q)),v(n,"width",H),v(n,"height",H),v(n,"stroke","var(--text-color)"),v(n,"fill",r=dn(o[11],o[13],o[2]))},m(e,l){h(e,n,l)},p(e,l){l&4&&r!==(r=dn(e[11],e[13],e[2]))&&v(n,"fill",r)},d(e){e&&s(n)}}}function $n(o){let n,r=Array(S),e=[];for(let l=0;l<r.length;l+=1)e[l]=un(tn(o,r,l));return{c(){for(let l=0;l<e.length;l+=1)e[l].c();n=Ae()},l(l){for(let f=0;f<e.length;f+=1)e[f].l(l);n=Ae()},m(l,f){for(let a=0;a<e.length;a+=1)e[a]&&e[a].m(l,f);h(l,n,f)},p(l,f){if(f&4){r=Array(S);let a;for(a=0;a<r.length;a+=1){const $=tn(l,r,a);e[a]?e[a].p($,f):(e[a]=un($),e[a].c(),e[a].m(n.parentNode,n))}for(;a<e.length;a+=1)e[a].d(1);e.length=r.length}},d(l){Pe(e,l),l&&s(n)}}}function Wn(o){let n,r=Array(S),e=[];for(let l=0;l<r.length;l+=1)e[l]=$n(en(o,r,l));return{c(){n=fe("svg");for(let l=0;l<e.length;l+=1)e[l].c();this.h()},l(l){n=he(l,"svg",{viewBox:!0});var f=b(n);for(let a=0;a<e.length;a+=1)e[a].l(f);f.forEach(s),this.h()},h(){v(n,"viewBox","0 0 250 250")},m(l,f){h(l,n,f);for(let a=0;a<e.length;a+=1)e[a]&&e[a].m(n,null)},p(l,f){if(f&4){r=Array(S);let a;for(a=0;a<r.length;a+=1){const $=en(l,r,a);e[a]?e[a].p($,f):(e[a]=$n($),e[a].c(),e[a].m(n,null))}for(;a<e.length;a+=1)e[a].d(1);e.length=r.length}},d(l){l&&s(n),Pe(e,l)}}}function Ln(o){let n,r;return n=new Pt({props:{f:o[8]}}),{c(){m(n.$$.fragment)},l(e){c(n.$$.fragment,e)},m(e,l){p(n,e,l),r=!0},p:st,i(e){r||(_(n.$$.fragment,e),r=!0)},o(e){d(n.$$.fragment,e),r=!1},d(e){g(n,e)}}}function mn(o){let n,r;return{c(){n=fe("rect"),this.h()},l(e){n=he(e,"rect",{x:!0,y:!0,width:!0,height:!0,stroke:!0,fill:!0}),b(n).forEach(s),this.h()},h(){v(n,"x",q+o[11]*(H+q)),v(n,"y",q+o[13]*(H+q)),v(n,"width",H),v(n,"height",H),v(n,"stroke","var(--text-color)"),v(n,"fill",r=gn(o[11],o[13],o[3]))},m(e,l){h(e,n,l)},p(e,l){l&8&&r!==(r=gn(e[11],e[13],e[3]))&&v(n,"fill",r)},d(e){e&&s(n)}}}function cn(o){let n,r=Array(S),e=[];for(let l=0;l<r.length;l+=1)e[l]=mn(Zt(o,r,l));return{c(){for(let l=0;l<e.length;l+=1)e[l].c();n=Ae()},l(l){for(let f=0;f<e.length;f+=1)e[f].l(l);n=Ae()},m(l,f){for(let a=0;a<e.length;a+=1)e[a]&&e[a].m(l,f);h(l,n,f)},p(l,f){if(f&8){r=Array(S);let a;for(a=0;a<r.length;a+=1){const $=Zt(l,r,a);e[a]?e[a].p($,f):(e[a]=mn($),e[a].c(),e[a].m(n.parentNode,n))}for(;a<e.length;a+=1)e[a].d(1);e.length=r.length}},d(l){Pe(e,l),l&&s(n)}}}function Gn(o){let n,r=Array(S),e=[];for(let l=0;l<r.length;l+=1)e[l]=cn(Xt(o,r,l));return{c(){n=fe("svg");for(let l=0;l<e.length;l+=1)e[l].c();this.h()},l(l){n=he(l,"svg",{viewBox:!0});var f=b(n);for(let a=0;a<e.length;a+=1)e[a].l(f);f.forEach(s),this.h()},h(){v(n,"viewBox","0 0 250 250")},m(l,f){h(l,n,f);for(let a=0;a<e.length;a+=1)e[a]&&e[a].m(n,null)},p(l,f){if(f&8){r=Array(S);let a;for(a=0;a<r.length;a+=1){const $=Xt(l,r,a);e[a]?e[a].p($,f):(e[a]=cn($),e[a].c(),e[a].m(n,null))}for(;a<e.length;a+=1)e[a].d(1);e.length=r.length}},d(l){l&&s(n),Pe(e,l)}}}function Vn(o){let n,r,e,l,f,a,$,z,M,U,F,K,J,O,le,C,Y,ae,X,j,se,Z,B,ee,W,te,Q,oe,ne,L,re,G,me;return e=new R({props:{data:[{x:0,y:70},{x:105,y:70}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),l=new R({props:{data:[{x:120,y:70},{x:120,y:20},{x:155,y:20}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),f=new R({props:{data:[{x:120,y:70},{x:120,y:120},{x:155,y:120}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),a=new R({props:{data:[{x:220,y:20},{x:260,y:20},{x:260,y:50}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),$=new R({props:{data:[{x:220,y:120},{x:260,y:120},{x:260,y:90}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),z=new R({props:{data:[{x:260,y:70},{x:390,y:70}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),M=new $e({props:{x:40,y:70,width:55,height:25,text:"n \\times n",fontSize:15,type:"latex",class:"fill-green-100"}}),U=new $e({props:{x:120,y:70,width:15,height:15,class:"fill-blue-100"}}),F=new Jt({props:{x:260,y:70,radius:10,class:"fill-red-300"}}),K=new $e({props:{x:190,y:20,width:55,height:25,text:"tanh",fontSize:15,type:"latex",class:"fill-yellow-100"}}),J=new $e({props:{x:190,y:120,width:55,height:25,text:"\\sigma",fontSize:15,type:"latex",class:"fill-yellow-100"}}),O=new R({props:{data:[{x:90,y:70},{x:90,y:250}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),le=new $e({props:{x:90,y:170,width:55,height:25,text:"1 \\times 1",fontSize:15,type:"latex",class:"fill-green-100"}}),Y=new R({props:{data:[{x:0,y:180},{x:390,y:180}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),ae=new R({props:{data:[{x:40,y:180},{x:40,y:90}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),X=new R({props:{data:[{x:0,y:70},{x:105,y:70}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),j=new R({props:{data:[{x:120,y:70},{x:120,y:20},{x:155,y:20}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),se=new R({props:{data:[{x:260,y:70},{x:350,y:70},{x:350,y:160}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),Z=new R({props:{data:[{x:120,y:70},{x:120,y:120},{x:155,y:120}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),B=new R({props:{data:[{x:220,y:20},{x:260,y:20},{x:260,y:50}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),ee=new R({props:{data:[{x:220,y:120},{x:260,y:120},{x:260,y:90}],strokeWidth:2,dashed:!0,strokeDashArray:"6 6",moving:!0}}),W=new $e({props:{x:40,y:70,width:55,height:25,text:"1 \\times n",fontSize:15,type:"latex",class:"fill-green-100"}}),te=new Ut({props:{x:90,y:70,radius:10,offset:4,class:"fill-red-300"}}),Q=new Ut({props:{x:350,y:180,radius:10,offset:4,class:"fill-red-300"}}),oe=new $e({props:{x:350,y:70,width:55,height:25,text:"1 \\times 1",fontSize:15,type:"latex",class:"fill-green-100"}}),ne=new $e({props:{x:120,y:70,width:15,height:15,class:"fill-blue-100"}}),L=new Jt({props:{x:260,y:70,radius:10,class:"fill-red-300"}}),re=new $e({props:{x:190,y:20,width:55,height:25,text:"tanh",fontSize:15,type:"latex",class:"fill-yellow-100"}}),G=new $e({props:{x:190,y:120,width:55,height:25,text:"\\sigma",fontSize:15,type:"latex",class:"fill-yellow-100"}}),{c(){n=fe("svg"),r=fe("g"),m(e.$$.fragment),m(l.$$.fragment),m(f.$$.fragment),m(a.$$.fragment),m($.$$.fragment),m(z.$$.fragment),m(M.$$.fragment),m(U.$$.fragment),m(F.$$.fragment),m(K.$$.fragment),m(J.$$.fragment),m(O.$$.fragment),m(le.$$.fragment),C=fe("g"),m(Y.$$.fragment),m(ae.$$.fragment),m(X.$$.fragment),m(j.$$.fragment),m(se.$$.fragment),m(Z.$$.fragment),m(B.$$.fragment),m(ee.$$.fragment),m(W.$$.fragment),m(te.$$.fragment),m(Q.$$.fragment),m(oe.$$.fragment),m(ne.$$.fragment),m(L.$$.fragment),m(re.$$.fragment),m(G.$$.fragment),this.h()},l(u){n=he(u,"svg",{viewBox:!0,class:!0});var ie=b(n);r=he(ie,"g",{});var D=b(r);c(e.$$.fragment,D),c(l.$$.fragment,D),c(f.$$.fragment,D),c(a.$$.fragment,D),c($.$$.fragment,D),c(z.$$.fragment,D),c(M.$$.fragment,D),c(U.$$.fragment,D),c(F.$$.fragment,D),c(K.$$.fragment,D),c(J.$$.fragment,D),D.forEach(s),c(O.$$.fragment,ie),c(le.$$.fragment,ie),C=he(ie,"g",{transform:!0});var A=b(C);c(Y.$$.fragment,A),c(ae.$$.fragment,A),c(X.$$.fragment,A),c(j.$$.fragment,A),c(se.$$.fragment,A),c(Z.$$.fragment,A),c(B.$$.fragment,A),c(ee.$$.fragment,A),c(W.$$.fragment,A),c(te.$$.fragment,A),c(Q.$$.fragment,A),c(oe.$$.fragment,A),c(ne.$$.fragment,A),c(L.$$.fragment,A),c(re.$$.fragment,A),c(G.$$.fragment,A),A.forEach(s),ie.forEach(s),this.h()},h(){v(C,"transform","translate(0 200)"),v(n,"viewBox","0 0 400 400"),v(n,"class","border")},m(u,ie){h(u,n,ie),N(n,r),p(e,r,null),p(l,r,null),p(f,r,null),p(a,r,null),p($,r,null),p(z,r,null),p(M,r,null),p(U,r,null),p(F,r,null),p(K,r,null),p(J,r,null),p(O,n,null),p(le,n,null),N(n,C),p(Y,C,null),p(ae,C,null),p(X,C,null),p(j,C,null),p(se,C,null),p(Z,C,null),p(B,C,null),p(ee,C,null),p(W,C,null),p(te,C,null),p(Q,C,null),p(oe,C,null),p(ne,C,null),p(L,C,null),p(re,C,null),p(G,C,null),me=!0},p:st,i(u){me||(_(e.$$.fragment,u),_(l.$$.fragment,u),_(f.$$.fragment,u),_(a.$$.fragment,u),_($.$$.fragment,u),_(z.$$.fragment,u),_(M.$$.fragment,u),_(U.$$.fragment,u),_(F.$$.fragment,u),_(K.$$.fragment,u),_(J.$$.fragment,u),_(O.$$.fragment,u),_(le.$$.fragment,u),_(Y.$$.fragment,u),_(ae.$$.fragment,u),_(X.$$.fragment,u),_(j.$$.fragment,u),_(se.$$.fragment,u),_(Z.$$.fragment,u),_(B.$$.fragment,u),_(ee.$$.fragment,u),_(W.$$.fragment,u),_(te.$$.fragment,u),_(Q.$$.fragment,u),_(oe.$$.fragment,u),_(ne.$$.fragment,u),_(L.$$.fragment,u),_(re.$$.fragment,u),_(G.$$.fragment,u),me=!0)},o(u){d(e.$$.fragment,u),d(l.$$.fragment,u),d(f.$$.fragment,u),d(a.$$.fragment,u),d($.$$.fragment,u),d(z.$$.fragment,u),d(M.$$.fragment,u),d(U.$$.fragment,u),d(F.$$.fragment,u),d(K.$$.fragment,u),d(J.$$.fragment,u),d(O.$$.fragment,u),d(le.$$.fragment,u),d(Y.$$.fragment,u),d(ae.$$.fragment,u),d(X.$$.fragment,u),d(j.$$.fragment,u),d(se.$$.fragment,u),d(Z.$$.fragment,u),d(B.$$.fragment,u),d(ee.$$.fragment,u),d(W.$$.fragment,u),d(te.$$.fragment,u),d(Q.$$.fragment,u),d(oe.$$.fragment,u),d(ne.$$.fragment,u),d(L.$$.fragment,u),d(re.$$.fragment,u),d(G.$$.fragment,u),me=!1},d(u){u&&s(n),g(e),g(l),g(f),g(a),g($),g(z),g(M),g(U),g(F),g(K),g(J),g(O),g(le),g(Y),g(ae),g(X),g(j),g(se),g(Z),g(B),g(ee),g(W),g(te),g(Q),g(oe),g(ne),g(L),g(re),g(G)}}}function Hn(o){let n;return{c(){n=x("n \\times n")},l(r){n=y(r,"n \\times n")},m(r,e){h(r,n,e)},d(r){r&&s(n)}}}function qn(o){let n;return{c(){n=x("p")},l(r){n=y(r,"p")},m(r,e){h(r,n,e)},d(r){r&&s(n)}}}function In(o){let n;return{c(){n=x("\\tanh")},l(r){n=y(r,"\\tanh")},m(r,e){h(r,n,e)},d(r){r&&s(n)}}}function Rn(o){let n;return{c(){n=x("\\sigma")},l(r){n=y(r,"\\sigma")},m(r,e){h(r,n,e)},d(r){r&&s(n)}}}function Fn(o){let n;return{c(){n=x("\\tanh")},l(r){n=y(r,"\\tanh")},m(r,e){h(r,n,e)},d(r){r&&s(n)}}}function Kn(o){let n,r,e,l,f,a,$,z,M,U,F,K,J,O,le,C,Y,ae,X,j,se,Z,B,ee,W,te,Q,oe,ne,L,re,G,me,u,ie,D,A,ot,ue,Tt,pe,Mt,_e,Et,it,Se,Dt,ft,de,ht,ge,ut,Be,St,$t,ve,mt,we,ct,We,Bt,pt,Te,_t,Le,dt,Ge,Wt,gt,Ve,Lt,vt,ke,wt,V,Gt,xe,Vt,ye,Ht,be,qt,ze,It,Ne,Rt,kt,He,Ft,xt,qe,Kt,yt,Me,bt,Ie,Ot,zt,Ee,De,Qt,Nt,Re,Ct;return z=new Yt({props:{$$slots:{default:[An]},$$scope:{ctx:o}}}),M=new Nn({props:{id:1,type:"reference"}}),B=new At({props:{$$slots:{default:[Pn]},$$scope:{ctx:o}}}),W=new lt({props:{maxWidth:"250px",$$slots:{default:[Tn]},$$scope:{ctx:o}}}),L=new At({props:{$$slots:{default:[Mn]},$$scope:{ctx:o}}}),G=new lt({props:{maxWidth:"250px",$$slots:{default:[En]},$$scope:{ctx:o}}}),A=new jt({props:{code:`class MaskedConvolution(nn.Module):
    def __init__(self, in_channels, out_channels, mask, dilation=1):
        super().__init__()
        kernel_size = mask.shape
        padding = tuple([dilation * (size - 1) // 2 for size in kernel_size])

        self.conv = nn.Conv2d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=kernel_size,
            padding=padding,
            dilation=dilation,
        )
        self.register_buffer("mask", mask)

    def forward(self, x):
        with torch.no_grad():
            self.conv.weight *= self.mask
        return self.conv(x)`}}),pe=new Yt({props:{$$slots:{default:[Dn]},$$scope:{ctx:o}}}),_e=new Yt({props:{$$slots:{default:[Sn]},$$scope:{ctx:o}}}),de=new At({props:{$$slots:{default:[Bn]},$$scope:{ctx:o}}}),ge=new lt({props:{maxWidth:"250px",$$slots:{default:[Wn]},$$scope:{ctx:o}}}),ve=new At({props:{$$slots:{default:[Ln]},$$scope:{ctx:o}}}),we=new lt({props:{maxWidth:"250px",$$slots:{default:[Gn]},$$scope:{ctx:o}}}),Te=new jt({props:{code:`class VerticalStackConvolution(MaskedConvolution):
    def __init__(
        self, in_channels, out_channels, kernel_size=3, mask_type="B", dilation=1
    ):
        assert mask_type in ["A", "B"]
        mask = torch.ones(kernel_size, kernel_size)
        mask[kernel_size // 2 + 1 :, :] = 0
        if mask_type == "A":
            mask[kernel_size // 2, :] = 0

        super().__init__(in_channels, out_channels, mask, dilation=dilation)


class HorizontalStackConvolution(MaskedConvolution):
    def __init__(
        self, in_channels, out_channels, kernel_size=3, mask_type="B", dilation=1
    ):
        assert mask_type in ["A", "B"]
        mask = torch.ones(1, kernel_size)
        mask[0, kernel_size // 2 + 1 :] = 0
        if mask_type == "A":
            mask[0, kernel_size // 2] = 0
        super().__init__(in_channels, out_channels, mask, dilation=dilation)`}}),ke=new lt({props:{maxWidth:"400px",$$slots:{default:[Vn]},$$scope:{ctx:o}}}),xe=new at({props:{$$slots:{default:[Hn]},$$scope:{ctx:o}}}),ye=new at({props:{$$slots:{default:[qn]},$$scope:{ctx:o}}}),be=new at({props:{$$slots:{default:[In]},$$scope:{ctx:o}}}),ze=new at({props:{$$slots:{default:[Rn]},$$scope:{ctx:o}}}),Ne=new at({props:{$$slots:{default:[Fn]},$$scope:{ctx:o}}}),Me=new jt({props:{code:`class ConditionalGatedResidualBlock(nn.Module):
    def __init__(self, in_channels, kernel_size=3, dilation=1):
        super().__init__()
        self.v = VerticalStackConvolution(
            in_channels,
            out_channels=2 * in_channels,
            kernel_size=kernel_size,
            dilation=dilation,
        )
        self.h = HorizontalStackConvolution(
            in_channels,
            out_channels=2 * in_channels,
            kernel_size=kernel_size,
            dilation=dilation,
        )
        self.v_to_h = nn.Conv2d(2 * in_channels, 2 * in_channels, kernel_size=1)
        self.v_to_res = nn.Conv2d(in_channels, in_channels, kernel_size=1)

        self.v_embedding = nn.Embedding(num_embeddings=10, embedding_dim=in_channels)
        self.h_embedding = nn.Embedding(num_embeddings=10, embedding_dim=in_channels)

    def forward(self, v_prev, h_prev, num_cls):
        # calculate embeddings to condition the model
        v_embedding = self.v_embedding(num_cls).unsqueeze(-1).unsqueeze(-1)
        h_embedding = self.h_embedding(num_cls).unsqueeze(-1).unsqueeze(-1)

        # vertical stack
        v = self.v(v_prev + v_embedding)
        v_f, v_g = v.chunk(2, dim=1)
        v_out = torch.tanh(v_f) * torch.sigmoid(v_g)

        # vertical to horizontal
        v_to_h = self.v_to_h(v)

        # horizontal stack
        h = self.h(h_prev + h_embedding) + v_to_h
        h_f, h_g = h.chunk(2, dim=1)
        h_out = torch.tanh(h_f) * torch.sigmoid(h_g)

        # skip connection
        h_out = self.v_to_res(h_out)
        h_out += h_prev

        return v_out, h_out


class ConditionalGatedPixelCNN(nn.Module):
    def __init__(self, hidden_dim, dilations=[1, 2, 1, 4, 1, 2, 1]):
        super().__init__()
        self.v = VerticalStackConvolution(
            in_channels=1, out_channels=hidden_dim, kernel_size=7, mask_type="A"
        )
        self.h = HorizontalStackConvolution(
            in_channels=1, kernel_size=7, out_channels=hidden_dim, mask_type="A"
        )

        self.gated_residual_blocks = nn.ModuleList(
            [
                ConditionalGatedResidualBlock(
                    hidden_dim, kernel_size=3, dilation=dilation
                )
                for dilation in dilations
            ]
        )

        self.conv = nn.Conv2d(
            in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=1
        )

        # we apply a 256 way softmax
        self.output = nn.Conv2d(in_channels=hidden_dim, out_channels=256, kernel_size=1)

    def forward(self, x, label):
        v = self.v(x)
        h = self.h(x)

        for gated_layer in self.gated_residual_blocks:
            v, h = gated_layer(v, h, label)

        out = self.conv(F.relu(h))
        out = self.output(F.relu(out))
        # from Batch, Classes, Height, Width to Batch, Classes, Channel, Height, Width
        out = out.unsqueeze(dim=2)
        return out`}}),{c(){n=P("h1"),r=x("Gated PixelCNN"),e=w(),l=P("div"),f=w(),a=P("p"),$=x(`Shortly after the initial release of the PixelCNN architecture, DeepMind
    released the `),m(z.$$.fragment),m(M.$$.fragment),U=x(`. The paper introduced several improvements simultaneously, that reduced
    the gap with the recurrent PixelRNN.`),F=w(),K=P("div"),J=w(),O=P("h2"),le=x("Vertical and horizontal Stacks"),C=w(),Y=P("p"),ae=x(`The PixelCNN has a limitation, that is not obvious at first glance. To
    explain that limitation let's remember how a convolutional neural network
    usually works. The very first layer applies convolutions to a tight
    receptive field around a particular pixel. If we apply a 3x3 convolution,
    then the neural network can only look at the immediate surroundings of a
    particular pixel. But as we stack more and more convolutional layers on top
    of each other, the receptive field starts to grow.`),X=w(),j=P("p"),se=x(`In this interactive example we assume that all calculations are considered
    from the perspective of the black pixel, the kernel size is 3x3 and the
    padding is always 1 in order to keep the size of the image constant.`),Z=w(),m(B.$$.fragment),ee=w(),m(W.$$.fragment),te=w(),Q=P("p"),oe=x(`Now let's see how the receptive field grows, once we incorporate masked
    convolutions.`),ne=w(),m(L.$$.fragment),re=w(),m(G.$$.fragment),me=w(),u=P("p"),ie=x(`While the receptive field grows, we are left with a blind spot. Many pixels
    above the black dot are not taken into the account, which will most likely
    deteriorate the performance.`),D=w(),m(A.$$.fragment),ot=w(),ue=P("p"),Tt=x(`To deal with this problem the researchers at DeepMind separated the
    convolution into two distinct stacks: the `),m(pe.$$.fragment),Mt=x(", which processes the pixels above the black pixel and the "),m(_e.$$.fragment),Et=x(", which processes the pixels to the left."),it=w(),Se=P("p"),Dt=x(`You can think about the vertical stack as a regular convolution, that can
    only access the upper half of the image.`),ft=w(),m(de.$$.fragment),ht=w(),m(ge.$$.fragment),ut=w(),Be=P("p"),St=x(`The horizontal stack is a 1d convolution that processes the pixels to the
    left.`),$t=w(),m(ve.$$.fragment),mt=w(),m(we.$$.fragment),ct=w(),We=P("p"),Bt=x("The combination of both produces the desired output."),pt=w(),m(Te.$$.fragment),_t=w(),Le=P("div"),dt=w(),Ge=P("h2"),Wt=x("Gated Architecture"),gt=w(),Ve=P("p"),Lt=x(`The gated PixelCNN architecture was developed in order to close the
    performance gap between the PixelCNN and the RowLSTM. The researcher
    hypothesised, that the multiplicative units from an LSTM can help the model
    to learn more complex patterns and introduced similar units to the
    convolutional layers.`),vt=w(),m(ke.$$.fragment),wt=w(),V=P("p"),Gt=x(`Let's start our discussion with the upper part of the graph: the vertical
    stack. The vertical layer receives the output from the previous vertical
    stack and applies a `),m(xe.$$.fragment),Vt=x(` masked convolution of type 'B',
    such that the mask only looks at the above pixels. The convolution takes in `),m(ye.$$.fragment),Ht=x(`
    feature maps and produces twice that amount as the output. This is done because
    one half goes into the `),m(be.$$.fragment),qt=x(` and the other goes into the sigmoid
    activation `),m(ze.$$.fragment),It=x(`. We multiply both results positionwise. In
    essence we can interpret the sigmoid output as a gate, that decides which
    part of the `),m(Ne.$$.fragment),Rt=x(" output is allowed to flow."),kt=w(),He=P("p"),Ft=x(`The lower part of the graph is the horizontal stack. First we process the
    output from the vertical convolution through a 1x1 convolution and add that
    result to the output of the horizontal convolution. That way the model can
    attend to all above pixels and all pixels to the left. Second we use skip
    connections in the vertical stack in order to facilitate training.`),xt=w(),qe=P("p"),Kt=x(`Lastly the PixelCNN paper focused on conditional models. For example we
    would like to condition the model on the label we would like to produce. As
    we are dealing with MNIST, we could use the numbers 0-9 as an additional
    input to the model, so that it can learn to generate specific numbers on
    demand. This should make it easier for a model to create coherent numbers.`),yt=w(),m(Me.$$.fragment),bt=w(),Ie=P("p"),Ot=x(`If we train our model for 25 epochs we get images similar to those below.
    The quality of the generated images is clearly a lot better than those we
    created in the previous section.`),zt=w(),Ee=P("div"),De=P("img"),Nt=w(),Re=P("div"),this.h()},l(t){n=T(t,"H1",{});var i=b(n);r=y(i,"Gated PixelCNN"),i.forEach(s),e=k(t),l=T(t,"DIV",{class:!0}),b(l).forEach(s),f=k(t),a=T(t,"P",{});var Ce=b(a);$=y(Ce,`Shortly after the initial release of the PixelCNN architecture, DeepMind
    released the `),c(z.$$.fragment,Ce),c(M.$$.fragment,Ce),U=y(Ce,`. The paper introduced several improvements simultaneously, that reduced
    the gap with the recurrent PixelRNN.`),Ce.forEach(s),F=k(t),K=T(t,"DIV",{class:!0}),b(K).forEach(s),J=k(t),O=T(t,"H2",{});var Fe=b(O);le=y(Fe,"Vertical and horizontal Stacks"),Fe.forEach(s),C=k(t),Y=T(t,"P",{});var Ke=b(Y);ae=y(Ke,`The PixelCNN has a limitation, that is not obvious at first glance. To
    explain that limitation let's remember how a convolutional neural network
    usually works. The very first layer applies convolutions to a tight
    receptive field around a particular pixel. If we apply a 3x3 convolution,
    then the neural network can only look at the immediate surroundings of a
    particular pixel. But as we stack more and more convolutional layers on top
    of each other, the receptive field starts to grow.`),Ke.forEach(s),X=k(t),j=T(t,"P",{});var Oe=b(j);se=y(Oe,`In this interactive example we assume that all calculations are considered
    from the perspective of the black pixel, the kernel size is 3x3 and the
    padding is always 1 in order to keep the size of the image constant.`),Oe.forEach(s),Z=k(t),c(B.$$.fragment,t),ee=k(t),c(W.$$.fragment,t),te=k(t),Q=T(t,"P",{});var Ye=b(Q);oe=y(Ye,`Now let's see how the receptive field grows, once we incorporate masked
    convolutions.`),Ye.forEach(s),ne=k(t),c(L.$$.fragment,t),re=k(t),c(G.$$.fragment,t),me=k(t),u=T(t,"P",{});var je=b(u);ie=y(je,`While the receptive field grows, we are left with a blind spot. Many pixels
    above the black dot are not taken into the account, which will most likely
    deteriorate the performance.`),je.forEach(s),D=k(t),c(A.$$.fragment,t),ot=k(t),ue=T(t,"P",{});var ce=b(ue);Tt=y(ce,`To deal with this problem the researchers at DeepMind separated the
    convolution into two distinct stacks: the `),c(pe.$$.fragment,ce),Mt=y(ce,", which processes the pixels above the black pixel and the "),c(_e.$$.fragment,ce),Et=y(ce,", which processes the pixels to the left."),ce.forEach(s),it=k(t),Se=T(t,"P",{});var Qe=b(Se);Dt=y(Qe,`You can think about the vertical stack as a regular convolution, that can
    only access the upper half of the image.`),Qe.forEach(s),ft=k(t),c(de.$$.fragment,t),ht=k(t),c(ge.$$.fragment,t),ut=k(t),Be=T(t,"P",{});var Ue=b(Be);St=y(Ue,`The horizontal stack is a 1d convolution that processes the pixels to the
    left.`),Ue.forEach(s),$t=k(t),c(ve.$$.fragment,t),mt=k(t),c(we.$$.fragment,t),ct=k(t),We=T(t,"P",{});var Je=b(We);Bt=y(Je,"The combination of both produces the desired output."),Je.forEach(s),pt=k(t),c(Te.$$.fragment,t),_t=k(t),Le=T(t,"DIV",{class:!0}),b(Le).forEach(s),dt=k(t),Ge=T(t,"H2",{});var Xe=b(Ge);Wt=y(Xe,"Gated Architecture"),Xe.forEach(s),gt=k(t),Ve=T(t,"P",{});var Ze=b(Ve);Lt=y(Ze,`The gated PixelCNN architecture was developed in order to close the
    performance gap between the PixelCNN and the RowLSTM. The researcher
    hypothesised, that the multiplicative units from an LSTM can help the model
    to learn more complex patterns and introduced similar units to the
    convolutional layers.`),Ze.forEach(s),vt=k(t),c(ke.$$.fragment,t),wt=k(t),V=T(t,"P",{});var I=b(V);Gt=y(I,`Let's start our discussion with the upper part of the graph: the vertical
    stack. The vertical layer receives the output from the previous vertical
    stack and applies a `),c(xe.$$.fragment,I),Vt=y(I,` masked convolution of type 'B',
    such that the mask only looks at the above pixels. The convolution takes in `),c(ye.$$.fragment,I),Ht=y(I,`
    feature maps and produces twice that amount as the output. This is done because
    one half goes into the `),c(be.$$.fragment,I),qt=y(I,` and the other goes into the sigmoid
    activation `),c(ze.$$.fragment,I),It=y(I,`. We multiply both results positionwise. In
    essence we can interpret the sigmoid output as a gate, that decides which
    part of the `),c(Ne.$$.fragment,I),Rt=y(I," output is allowed to flow."),I.forEach(s),kt=k(t),He=T(t,"P",{});var et=b(He);Ft=y(et,`The lower part of the graph is the horizontal stack. First we process the
    output from the vertical convolution through a 1x1 convolution and add that
    result to the output of the horizontal convolution. That way the model can
    attend to all above pixels and all pixels to the left. Second we use skip
    connections in the vertical stack in order to facilitate training.`),et.forEach(s),xt=k(t),qe=T(t,"P",{});var tt=b(qe);Kt=y(tt,`Lastly the PixelCNN paper focused on conditional models. For example we
    would like to condition the model on the label we would like to produce. As
    we are dealing with MNIST, we could use the numbers 0-9 as an additional
    input to the model, so that it can learn to generate specific numbers on
    demand. This should make it easier for a model to create coherent numbers.`),tt.forEach(s),yt=k(t),c(Me.$$.fragment,t),bt=k(t),Ie=T(t,"P",{});var nt=b(Ie);Ot=y(nt,`If we train our model for 25 epochs we get images similar to those below.
    The quality of the generated images is clearly a lot better than those we
    created in the previous section.`),nt.forEach(s),zt=k(t),Ee=T(t,"DIV",{class:!0});var rt=b(Ee);De=T(rt,"IMG",{src:!0,alt:!0,class:!0}),rt.forEach(s),Nt=k(t),Re=T(t,"DIV",{class:!0}),b(Re).forEach(s),this.h()},h(){v(l,"class","separator"),v(K,"class","separator"),v(Le,"class","separator"),yn(De.src,Qt=Cn)||v(De,"src",Qt),v(De,"alt","Generated MNIST Images"),v(De,"class","w-96"),v(Ee,"class","flex justify-center items-center"),v(Re,"class","separator")},m(t,i){h(t,n,i),N(n,r),h(t,e,i),h(t,l,i),h(t,f,i),h(t,a,i),N(a,$),p(z,a,null),p(M,a,null),N(a,U),h(t,F,i),h(t,K,i),h(t,J,i),h(t,O,i),N(O,le),h(t,C,i),h(t,Y,i),N(Y,ae),h(t,X,i),h(t,j,i),N(j,se),h(t,Z,i),p(B,t,i),h(t,ee,i),p(W,t,i),h(t,te,i),h(t,Q,i),N(Q,oe),h(t,ne,i),p(L,t,i),h(t,re,i),p(G,t,i),h(t,me,i),h(t,u,i),N(u,ie),h(t,D,i),p(A,t,i),h(t,ot,i),h(t,ue,i),N(ue,Tt),p(pe,ue,null),N(ue,Mt),p(_e,ue,null),N(ue,Et),h(t,it,i),h(t,Se,i),N(Se,Dt),h(t,ft,i),p(de,t,i),h(t,ht,i),p(ge,t,i),h(t,ut,i),h(t,Be,i),N(Be,St),h(t,$t,i),p(ve,t,i),h(t,mt,i),p(we,t,i),h(t,ct,i),h(t,We,i),N(We,Bt),h(t,pt,i),p(Te,t,i),h(t,_t,i),h(t,Le,i),h(t,dt,i),h(t,Ge,i),N(Ge,Wt),h(t,gt,i),h(t,Ve,i),N(Ve,Lt),h(t,vt,i),p(ke,t,i),h(t,wt,i),h(t,V,i),N(V,Gt),p(xe,V,null),N(V,Vt),p(ye,V,null),N(V,Ht),p(be,V,null),N(V,qt),p(ze,V,null),N(V,It),p(Ne,V,null),N(V,Rt),h(t,kt,i),h(t,He,i),N(He,Ft),h(t,xt,i),h(t,qe,i),N(qe,Kt),h(t,yt,i),p(Me,t,i),h(t,bt,i),h(t,Ie,i),N(Ie,Ot),h(t,zt,i),h(t,Ee,i),N(Ee,De),h(t,Nt,i),h(t,Re,i),Ct=!0},p(t,i){const Ce={};i&1048576&&(Ce.$$scope={dirty:i,ctx:t}),z.$set(Ce);const Fe={};i&1048576&&(Fe.$$scope={dirty:i,ctx:t}),B.$set(Fe);const Ke={};i&1048577&&(Ke.$$scope={dirty:i,ctx:t}),W.$set(Ke);const Oe={};i&1048576&&(Oe.$$scope={dirty:i,ctx:t}),L.$set(Oe);const Ye={};i&1048578&&(Ye.$$scope={dirty:i,ctx:t}),G.$set(Ye);const je={};i&1048576&&(je.$$scope={dirty:i,ctx:t}),pe.$set(je);const ce={};i&1048576&&(ce.$$scope={dirty:i,ctx:t}),_e.$set(ce);const Qe={};i&1048576&&(Qe.$$scope={dirty:i,ctx:t}),de.$set(Qe);const Ue={};i&1048580&&(Ue.$$scope={dirty:i,ctx:t}),ge.$set(Ue);const Je={};i&1048576&&(Je.$$scope={dirty:i,ctx:t}),ve.$set(Je);const Xe={};i&1048584&&(Xe.$$scope={dirty:i,ctx:t}),we.$set(Xe);const Ze={};i&1048576&&(Ze.$$scope={dirty:i,ctx:t}),ke.$set(Ze);const I={};i&1048576&&(I.$$scope={dirty:i,ctx:t}),xe.$set(I);const et={};i&1048576&&(et.$$scope={dirty:i,ctx:t}),ye.$set(et);const tt={};i&1048576&&(tt.$$scope={dirty:i,ctx:t}),be.$set(tt);const nt={};i&1048576&&(nt.$$scope={dirty:i,ctx:t}),ze.$set(nt);const rt={};i&1048576&&(rt.$$scope={dirty:i,ctx:t}),Ne.$set(rt)},i(t){Ct||(_(z.$$.fragment,t),_(M.$$.fragment,t),_(B.$$.fragment,t),_(W.$$.fragment,t),_(L.$$.fragment,t),_(G.$$.fragment,t),_(A.$$.fragment,t),_(pe.$$.fragment,t),_(_e.$$.fragment,t),_(de.$$.fragment,t),_(ge.$$.fragment,t),_(ve.$$.fragment,t),_(we.$$.fragment,t),_(Te.$$.fragment,t),_(ke.$$.fragment,t),_(xe.$$.fragment,t),_(ye.$$.fragment,t),_(be.$$.fragment,t),_(ze.$$.fragment,t),_(Ne.$$.fragment,t),_(Me.$$.fragment,t),Ct=!0)},o(t){d(z.$$.fragment,t),d(M.$$.fragment,t),d(B.$$.fragment,t),d(W.$$.fragment,t),d(L.$$.fragment,t),d(G.$$.fragment,t),d(A.$$.fragment,t),d(pe.$$.fragment,t),d(_e.$$.fragment,t),d(de.$$.fragment,t),d(ge.$$.fragment,t),d(ve.$$.fragment,t),d(we.$$.fragment,t),d(Te.$$.fragment,t),d(ke.$$.fragment,t),d(xe.$$.fragment,t),d(ye.$$.fragment,t),d(be.$$.fragment,t),d(ze.$$.fragment,t),d(Ne.$$.fragment,t),d(Me.$$.fragment,t),Ct=!1},d(t){t&&s(n),t&&s(e),t&&s(l),t&&s(f),t&&s(a),g(z),g(M),t&&s(F),t&&s(K),t&&s(J),t&&s(O),t&&s(C),t&&s(Y),t&&s(X),t&&s(j),t&&s(Z),g(B,t),t&&s(ee),g(W,t),t&&s(te),t&&s(Q),t&&s(ne),g(L,t),t&&s(re),g(G,t),t&&s(me),t&&s(u),t&&s(D),g(A,t),t&&s(ot),t&&s(ue),g(pe),g(_e),t&&s(it),t&&s(Se),t&&s(ft),g(de,t),t&&s(ht),g(ge,t),t&&s(ut),t&&s(Be),t&&s($t),g(ve,t),t&&s(mt),g(we,t),t&&s(ct),t&&s(We),t&&s(pt),g(Te,t),t&&s(_t),t&&s(Le),t&&s(dt),t&&s(Ge),t&&s(gt),t&&s(Ve),t&&s(vt),g(ke,t),t&&s(wt),t&&s(V),g(xe),g(ye),g(be),g(ze),g(Ne),t&&s(kt),t&&s(He),t&&s(xt),t&&s(qe),t&&s(yt),g(Me,t),t&&s(bt),t&&s(Ie),t&&s(zt),t&&s(Ee),t&&s(Nt),t&&s(Re)}}}function On(o){let n,r,e,l,f,a;return e=new bn({props:{$$slots:{default:[Kn]},$$scope:{ctx:o}}}),f=new zn({props:{references:o[4]}}),{c(){n=P("meta"),r=w(),m(e.$$.fragment),l=w(),m(f.$$.fragment),this.h()},l($){const z=xn("svelte-1e21r36",document.head);n=T(z,"META",{name:!0,content:!0}),z.forEach(s),r=k($),c(e.$$.fragment,$),l=k($),c(f.$$.fragment,$),this.h()},h(){document.title="Gated PixelCNN - World4AI",v(n,"name","description"),v(n,"content","The gated PixelCNN model was developed by DeepMind to improve the generative quality of the common PixelCNN. The model utilizes two stacks of masked convolutions and a gated architecture to improve the performance.")},m($,z){N(document.head,n),h($,r,z),p(e,$,z),h($,l,z),p(f,$,z),a=!0},p($,[z]){const M={};z&1048591&&(M.$$scope={dirty:z,ctx:$}),e.$set(M)},i($){a||(_(e.$$.fragment,$),_(f.$$.fragment,$),a=!0)},o($){d(e.$$.fragment,$),d(f.$$.fragment,$),a=!1},d($){s(n),$&&s(r),g(e,$),$&&s(l),g(f,$)}}}const E=4,S=9,H=22,q=5;function pn(o,n,r){let e=Math.abs(n-E),l=Math.abs(o-E);return o===E&&n===E?"black":e<=r&&l<=r?`hsl(10, ${100/Math.max(e,l)+10}%, 50%)`:"none"}function _n(o,n,r){let e=Math.abs(n-E),l=Math.abs(o-E),f=S-o;return o===E&&n===E?"black":e<=r&&l<=r&&n<=E&&n<f?`hsl(10, ${100/Math.max(e,l)+10}%, 50%)`:"none"}function dn(o,n,r){let e=Math.abs(n-E),l=Math.abs(o-E);return o===E&&n===E?"black":e<=r&&l<=r&&n<E?`hsl(10, ${100/Math.max(e,l)+10}%, 50%)`:"none"}function gn(o,n,r){let e=Math.abs(n-E),l=Math.abs(o-E);return o===E&&n===E?"black":e<=r&&l<=r&&o<E&&n===E?`hsl(10, ${100/Math.max(e,l)+10}%, 50%)`:"none"}function Yn(o,n,r){const e=[{author:" van den Oord, AÃ¤ron and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray",title:"Conditional Image Generation with PixelCNN Decoders",year:"2016"}];let l=0,f=0,a=0,$=0;function z(){l===4?r(0,l=0):r(0,l+=1)}function M(){f===4?r(1,f=0):r(1,f+=1)}function U(){a===4?r(2,a=0):r(2,a+=1)}function F(){$===4?r(3,$=0):r(3,$+=1)}return[l,f,a,$,e,z,M,U,F]}class or extends vn{constructor(n){super(),wn(this,n,Yn,On,kn,{})}}export{or as default};
