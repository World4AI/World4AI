import{S as ze,i as Ee,s as We,k as I,a as X,q as f,y as c,W as Be,l as C,h as r,c as q,m as P,r as m,z as d,n as re,N as x,b as l,A as g,g as w,d as v,B as _,C as J,Q as Ae,R as Se}from"../chunks/index.4d92b023.js";import{C as De}from"../chunks/Container.b0705c7b.js";import{L as ee}from"../chunks/Latex.e0b308c0.js";import{H as _e}from"../chunks/Highlight.b7c1de53.js";import{S as Pe}from"../chunks/SvgContainer.f70b5745.js";import{B as G}from"../chunks/Block.059eddcd.js";import{A as fe}from"../chunks/Arrow.ae91874c.js";import{B as Te}from"../chunks/Border.97f6e782.js";function Ie(k){let t;return{c(){t=f("autoencoder")},l(a){t=m(a,"autoencoder")},m(a,n){l(a,t,n)},d(a){a&&r(t)}}}function Xe(k){let t=String.raw`\mathbf{X}`+"",a;return{c(){a=f(t)},l(n){a=m(n,t)},m(n,$){l(n,a,$)},p:J,d(n){n&&r(a)}}}function Ce(k){let t=String.raw`\mathbf{X}'`+"",a;return{c(){a=f(t)},l(n){a=m(n,t)},m(n,$){l(n,a,$)},p:J,d(n){n&&r(a)}}}function qe(k){let t,a,n,$,S,h,T,p,z,o,b,y,E,D,A,O,W;return a=new fe({props:{data:[{x:B+12.5+5,y:90-75},{x:B+80*2-12.5-10,y:90-20}],dashed:!0,strokeDashArray:"4 4",strokeWidth:1.5,moving:!0,speed:50}}),n=new fe({props:{data:[{x:B+12.5+5,y:90+75},{x:B+80*2-12.5-10,y:90+20}],dashed:!0,strokeDashArray:"4 4",strokeWidth:1.5,moving:!0,speed:50}}),$=new fe({props:{data:[{x:B+80*2+12.5+5,y:90-20},{x:B+80*4-12.5-10,y:90-75}],dashed:!0,strokeDashArray:"4 4",strokeWidth:1.5,moving:!0,speed:50}}),S=new fe({props:{data:[{x:B+80*2+12.5+5,y:90+20},{x:B+80*4-12.5-10,y:90+75}],dashed:!0,strokeDashArray:"4 4",strokeWidth:1.5,moving:!0,speed:50}}),h=new G({props:{x:B+0,y:90,width:25,height:150,text:String.raw`\mathbf{X}`,type:"latex",fontSize:"20",color:"var(--main-color-3)"}}),T=new G({props:{x:B+80,y:90,width:25,height:100,color:"var(--main-color-2)"}}),p=new G({props:{x:B+80*2,y:90,width:25,height:40,text:String.raw`\mathbf{z}`,type:"latex",fontSize:"20",color:"var(--main-color-1)"}}),z=new G({props:{x:B+80*3,y:90,width:25,height:100,color:"var(--main-color-2)"}}),o=new G({props:{x:B+80*4,y:90,width:25,height:150,text:String.raw`\mathbf{X'}`,type:"latex",fontSize:"20",color:"var(--main-color-3)"}}),b=new Te({props:{x:10,y:5,width:140,height:180}}),y=new Te({props:{x:250,y:5,width:140,height:180}}),E=new G({props:{x:50,y:230,width:80,height:25,text:"Encoder",fontSize:"15"}}),D=new G({props:{x:200,y:40,width:80,height:20,text:"Bottleneck",fontSize:"12"}}),A=new G({props:{x:350,y:230,width:80,height:25,text:"Decoder",fontSize:"15"}}),{c(){t=Ae("svg"),c(a.$$.fragment),c(n.$$.fragment),c($.$$.fragment),c(S.$$.fragment),c(h.$$.fragment),c(T.$$.fragment),c(p.$$.fragment),c(z.$$.fragment),c(o.$$.fragment),c(b.$$.fragment),c(y.$$.fragment),c(E.$$.fragment),c(D.$$.fragment),c(A.$$.fragment),O=Ae("svg"),this.h()},l(i){t=Se(i,"svg",{viewBox:!0});var u=P(t);d(a.$$.fragment,u),d(n.$$.fragment,u),d($.$$.fragment,u),d(S.$$.fragment,u),d(h.$$.fragment,u),d(T.$$.fragment,u),d(p.$$.fragment,u),d(z.$$.fragment,u),d(o.$$.fragment,u),d(b.$$.fragment,u),d(y.$$.fragment,u),d(E.$$.fragment,u),d(D.$$.fragment,u),d(A.$$.fragment,u),O=Se(u,"svg",{});var te=P(O);te.forEach(r),u.forEach(r),this.h()},h(){re(t,"viewBox","0 0 400 250")},m(i,u){l(i,t,u),g(a,t,null),g(n,t,null),g($,t,null),g(S,t,null),g(h,t,null),g(T,t,null),g(p,t,null),g(z,t,null),g(o,t,null),g(b,t,null),g(y,t,null),g(E,t,null),g(D,t,null),g(A,t,null),x(t,O),W=!0},p:J,i(i){W||(w(a.$$.fragment,i),w(n.$$.fragment,i),w($.$$.fragment,i),w(S.$$.fragment,i),w(h.$$.fragment,i),w(T.$$.fragment,i),w(p.$$.fragment,i),w(z.$$.fragment,i),w(o.$$.fragment,i),w(b.$$.fragment,i),w(y.$$.fragment,i),w(E.$$.fragment,i),w(D.$$.fragment,i),w(A.$$.fragment,i),W=!0)},o(i){v(a.$$.fragment,i),v(n.$$.fragment,i),v($.$$.fragment,i),v(S.$$.fragment,i),v(h.$$.fragment,i),v(T.$$.fragment,i),v(p.$$.fragment,i),v(z.$$.fragment,i),v(o.$$.fragment,i),v(b.$$.fragment,i),v(y.$$.fragment,i),v(E.$$.fragment,i),v(D.$$.fragment,i),v(A.$$.fragment,i),W=!1},d(i){i&&r(t),_(a),_(n),_($),_(S),_(h),_(T),_(p),_(z),_(o),_(b),_(y),_(E),_(D),_(A)}}}function He(k){let t;return{c(){t=f("encoder")},l(a){t=m(a,"encoder")},m(a,n){l(a,t,n)},d(a){a&&r(t)}}}function Le(k){let t;return{c(){t=f("decoder")},l(a){t=m(a,"decoder")},m(a,n){l(a,t,n)},d(a){a&&r(t)}}}function Ve(k){let t=String.raw`\mathbf{X}`+"",a;return{c(){a=f(t)},l(n){a=m(n,t)},m(n,$){l(n,a,$)},p:J,d(n){n&&r(a)}}}function Ye(k){let t=String.raw`\mathbf{z}`+"",a;return{c(){a=f(t)},l(n){a=m(n,t)},m(n,$){l(n,a,$)},p:J,d(n){n&&r(a)}}}function Me(k){let t=String.raw`\mathbf{z}`+"",a;return{c(){a=f(t)},l(n){a=m(n,t)},m(n,$){l(n,a,$)},p:J,d(n){n&&r(a)}}}function Ne(k){let t=String.raw`\mathbf{X'}`+"",a;return{c(){a=f(t)},l(n){a=m(n,t)},m(n,$){l(n,a,$)},p:J,d(n){n&&r(a)}}}function Oe(k){let t,a,n,$,S,h,T,p,z,o,b,y,E,D,A,O,W,i,u,te,oe,H,me,Q,he,R,pe,se,L,ce,j,de,F,ge,ie,K,we,le,U,ve,$e,Z,ue;return n=new _e({props:{$$slots:{default:[Ie]},$$scope:{ctx:k}}}),p=new ee({props:{$$slots:{default:[Xe]},$$scope:{ctx:k}}}),o=new ee({props:{$$slots:{default:[Ce]},$$scope:{ctx:k}}}),E=new Pe({props:{maxWidth:"600px",$$slots:{default:[qe]},$$scope:{ctx:k}}}),W=new _e({props:{$$slots:{default:[He]},$$scope:{ctx:k}}}),u=new _e({props:{$$slots:{default:[Le]},$$scope:{ctx:k}}}),Q=new ee({props:{$$slots:{default:[Ve]},$$scope:{ctx:k}}}),R=new ee({props:{$$slots:{default:[Ye]},$$scope:{ctx:k}}}),j=new ee({props:{$$slots:{default:[Me]},$$scope:{ctx:k}}}),F=new ee({props:{$$slots:{default:[Ne]},$$scope:{ctx:k}}}),{c(){t=I("p"),a=f("An "),c(n.$$.fragment),$=f(" is a neural network architecture, that maps an input into a lower dimensional space and reconstructs the original input from the lower space."),S=X(),h=I("p"),T=f("We use some variable "),c(p.$$.fragment),z=f(" as an input into an autoencoder. This could be a vector input in a fully connected neural network, but an autoencoder is also often used with images in combination with a convolutional neural network, therefore we could be dealing with a matrix. An autoencoder is trained in an unsupervised way, without using any additional labels, specifically the input and the training labels of an autoencoder are identical. So if we use an image as an input, we expect the output of the neural network, "),c(o.$$.fragment),b=f(", to be as close as possible to that input image."),y=X(),c(E.$$.fragment),D=X(),A=I("p"),O=f("The neural network consists of two components: an "),c(W.$$.fragment),i=f(" and a "),c(u.$$.fragment),te=f("."),oe=X(),H=I("p"),me=f("The encoder takes the input image "),c(Q.$$.fragment),he=f(" and produces the latent variable vector "),c(R.$$.fragment),pe=f(". The dimensionality of hidden values keeps decreasing, until arrive at so called bottleneck. By decreasing the dimensionality, we compress the information, that is contained in the input, until we reach the highest compression point with the latent variable."),se=X(),L=I("p"),ce=f("The decoder takes the latent variable vector "),c(j.$$.fragment),de=f(" as an input and tries to uncompress the information into the original space. The neural network has to learn to produce "),c(F.$$.fragment),ge=f(", that is as close as possible to the input. As we squeeze a high dimensional image into a low dimensional vector, the compression is lossy and the output image might lose some detail, but if the network is expressive enough, the loss won't be dramatic."),ie=X(),K=I("p"),we=f("Intuitively we could argue, that the neural network removes all the unnecessary noise, until only the relevant characteristics of the data that are contained in the latent space are left."),le=X(),U=I("p"),ve=f("In our notebook we will use this architecture to actually compress the images into a lower dimensional space. Yet we would like to use an autoencoder in order to generate new images and we can utilize the decoder for that purpose. Think about it, the decoder takes the latent variable vector and produces an image out of it. The problem with this vanilla autoencoder is that we have no built-in mechanism to sample new latent variables from which we could generate the images. A variational autoencoder on the other hand is much better suited as a generative model. We will study and utilze this architecture in the next section."),$e=X(),Z=I("div"),this.h()},l(e){t=C(e,"P",{});var s=P(t);a=m(s,"An "),d(n.$$.fragment,s),$=m(s," is a neural network architecture, that maps an input into a lower dimensional space and reconstructs the original input from the lower space."),s.forEach(r),S=q(e),h=C(e,"P",{});var V=P(h);T=m(V,"We use some variable "),d(p.$$.fragment,V),z=m(V," as an input into an autoencoder. This could be a vector input in a fully connected neural network, but an autoencoder is also often used with images in combination with a convolutional neural network, therefore we could be dealing with a matrix. An autoencoder is trained in an unsupervised way, without using any additional labels, specifically the input and the training labels of an autoencoder are identical. So if we use an image as an input, we expect the output of the neural network, "),d(o.$$.fragment,V),b=m(V,", to be as close as possible to that input image."),V.forEach(r),y=q(e),d(E.$$.fragment,e),D=q(e),A=C(e,"P",{});var Y=P(A);O=m(Y,"The neural network consists of two components: an "),d(W.$$.fragment,Y),i=m(Y," and a "),d(u.$$.fragment,Y),te=m(Y,"."),Y.forEach(r),oe=q(e),H=C(e,"P",{});var M=P(H);me=m(M,"The encoder takes the input image "),d(Q.$$.fragment,M),he=m(M," and produces the latent variable vector "),d(R.$$.fragment,M),pe=m(M,". The dimensionality of hidden values keeps decreasing, until arrive at so called bottleneck. By decreasing the dimensionality, we compress the information, that is contained in the input, until we reach the highest compression point with the latent variable."),M.forEach(r),se=q(e),L=C(e,"P",{});var N=P(L);ce=m(N,"The decoder takes the latent variable vector "),d(j.$$.fragment,N),de=m(N," as an input and tries to uncompress the information into the original space. The neural network has to learn to produce "),d(F.$$.fragment,N),ge=m(N,", that is as close as possible to the input. As we squeeze a high dimensional image into a low dimensional vector, the compression is lossy and the output image might lose some detail, but if the network is expressive enough, the loss won't be dramatic."),N.forEach(r),ie=q(e),K=C(e,"P",{});var ne=P(K);we=m(ne,"Intuitively we could argue, that the neural network removes all the unnecessary noise, until only the relevant characteristics of the data that are contained in the latent space are left."),ne.forEach(r),le=q(e),U=C(e,"P",{});var ae=P(U);ve=m(ae,"In our notebook we will use this architecture to actually compress the images into a lower dimensional space. Yet we would like to use an autoencoder in order to generate new images and we can utilize the decoder for that purpose. Think about it, the decoder takes the latent variable vector and produces an image out of it. The problem with this vanilla autoencoder is that we have no built-in mechanism to sample new latent variables from which we could generate the images. A variational autoencoder on the other hand is much better suited as a generative model. We will study and utilze this architecture in the next section."),ae.forEach(r),$e=q(e),Z=C(e,"DIV",{class:!0}),P(Z).forEach(r),this.h()},h(){re(Z,"class","separator")},m(e,s){l(e,t,s),x(t,a),g(n,t,null),x(t,$),l(e,S,s),l(e,h,s),x(h,T),g(p,h,null),x(h,z),g(o,h,null),x(h,b),l(e,y,s),g(E,e,s),l(e,D,s),l(e,A,s),x(A,O),g(W,A,null),x(A,i),g(u,A,null),x(A,te),l(e,oe,s),l(e,H,s),x(H,me),g(Q,H,null),x(H,he),g(R,H,null),x(H,pe),l(e,se,s),l(e,L,s),x(L,ce),g(j,L,null),x(L,de),g(F,L,null),x(L,ge),l(e,ie,s),l(e,K,s),x(K,we),l(e,le,s),l(e,U,s),x(U,ve),l(e,$e,s),l(e,Z,s),ue=!0},p(e,s){const V={};s&1&&(V.$$scope={dirty:s,ctx:e}),n.$set(V);const Y={};s&1&&(Y.$$scope={dirty:s,ctx:e}),p.$set(Y);const M={};s&1&&(M.$$scope={dirty:s,ctx:e}),o.$set(M);const N={};s&1&&(N.$$scope={dirty:s,ctx:e}),E.$set(N);const ne={};s&1&&(ne.$$scope={dirty:s,ctx:e}),W.$set(ne);const ae={};s&1&&(ae.$$scope={dirty:s,ctx:e}),u.$set(ae);const be={};s&1&&(be.$$scope={dirty:s,ctx:e}),Q.$set(be);const ke={};s&1&&(ke.$$scope={dirty:s,ctx:e}),R.$set(ke);const xe={};s&1&&(xe.$$scope={dirty:s,ctx:e}),j.$set(xe);const ye={};s&1&&(ye.$$scope={dirty:s,ctx:e}),F.$set(ye)},i(e){ue||(w(n.$$.fragment,e),w(p.$$.fragment,e),w(o.$$.fragment,e),w(E.$$.fragment,e),w(W.$$.fragment,e),w(u.$$.fragment,e),w(Q.$$.fragment,e),w(R.$$.fragment,e),w(j.$$.fragment,e),w(F.$$.fragment,e),ue=!0)},o(e){v(n.$$.fragment,e),v(p.$$.fragment,e),v(o.$$.fragment,e),v(E.$$.fragment,e),v(W.$$.fragment,e),v(u.$$.fragment,e),v(Q.$$.fragment,e),v(R.$$.fragment,e),v(j.$$.fragment,e),v(F.$$.fragment,e),ue=!1},d(e){e&&r(t),_(n),e&&r(S),e&&r(h),_(p),_(o),e&&r(y),_(E,e),e&&r(D),e&&r(A),_(W),_(u),e&&r(oe),e&&r(H),_(Q),_(R),e&&r(se),e&&r(L),_(j),_(F),e&&r(ie),e&&r(K),e&&r(le),e&&r(U),e&&r($e),e&&r(Z)}}}function Qe(k){let t,a,n,$,S,h,T,p,z;return p=new De({props:{$$slots:{default:[Oe]},$$scope:{ctx:k}}}),{c(){t=I("meta"),a=X(),n=I("h1"),$=f("Autoencoders"),S=X(),h=I("div"),T=X(),c(p.$$.fragment),this.h()},l(o){const b=Be("svelte-2tiht0",document.head);t=C(b,"META",{name:!0,content:!0}),b.forEach(r),a=q(o),n=C(o,"H1",{});var y=P(n);$=m(y,"Autoencoders"),y.forEach(r),S=q(o),h=C(o,"DIV",{class:!0}),P(h).forEach(r),T=q(o),d(p.$$.fragment,o),this.h()},h(){document.title="World4AI | Deep Learning | Autoencoders ",re(t,"name","description"),re(t,"content","An autoencoder uses an encoder to map its input to latent space and uses a decoder to transform the latent variable back into the original image. The bottleneck is usually a lower dimensional vector that the input space, therefore an autoencoder compresses the input information."),re(h,"class","separator")},m(o,b){x(document.head,t),l(o,a,b),l(o,n,b),x(n,$),l(o,S,b),l(o,h,b),l(o,T,b),g(p,o,b),z=!0},p(o,[b]){const y={};b&1&&(y.$$scope={dirty:b,ctx:o}),p.$set(y)},i(o){z||(w(p.$$.fragment,o),z=!0)},o(o){v(p.$$.fragment,o),z=!1},d(o){r(t),o&&r(a),o&&r(n),o&&r(S),o&&r(h),o&&r(T),_(p,o)}}}const B=40;class et extends ze{constructor(t){super(),Ee(this,t,null,Qe,We,{})}}export{et as default};
