import{S as Hi,i as Ri,s as qi,k as l,a as c,q as s,y as m,W as Zi,l as i,h as t,c as f,m as d,r as n,z as u,n as C,N as a,b as r,A as _,g as w,d as $,B as E}from"../chunks/index.4d92b023.js";import{C as Fi}from"../chunks/Container.b0705c7b.js";import{H as zs}from"../chunks/Highlight.b7c1de53.js";import{A as Vi}from"../chunks/Alert.25a852b3.js";import{P as v}from"../chunks/PythonCode.212ba7a6.js";function Gi(h){let p;return{c(){p=s("batch")},l(b){p=n(b,"batch")},m(b,D){r(b,p,D)},d(b){b&&t(p)}}}function Yi(h){let p;return{c(){p=s("stochastic")},l(b){p=n(b,"stochastic")},m(b,D){r(b,p,D)},d(b){b&&t(p)}}}function Xi(h){let p;return{c(){p=s("Mini-batch")},l(b){p=n(b,"Mini-batch")},m(b,D){r(b,p,D)},d(b){b&&t(p)}}}function Ki(h){let p;return{c(){p=s("epoch")},l(b){p=n(b,"epoch")},m(b,D){r(b,p,D)},d(b){b&&t(p)}}}function Ji(h){let p;return{c(){p=s(`An epoch is the time period, in which all the samples in the dataset
        have been iterated over and used for gradient calculations.`)},l(b){p=n(b,`An epoch is the time period, in which all the samples in the dataset
        have been iterated over and used for gradient calculations.`)},m(b,D){r(b,p,D)},d(b){b&&t(p)}}}function Qi(h){let p,b,D,U,H,x,K,S,O,y,T,R,Na,rt,xa,Sa,kt,Q,Nt,P,Ma,lt,Aa,Wa,it,Ba,ja,dt,Ua,Ha,ct,Ra,qa,ft,Za,Cs,xt,Os,ks,Fa,we,Va,q,Ns,St,xs,Ss,Mt,Ms,As,Ga,$e,Ya,Ee,Ws,Xa,ee,Bs,At,js,Us,Ka,be,Ja,W,Hs,Wt,Rs,qs,Bt,Zs,Fs,jt,Vs,Gs,Qa,te,Ys,ae,Xs,eo,oe,Ks,se,Js,to,ve,ne,Qs,ao,g,en,Ut,tn,an,Ht,on,sn,Rt,nn,rn,qt,ln,dn,Zt,cn,fn,Ft,hn,pn,Vt,mn,un,Gt,_n,wn,oo,ht,$n,so,ye,no,pt,En,ro,De,lo,mt,bn,io,ge,co,Le,vn,fo,B,yn,Yt,Dn,gn,Xt,Ln,Tn,Kt,Pn,In,ho,Te,po,ut,zn,mo,Pe,uo,Ie,Cn,_o,re,On,le,kn,wo,ie,$o,_t,Nn,Eo,ze,bo,Ce,xn,vo,de,Sn,Jt,Mn,An,yo,Oe,Do,wt,Wn,go,Z,Bn,Qt,jn,Un,ce,Hn,Rn,Lo,$t,To,Et,qn,Po,bt,Zn,Io,ke,zo,vt,Fn,Co,Ne,Oo,fe,Vn,ea,Gn,Yn,ko,xe,No,Se,xo,k,Xn,ta,Kn,Jn,aa,Qn,er,oa,tr,ar,sa,or,sr,na,nr,rr,So,Me,Mo,M,lr,ra,ir,dr,la,cr,fr,ia,hr,pr,da,mr,ur,Ao,Ae,Wo,yt,_r,Bo,We,jo,A,wr,ca,$r,Er,fa,br,vr,ha,yr,Dr,pa,gr,Lr,Uo,Be,Ho,Dt,Tr,Ro,je,qo,F,Pr,ma,Ir,zr,ua,Cr,Or,Zo,Ue,Fo,gt,kr,Vo,He,Go,Lt,Nr,Yo,Re,Xo,qe,Ko,Ze,xr,Jo,he,Sr,_a,Mr,Ar,Qo,Fe,es,L,Wr,wa,Br,jr,$a,Ur,Hr,Ea,Rr,qr,ba,Zr,Fr,va,Vr,Gr,ya,Yr,Xr,Da,Kr,Jr,ts,Ve,as,V,Qr,ga,el,tl,La,al,ol,os,Ge,ss,G,sl,Ta,nl,rl,Pa,ll,il,ns,Ye,rs,Xe,ls,Ke,dl,is,pe,cl,Ia,fl,hl,ds,Je,cs,Qe,fs,et,hs,tt,pl,ps,me,ml,za,ul,_l,ms,at,us,ot,_s,st,ws,nt,wl,$s,Tt,Es;return Q=new v({props:{code:h[0]}}),we=new v({props:{code:h[1]}}),$e=new v({props:{code:h[2]}}),be=new v({props:{code:h[3]}}),ae=new zs({props:{$$slots:{default:[Gi]},$$scope:{ctx:h}}}),se=new zs({props:{$$slots:{default:[Yi]},$$scope:{ctx:h}}}),ne=new zs({props:{$$slots:{default:[Xi]},$$scope:{ctx:h}}}),ye=new v({props:{code:h[4]}}),De=new v({props:{code:h[5]}}),ge=new v({props:{code:h[6]}}),Te=new v({props:{code:h[7]}}),Pe=new v({props:{code:h[8]}}),le=new zs({props:{$$slots:{default:[Ki]},$$scope:{ctx:h}}}),ie=new Vi({props:{type:"info",$$slots:{default:[Ji]},$$scope:{ctx:h}}}),ze=new v({props:{code:h[9]}}),Oe=new v({props:{code:h[10]}}),ke=new v({props:{code:h[11]}}),Ne=new v({props:{code:h[12]}}),xe=new v({props:{code:h[13]}}),Se=new v({props:{code:h[14]}}),Me=new v({props:{code:h[15]}}),Ae=new v({props:{code:h[16]}}),We=new v({props:{code:h[17]}}),Be=new v({props:{code:h[18]}}),je=new v({props:{code:h[19]}}),Ue=new v({props:{code:h[20]}}),He=new v({props:{code:h[21]}}),Re=new v({props:{code:h[22]}}),qe=new v({props:{code:h[23]}}),Fe=new v({props:{code:h[24]}}),Ve=new v({props:{code:h[25]}}),Ge=new v({props:{code:h[26]}}),Ye=new v({props:{code:h[27]}}),Xe=new v({props:{code:h[28]}}),Je=new v({props:{code:h[29]}}),Qe=new v({props:{code:h[30]}}),et=new v({props:{code:h[31]}}),at=new v({props:{code:h[32]}}),ot=new v({props:{code:h[33]}}),st=new v({props:{code:h[34]}}),{c(){p=l("p"),b=s(`In the last sections we have shown a very simple implementation of a
        neural network using PyTorch. In reality though PyTorch provides a lot
        of functionalities to make neural network training much more efficient
        and scalable. This section is dedicated to those functionalities.`),D=c(),U=l("div"),H=c(),x=l("h2"),K=s("Data"),S=c(),O=l("p"),y=s(`So far we have looked at very small datasets and were not necessarily
        concerned with how we would manage the data, but deep learning is
        dependent on lots and lots of data and we need to be able to store,
        manage and retrieve the data. When we retrieve the data we need to make
        sure, that we don't go beyond the capacity of our RAM or VRAM (Video
        RAM). PyTorch gives us a flexible way to deal with our data pipeline the
        way we see fit by providing the `),T=l("code"),R=s("Dataset"),Na=s(` and the
        `),rt=l("code"),xa=s("DataLoader"),Sa=s(" classes."),kt=c(),m(Q.$$.fragment),Nt=c(),P=l("p"),Ma=s("The "),lt=l("code"),Aa=s("Dataset"),Wa=s(` object is the PyTorch representation of data.
        When we are dealing with real world data we subclass the
        `),it=l("code"),Ba=s("Dataset"),ja=s(`
        class and overwrite the `),dt=l("code"),Ua=s("__getitem__"),Ha=s(` and the
        `),ct=l("code"),Ra=s("__len__"),qa=s(`
        methods. Below we create a dataset that contains a list of numbers, the
        size of which depends on the size parameter in the
        `),ft=l("code"),Za=s("__init___"),Cs=s(`
        method. The `),xt=l("code"),Os=s("__getitem__"),ks=s(` method implements the logic, which determines
        how the individual element of our data should be returned given only the
        index of data.`),Fa=c(),m(we.$$.fragment),Va=c(),q=l("p"),Ns=s("We use the "),St=l("code"),xs=s("ListDataset"),Ss=s(" to create a "),Mt=l("code"),Ms=s("list"),As=s(` with 100
        elements from 0 to 99.`),Ga=c(),m($e.$$.fragment),Ya=c(),Ee=l("pre"),Ws=s(` 100
 42`),Xa=c(),ee=l("p"),Bs=s(`In practice we could for example use the Dataset to load an image for
        the index received in the `),At=l("code"),js=s("__getitem__"),Us=s(` method. Below is a dummy
        implementation of such a Dataset.`),Ka=c(),m(be.$$.fragment),Ja=c(),W=l("p"),Hs=s("During the training process we only directly interact with the "),Wt=l("code"),Rs=s("DataLoader"),qs=s(`
        object and not with the `),Bt=l("code"),Zs=s("Dataset"),Fs=s(` object. The goal of the
        `),jt=l("code"),Vs=s("DataLoader"),Gs=s(` is to return data in batch sized pieces. Those batches
        can then be used for training or testing purposes. But what exaclty is a
        batch? The batch size tells us what proportion of the whole dataset is going
        to be used to calculate the graedients, before a single gradient descent
        step is taken.`),Qa=c(),te=l("p"),Ys=s(`The approach of using the whole dataset to calculate the gradient is
        called `),m(ae.$$.fragment),Xs=s(` gradient descent. Using the whole dataset
        has the advantage that we get a good estimation for the gradients, yet in
        many cases batch gradient descent is not used in practice. We often have
        to deal with datasets consisting of thousands of features and millions of
        samples. It is not possible to load all that data on the GPU's. Even if it
        was possible, it would take a lot of time to calculate the gradients for
        all the samples in order to take just a single training step.`),eo=c(),oe=l("p"),Ks=s("In "),m(se.$$.fragment),Js=s(` gradient descent we introduce some stochasticity
        by shuffling the dataset randomly and using one sample at a time to calculate
        the gradient and to take a gradient descent step until we have used all samples
        in the dataset. The advantage of stochastic gradient descent is that we do
        not have to wait for the calculation of gradients for all samples, but in
        the process we lose the advantages of parallelization that we get with batch
        gradient descent. When we calculate the gradient based on one sample the
        calculation is going to be off. By iterating over the whole dataset the sum
        of the directions is going to move the weights and biases towards the optimum.
        In fact this behaviour is often seen as advantageous, because theoretically
        the imprecise gradient could potentially push a variable from a local minimum.`),to=c(),ve=l("p"),m(ne.$$.fragment),Qs=s(` gradient descent combines the advantages
        of the stochastic and batch gradient descent. Insdead of using one sample
        at a time ,several samples are utilized to calculate the gradients. Similar
        to the learning rate, the the mini-batch is a hyperparameter and needs to
        be determined by the developer. Usually the size is calculated as a power
        of 2, for example 32, 64, 128 and so on. You just need to remember that the
        batch needs to fit into the memory of your graphics card. The calculation
        of the gradients with mini-batches can be parallelized, because we can distribute
        the samples on different cores of the CPU/GPU. Additionally it has the advantage
        that theoretically our training dataset can be as large as we want.`),ao=c(),g=l("p"),en=s("The "),Ut=l("code"),tn=s("DataLoader"),an=s(` takes several arguments to control the above
        described details. The `),Ht=l("code"),on=s("dataset"),sn=s(` argument expects a
        `),Rt=l("code"),nn=s("Dataset"),rn=s(`
        object that implements the `),qt=l("code"),ln=s("__init__"),dn=s(` and
        `),Zt=l("code"),cn=s("__getitem__"),fn=s(`
        interface. The `),Ft=l("code"),hn=s("batch_size"),pn=s(` parameter determines the size of
        the mini-batch. The default value is 1, which is equal to stochastic
        gradient descent. The `),Vt=l("code"),mn=s("shuffle"),un=s(` parameter is a boolean value,
        that detemines if the dataset will be shuffled at the beginning of the
        iteration process. The default value is `),Gt=l("code"),_n=s("False"),wn=s("."),oo=c(),ht=l("p"),$n=s(`Let's generate a ListDataset with just 5 elements for demonstration
        purposes.`),so=c(),m(ye.$$.fragment),no=c(),pt=l("p"),En=s(`We generate a DataLoader that shuffles the dataset object and returns 2
        samples at a time.`),ro=c(),m(De.$$.fragment),lo=c(),mt=l("p"),bn=s(`Finally we iterate through the DataLoader and receive a batch at a time.
        Once only one object remains, a single element is returned.`),io=c(),m(ge.$$.fragment),co=c(),Le=l("pre"),vn=s(`Batch Nr: 1 Data: tensor([4, 0])
Batch Nr: 2 Data: tensor([3, 1])
Batch Nr: 3 Data: tensor([2])`),fo=c(),B=l("p"),yn=s(`Often we want our batches to always be of equal size. If a batch is too
        small the calculation of the gradient might be too noisy. To avoid that
        we can use the `),Yt=l("code"),Dn=s("drop_last"),gn=s(` argument. The
        `),Xt=l("code"),Ln=s("drop_last"),Tn=s(`
        parameter removes the last batch, if it is less than
        `),Kt=l("code"),Pn=s("batch_size"),In=s(". The argument defaults to False"),ho=c(),m(Te.$$.fragment),po=c(),ut=l("p"),zn=s("When we do the same exercise again, we end up with fewer iterations."),mo=c(),m(Pe.$$.fragment),uo=c(),Ie=l("pre"),Cn=s(`Batch Nr: 1 Data: tensor([0, 2])
Batch Nr: 2 Data: tensor([3, 4])
`),_o=c(),re=l("p"),On=s(`Each sample in the dataset is typically used several times in the
        training process. Each iteration over the whole dataset is called an `),m(le.$$.fragment),kn=s("."),wo=c(),m(ie.$$.fragment),$o=c(),_t=l("p"),Nn=s(`If we want to use several epochs in a training loop, all we have to do
        is to include an additional outer loop.`),Eo=c(),m(ze.$$.fragment),bo=c(),Ce=l("pre"),xn=s(`Epoch Nr: 1 Batch Nr: 1 Data: tensor([2, 1])
Epoch Nr: 1 Batch Nr: 2 Data: tensor([4, 0])
Epoch Nr: 2 Batch Nr: 1 Data: tensor([2, 4])
Epoch Nr: 2 Batch Nr: 2 Data: tensor([3, 1])
`),vo=c(),de=l("p"),Sn=s(`Oftentiems it is useful to get the next batch of data using a separate
        process, while we are still in the process of calculating the gradients.
        The `),Jt=l("code"),Mn=s("num_workers"),An=s(` parameter determines the number of workers,
        that get the data in parallel. The default is 0, which means that only the
        main process is used.`),yo=c(),m(Oe.$$.fragment),Do=c(),wt=l("p"),Wn=s(`We won't notice the speed difference using such a simple example, but
        the speedup with large datasets might be noticable.`),go=c(),Z=l("p"),Bn=s("There are more parameters, that the "),Qt=l("code"),jn=s("DataLoader"),Un=s(` class
        provides. We are not going to cover those just yet, because for the most
        part the usual parameters are sufficient. We will cover the special
        cases when the need arises. If you are faced with a problem that
        requires more control, you can look at the
        `),ce=l("a"),Hn=s("PyTorch documentation"),Rn=s("."),Lo=c(),$t=l("div"),To=c(),Et=l("h2"),qn=s("Training Loop"),Po=c(),bt=l("p"),Zn=s(`The training loop that we implemented when we solved our circular
        problem works just fine, but PyTorch provides much better approaches.
        Once our neural network architectures get more and more complex, we will
        be glad that we are able to utilize a more efficient training approach.`),Io=c(),m(ke.$$.fragment),zo=c(),vt=l("p"),Fn=s(`This time around we explicitly set some parameters as constants. This
        time around we use a much higher number of samples and neurons, to
        demonstrate that PyTorch is able to handle those.`),Co=c(),m(Ne.$$.fragment),Oo=c(),fe=l("p"),Vn=s("We create a simple classification dataset with sklearn and construct a "),ea=l("code"),Gn=s("Dataset"),Yn=s(" object."),ko=c(),m(xe.$$.fragment),No=c(),m(Se.$$.fragment),xo=c(),k=l("p"),Xn=s(`This time around we will start by looking at the desired product, the
        training loop, to understand what we need in order to make our code
        clean, modular and scalable. Instead of calculating one layer after
        another we will calculate our forward pass using a single call to the `),ta=l("code"),Kn=s("model"),Jn=s(`. The model will contain all the matrix multiplications and activation
        functions needed to predict the probability that the features belong to
        a certain class. The `),aa=l("code"),Qn=s("criterion"),er=s(` is essentially a loss
        function, in our case it is the binary cross-entropy. The
        `),oa=l("code"),tr=s("optimizer"),ar=s(`
        loops through all parameters of the model and applies gradient descent
        when we call `),sa=l("code"),or=s("optimizer.step"),sr=s(` and clears all the gradients
        when we call `),na=l("code"),nr=s("optimizer.zero_grad()"),rr=s("."),So=c(),m(Me.$$.fragment),Mo=c(),M=l("p"),lr=s("In order to make our calculations more modular, we will create a "),ra=l("code"),ir=s("Module"),dr=s(`
        class. You can think about a module as a piece of a neural network.
        Usually modules are those pieces of a network, that we use over and over
        again. In essence you create a neural network by defining and stacking
        modules. As we need to apply affine transformations several times, we
        put the logic of a linear layer into a separate class and we call that
        class `),la=l("code"),cr=s("Module"),fr=s(`. This module initializes a weight matrix and a
        bias vector. For easier access at a later point we create an attribute
        `),ia=l("code"),hr=s("parameters"),pr=s(`, which is just a list holding the weights and
        biases. We also implement the `),da=l("code"),mr=s("__call__"),ur=s(` method, which contains
        the logic for the forward pass.`),Ao=c(),m(Ae.$$.fragment),Wo=c(),yt=l("p"),_r=s(`Our model needs an activation function, so we implement a sigmoid
        function.`),Bo=c(),m(We.$$.fragment),jo=c(),A=l("p"),wr=s("The "),ca=l("code"),$r=s("Model"),Er=s(` class is the abstraction of the neural network.
        We will need three fully connected layers, so the model initializes
        three linear modules. In the `),fa=l("code"),br=s("__call__"),vr=s(` method we implement
        forward pass of the neural network. So when we call
        `),ha=l("code"),yr=s("model(features)"),Dr=s(`, the features are processed by the neural
        network, until the last layer is reached. Additionally we implement the
        `),pa=l("code"),gr=s("parameters"),Lr=s(` method, which returns the full list of the parameters
        of the model.`),Uo=c(),m(Be.$$.fragment),Ho=c(),Dt=l("p"),Tr=s(`Below we test the forward pass with random numbers. Applying the forward
        pass of a predefined model should feel more intuitive than our previous
        implementations.`),Ro=c(),m(je.$$.fragment),qo=c(),F=l("p"),Pr=s(`The optimizer class is responsible for applying gradient descent and for
        clearing the gradients. Ours is a simple implementation of stochastic
        (or batch) gradient descent, but PyTorch has many more implementations.
        We will study those in future chapters. Our optimizer class needs the
        learning rate (alpha) and the parameters of the model. When we call `),ma=l("code"),Ir=s("step()"),zr=s(`
        we loop over all parameters and apply gradient descent and when we call
        `),ua=l("code"),Cr=s("zero_grad()"),Or=s(` we clear all the gradients. Notice that the optimizer
        logic works independent of the exact architecture of the model, making the
        code more managable.`),Zo=c(),m(Ue.$$.fragment),Fo=c(),gt=l("p"),kr=s(`Finally we implement the loss function. Once again the calculation of
        the loss is independent of the model or the optimizer. When we change
        one of the components, we do not introduce any breaking changes. If we
        replace the cross-entropy by mean squared error, our training loop will
        still keep working.`),Vo=c(),m(He.$$.fragment),Go=c(),Lt=l("p"),Nr=s("Now we have all components, that are required by our training loop."),Yo=c(),m(Re.$$.fragment),Xo=c(),m(qe.$$.fragment),Ko=c(),Ze=l("pre"),xr=s(`Epoch: 1 Loss: 0.44153448939323425
Epoch: 2 Loss: 0.26614147424697876
Epoch: 3 Loss: 0.1991310715675354
Epoch: 4 Loss: 0.16552086174488068
Epoch: 5 Loss: 0.14674726128578186
Epoch: 6 Loss: 0.13339845836162567
Epoch: 7 Loss: 0.12402357161045074
Epoch: 8 Loss: 0.11728055775165558
Epoch: 9 Loss: 0.11224914342164993
Epoch: 10 Loss: 0.1082562804222107
`),Jo=c(),he=l("p"),Sr=s(`You can probaly guess, that PyTorch provides classes and functions, that
        we implemented above, out of the box. The PyTorch module `),_a=l("code"),Mr=s("torch.nn"),Ar=s(" contains most of the classes and functions, that we will require."),Qo=c(),m(Fe.$$.fragment),es=c(),L=l("p"),Wr=s("When we write custom PyTorch modules we need to subclass "),wa=l("code"),Br=s("nn.Module"),jr=s(`. We need to putall trainable parameters into the
        `),$a=l("code"),Ur=s("nn.parameter.Parameter()"),Hr=s(`
        class. This tells PyTorch to put those tensors into the parameters list
        (which is used by the optimizer) and the tensors are automatically
        tracked for gradient computation. Instad of defining
        `),Ea=l("code"),Rr=s("__call__"),qr=s(`
        as we did before, we define the `),ba=l("code"),Zr=s("forward"),Fr=s(` method. PyTorch
        calls `),va=l("code"),Vr=s("forward"),Gr=s(` automatically, when we call the module
        object. You must never call this method directly, as PyTorch does
        additional calculations during the forward pass, so instead of using
        `),ya=l("code"),Yr=s("module.forward(features)"),Xr=s(`
        use `),Da=l("code"),Kr=s("module(features)"),Jr=s("."),ts=c(),m(Ve.$$.fragment),as=c(),V=l("p"),Qr=s(`The great thing about PyTorch modules is their composability. Earlier
        created modules can be used in subsequent modules. Below for example we
        use the above defined `),ga=l("code"),el=s("Module"),tl=s(` class in the
        `),La=l("code"),al=s("Model"),ol=s(` module. In later chapter we will see how we can create
        blocks of arbitrary complexity using this simple approach.`),os=c(),m(Ge.$$.fragment),ss=c(),G=l("p"),sl=s("PyTorch obviously provides loss functions and optimizers. We will use "),Ta=l("code"),nl=s("BCELoss"),rl=s(`, which calculates the binary cross-entropy loss. Optimizers are
        located in `),Pa=l("code"),ll=s("torch.optim"),il=s(`. For now we will use stochastic
        gradient descent, but there are many more optimizers that we will
        encounter soon.`),ns=c(),m(Ye.$$.fragment),rs=c(),m(Xe.$$.fragment),ls=c(),Ke=l("pre"),dl=s(`Epoch: 1 Loss: 0.4358866512775421
Epoch: 2 Loss: 0.26300883293151855
Epoch: 3 Loss: 0.1951223760843277
Epoch: 4 Loss: 0.16517716646194458
Epoch: 5 Loss: 0.14785249531269073
Epoch: 6 Loss: 0.1351807564496994
Epoch: 7 Loss: 0.12569186091423035
Epoch: 8 Loss: 0.11819736659526825
Epoch: 9 Loss: 0.11242685467004776
Epoch: 10 Loss: 0.10799615830183029
  `),is=c(),pe=l("p"),cl=s(`PyTorch provides a lot of modules out of the box. An affine/linear
        transformation layer is a common procedure, therefore you should use `),Ia=l("code"),fl=s("nn.Linear"),hl=s(" instead of implementing your solutions from scratch."),ds=c(),m(Je.$$.fragment),cs=c(),m(Qe.$$.fragment),fs=c(),m(et.$$.fragment),hs=c(),tt=l("pre"),pl=s(`Epoch: 1 Loss: 0.46121323108673096
Epoch: 2 Loss: 0.345653235912323
Epoch: 3 Loss: 0.26799750328063965
Epoch: 4 Loss: 0.20885568857192993
Epoch: 5 Loss: 0.16782595217227936
Epoch: 6 Loss: 0.14582592248916626
Epoch: 7 Loss: 0.1313050240278244
Epoch: 8 Loss: 0.12312141805887222
Epoch: 9 Loss: 0.11707331985235214
Epoch: 10 Loss: 0.11287659406661987
`),ps=c(),me=l("p"),ml=s(`To finish this chapter let us discuss an additional PyTorch
        convenience.You might have noticed, that all modules and activation
        functions are called one after another, where the output of one module
        (or activation) is used as the input into the next. In that case we can
        pack all modules and activations into a `),za=l("code"),ul=s("nn.Sequential"),_l=s(` object.
        When we call that object, the components will be executed in a sequential
        order.`),ms=c(),m(at.$$.fragment),us=c(),m(ot.$$.fragment),_s=c(),m(st.$$.fragment),ws=c(),nt=l("pre"),wl=s(`Epoch: 1 Loss: 0.4605180025100708
Epoch: 2 Loss: 0.3372548818588257
Epoch: 3 Loss: 0.27341559529304504
Epoch: 4 Loss: 0.22028055787086487
Epoch: 5 Loss: 0.17632894217967987
Epoch: 6 Loss: 0.15047569572925568
Epoch: 7 Loss: 0.1337045431137085
Epoch: 8 Loss: 0.12339214235544205
Epoch: 9 Loss: 0.11565018445253372
Epoch: 10 Loss: 0.11087213456630707
 `),$s=c(),Tt=l("div"),this.h()},l(e){p=i(e,"P",{});var o=d(p);b=n(o,`In the last sections we have shown a very simple implementation of a
        neural network using PyTorch. In reality though PyTorch provides a lot
        of functionalities to make neural network training much more efficient
        and scalable. This section is dedicated to those functionalities.`),o.forEach(t),D=f(e),U=i(e,"DIV",{class:!0}),d(U).forEach(t),H=f(e),x=i(e,"H2",{});var Ca=d(x);K=n(Ca,"Data"),Ca.forEach(t),S=f(e),O=i(e,"P",{});var J=d(O);y=n(J,`So far we have looked at very small datasets and were not necessarily
        concerned with how we would manage the data, but deep learning is
        dependent on lots and lots of data and we need to be able to store,
        manage and retrieve the data. When we retrieve the data we need to make
        sure, that we don't go beyond the capacity of our RAM or VRAM (Video
        RAM). PyTorch gives us a flexible way to deal with our data pipeline the
        way we see fit by providing the `),T=i(J,"CODE",{});var Oa=d(T);R=n(Oa,"Dataset"),Oa.forEach(t),Na=n(J,` and the
        `),rt=i(J,"CODE",{});var ka=d(rt);xa=n(ka,"DataLoader"),ka.forEach(t),Sa=n(J," classes."),J.forEach(t),kt=f(e),u(Q.$$.fragment,e),Nt=f(e),P=i(e,"P",{});var z=d(P);Ma=n(z,"The "),lt=i(z,"CODE",{});var El=d(lt);Aa=n(El,"Dataset"),El.forEach(t),Wa=n(z,` object is the PyTorch representation of data.
        When we are dealing with real world data we subclass the
        `),it=i(z,"CODE",{});var bl=d(it);Ba=n(bl,"Dataset"),bl.forEach(t),ja=n(z,`
        class and overwrite the `),dt=i(z,"CODE",{});var vl=d(dt);Ua=n(vl,"__getitem__"),vl.forEach(t),Ha=n(z,` and the
        `),ct=i(z,"CODE",{});var yl=d(ct);Ra=n(yl,"__len__"),yl.forEach(t),qa=n(z,`
        methods. Below we create a dataset that contains a list of numbers, the
        size of which depends on the size parameter in the
        `),ft=i(z,"CODE",{});var Dl=d(ft);Za=n(Dl,"__init___"),Dl.forEach(t),Cs=n(z,`
        method. The `),xt=i(z,"CODE",{});var gl=d(xt);Os=n(gl,"__getitem__"),gl.forEach(t),ks=n(z,` method implements the logic, which determines
        how the individual element of our data should be returned given only the
        index of data.`),z.forEach(t),Fa=f(e),u(we.$$.fragment,e),Va=f(e),q=i(e,"P",{});var Pt=d(q);Ns=n(Pt,"We use the "),St=i(Pt,"CODE",{});var Ll=d(St);xs=n(Ll,"ListDataset"),Ll.forEach(t),Ss=n(Pt," to create a "),Mt=i(Pt,"CODE",{});var Tl=d(Mt);Ms=n(Tl,"list"),Tl.forEach(t),As=n(Pt,` with 100
        elements from 0 to 99.`),Pt.forEach(t),Ga=f(e),u($e.$$.fragment,e),Ya=f(e),Ee=i(e,"PRE",{class:!0});var Pl=d(Ee);Ws=n(Pl,` 100
 42`),Pl.forEach(t),Xa=f(e),ee=i(e,"P",{});var bs=d(ee);Bs=n(bs,`In practice we could for example use the Dataset to load an image for
        the index received in the `),At=i(bs,"CODE",{});var Il=d(At);js=n(Il,"__getitem__"),Il.forEach(t),Us=n(bs,` method. Below is a dummy
        implementation of such a Dataset.`),bs.forEach(t),Ka=f(e),u(be.$$.fragment,e),Ja=f(e),W=i(e,"P",{});var ue=d(W);Hs=n(ue,"During the training process we only directly interact with the "),Wt=i(ue,"CODE",{});var zl=d(Wt);Rs=n(zl,"DataLoader"),zl.forEach(t),qs=n(ue,`
        object and not with the `),Bt=i(ue,"CODE",{});var Cl=d(Bt);Zs=n(Cl,"Dataset"),Cl.forEach(t),Fs=n(ue,` object. The goal of the
        `),jt=i(ue,"CODE",{});var Ol=d(jt);Vs=n(Ol,"DataLoader"),Ol.forEach(t),Gs=n(ue,` is to return data in batch sized pieces. Those batches
        can then be used for training or testing purposes. But what exaclty is a
        batch? The batch size tells us what proportion of the whole dataset is going
        to be used to calculate the graedients, before a single gradient descent
        step is taken.`),ue.forEach(t),Qa=f(e),te=i(e,"P",{});var vs=d(te);Ys=n(vs,`The approach of using the whole dataset to calculate the gradient is
        called `),u(ae.$$.fragment,vs),Xs=n(vs,` gradient descent. Using the whole dataset
        has the advantage that we get a good estimation for the gradients, yet in
        many cases batch gradient descent is not used in practice. We often have
        to deal with datasets consisting of thousands of features and millions of
        samples. It is not possible to load all that data on the GPU's. Even if it
        was possible, it would take a lot of time to calculate the gradients for
        all the samples in order to take just a single training step.`),vs.forEach(t),eo=f(e),oe=i(e,"P",{});var ys=d(oe);Ks=n(ys,"In "),u(se.$$.fragment,ys),Js=n(ys,` gradient descent we introduce some stochasticity
        by shuffling the dataset randomly and using one sample at a time to calculate
        the gradient and to take a gradient descent step until we have used all samples
        in the dataset. The advantage of stochastic gradient descent is that we do
        not have to wait for the calculation of gradients for all samples, but in
        the process we lose the advantages of parallelization that we get with batch
        gradient descent. When we calculate the gradient based on one sample the
        calculation is going to be off. By iterating over the whole dataset the sum
        of the directions is going to move the weights and biases towards the optimum.
        In fact this behaviour is often seen as advantageous, because theoretically
        the imprecise gradient could potentially push a variable from a local minimum.`),ys.forEach(t),to=f(e),ve=i(e,"P",{});var $l=d(ve);u(ne.$$.fragment,$l),Qs=n($l,` gradient descent combines the advantages
        of the stochastic and batch gradient descent. Insdead of using one sample
        at a time ,several samples are utilized to calculate the gradients. Similar
        to the learning rate, the the mini-batch is a hyperparameter and needs to
        be determined by the developer. Usually the size is calculated as a power
        of 2, for example 32, 64, 128 and so on. You just need to remember that the
        batch needs to fit into the memory of your graphics card. The calculation
        of the gradients with mini-batches can be parallelized, because we can distribute
        the samples on different cores of the CPU/GPU. Additionally it has the advantage
        that theoretically our training dataset can be as large as we want.`),$l.forEach(t),ao=f(e),g=i(e,"P",{});var I=d(g);en=n(I,"The "),Ut=i(I,"CODE",{});var kl=d(Ut);tn=n(kl,"DataLoader"),kl.forEach(t),an=n(I,` takes several arguments to control the above
        described details. The `),Ht=i(I,"CODE",{});var Nl=d(Ht);on=n(Nl,"dataset"),Nl.forEach(t),sn=n(I,` argument expects a
        `),Rt=i(I,"CODE",{});var xl=d(Rt);nn=n(xl,"Dataset"),xl.forEach(t),rn=n(I,`
        object that implements the `),qt=i(I,"CODE",{});var Sl=d(qt);ln=n(Sl,"__init__"),Sl.forEach(t),dn=n(I,` and
        `),Zt=i(I,"CODE",{});var Ml=d(Zt);cn=n(Ml,"__getitem__"),Ml.forEach(t),fn=n(I,`
        interface. The `),Ft=i(I,"CODE",{});var Al=d(Ft);hn=n(Al,"batch_size"),Al.forEach(t),pn=n(I,` parameter determines the size of
        the mini-batch. The default value is 1, which is equal to stochastic
        gradient descent. The `),Vt=i(I,"CODE",{});var Wl=d(Vt);mn=n(Wl,"shuffle"),Wl.forEach(t),un=n(I,` parameter is a boolean value,
        that detemines if the dataset will be shuffled at the beginning of the
        iteration process. The default value is `),Gt=i(I,"CODE",{});var Bl=d(Gt);_n=n(Bl,"False"),Bl.forEach(t),wn=n(I,"."),I.forEach(t),oo=f(e),ht=i(e,"P",{});var jl=d(ht);$n=n(jl,`Let's generate a ListDataset with just 5 elements for demonstration
        purposes.`),jl.forEach(t),so=f(e),u(ye.$$.fragment,e),no=f(e),pt=i(e,"P",{});var Ul=d(pt);En=n(Ul,`We generate a DataLoader that shuffles the dataset object and returns 2
        samples at a time.`),Ul.forEach(t),ro=f(e),u(De.$$.fragment,e),lo=f(e),mt=i(e,"P",{});var Hl=d(mt);bn=n(Hl,`Finally we iterate through the DataLoader and receive a batch at a time.
        Once only one object remains, a single element is returned.`),Hl.forEach(t),io=f(e),u(ge.$$.fragment,e),co=f(e),Le=i(e,"PRE",{class:!0});var Rl=d(Le);vn=n(Rl,`Batch Nr: 1 Data: tensor([4, 0])
Batch Nr: 2 Data: tensor([3, 1])
Batch Nr: 3 Data: tensor([2])`),Rl.forEach(t),fo=f(e),B=i(e,"P",{});var _e=d(B);yn=n(_e,`Often we want our batches to always be of equal size. If a batch is too
        small the calculation of the gradient might be too noisy. To avoid that
        we can use the `),Yt=i(_e,"CODE",{});var ql=d(Yt);Dn=n(ql,"drop_last"),ql.forEach(t),gn=n(_e,` argument. The
        `),Xt=i(_e,"CODE",{});var Zl=d(Xt);Ln=n(Zl,"drop_last"),Zl.forEach(t),Tn=n(_e,`
        parameter removes the last batch, if it is less than
        `),Kt=i(_e,"CODE",{});var Fl=d(Kt);Pn=n(Fl,"batch_size"),Fl.forEach(t),In=n(_e,". The argument defaults to False"),_e.forEach(t),ho=f(e),u(Te.$$.fragment,e),po=f(e),ut=i(e,"P",{});var Vl=d(ut);zn=n(Vl,"When we do the same exercise again, we end up with fewer iterations."),Vl.forEach(t),mo=f(e),u(Pe.$$.fragment,e),uo=f(e),Ie=i(e,"PRE",{class:!0});var Gl=d(Ie);Cn=n(Gl,`Batch Nr: 1 Data: tensor([0, 2])
Batch Nr: 2 Data: tensor([3, 4])
`),Gl.forEach(t),_o=f(e),re=i(e,"P",{});var Ds=d(re);On=n(Ds,`Each sample in the dataset is typically used several times in the
        training process. Each iteration over the whole dataset is called an `),u(le.$$.fragment,Ds),kn=n(Ds,"."),Ds.forEach(t),wo=f(e),u(ie.$$.fragment,e),$o=f(e),_t=i(e,"P",{});var Yl=d(_t);Nn=n(Yl,`If we want to use several epochs in a training loop, all we have to do
        is to include an additional outer loop.`),Yl.forEach(t),Eo=f(e),u(ze.$$.fragment,e),bo=f(e),Ce=i(e,"PRE",{class:!0});var Xl=d(Ce);xn=n(Xl,`Epoch Nr: 1 Batch Nr: 1 Data: tensor([2, 1])
Epoch Nr: 1 Batch Nr: 2 Data: tensor([4, 0])
Epoch Nr: 2 Batch Nr: 1 Data: tensor([2, 4])
Epoch Nr: 2 Batch Nr: 2 Data: tensor([3, 1])
`),Xl.forEach(t),vo=f(e),de=i(e,"P",{});var gs=d(de);Sn=n(gs,`Oftentiems it is useful to get the next batch of data using a separate
        process, while we are still in the process of calculating the gradients.
        The `),Jt=i(gs,"CODE",{});var Kl=d(Jt);Mn=n(Kl,"num_workers"),Kl.forEach(t),An=n(gs,` parameter determines the number of workers,
        that get the data in parallel. The default is 0, which means that only the
        main process is used.`),gs.forEach(t),yo=f(e),u(Oe.$$.fragment,e),Do=f(e),wt=i(e,"P",{});var Jl=d(wt);Wn=n(Jl,`We won't notice the speed difference using such a simple example, but
        the speedup with large datasets might be noticable.`),Jl.forEach(t),go=f(e),Z=i(e,"P",{});var It=d(Z);Bn=n(It,"There are more parameters, that the "),Qt=i(It,"CODE",{});var Ql=d(Qt);jn=n(Ql,"DataLoader"),Ql.forEach(t),Un=n(It,` class
        provides. We are not going to cover those just yet, because for the most
        part the usual parameters are sufficient. We will cover the special
        cases when the need arises. If you are faced with a problem that
        requires more control, you can look at the
        `),ce=i(It,"A",{href:!0,target:!0,rel:!0});var ei=d(ce);Hn=n(ei,"PyTorch documentation"),ei.forEach(t),Rn=n(It,"."),It.forEach(t),Lo=f(e),$t=i(e,"DIV",{class:!0}),d($t).forEach(t),To=f(e),Et=i(e,"H2",{});var ti=d(Et);qn=n(ti,"Training Loop"),ti.forEach(t),Po=f(e),bt=i(e,"P",{});var ai=d(bt);Zn=n(ai,`The training loop that we implemented when we solved our circular
        problem works just fine, but PyTorch provides much better approaches.
        Once our neural network architectures get more and more complex, we will
        be glad that we are able to utilize a more efficient training approach.`),ai.forEach(t),Io=f(e),u(ke.$$.fragment,e),zo=f(e),vt=i(e,"P",{});var oi=d(vt);Fn=n(oi,`This time around we explicitly set some parameters as constants. This
        time around we use a much higher number of samples and neurons, to
        demonstrate that PyTorch is able to handle those.`),oi.forEach(t),Co=f(e),u(Ne.$$.fragment,e),Oo=f(e),fe=i(e,"P",{});var Ls=d(fe);Vn=n(Ls,"We create a simple classification dataset with sklearn and construct a "),ea=i(Ls,"CODE",{});var si=d(ea);Gn=n(si,"Dataset"),si.forEach(t),Yn=n(Ls," object."),Ls.forEach(t),ko=f(e),u(xe.$$.fragment,e),No=f(e),u(Se.$$.fragment,e),xo=f(e),k=i(e,"P",{});var j=d(k);Xn=n(j,`This time around we will start by looking at the desired product, the
        training loop, to understand what we need in order to make our code
        clean, modular and scalable. Instead of calculating one layer after
        another we will calculate our forward pass using a single call to the `),ta=i(j,"CODE",{});var ni=d(ta);Kn=n(ni,"model"),ni.forEach(t),Jn=n(j,`. The model will contain all the matrix multiplications and activation
        functions needed to predict the probability that the features belong to
        a certain class. The `),aa=i(j,"CODE",{});var ri=d(aa);Qn=n(ri,"criterion"),ri.forEach(t),er=n(j,` is essentially a loss
        function, in our case it is the binary cross-entropy. The
        `),oa=i(j,"CODE",{});var li=d(oa);tr=n(li,"optimizer"),li.forEach(t),ar=n(j,`
        loops through all parameters of the model and applies gradient descent
        when we call `),sa=i(j,"CODE",{});var ii=d(sa);or=n(ii,"optimizer.step"),ii.forEach(t),sr=n(j,` and clears all the gradients
        when we call `),na=i(j,"CODE",{});var di=d(na);nr=n(di,"optimizer.zero_grad()"),di.forEach(t),rr=n(j,"."),j.forEach(t),So=f(e),u(Me.$$.fragment,e),Mo=f(e),M=i(e,"P",{});var Y=d(M);lr=n(Y,"In order to make our calculations more modular, we will create a "),ra=i(Y,"CODE",{});var ci=d(ra);ir=n(ci,"Module"),ci.forEach(t),dr=n(Y,`
        class. You can think about a module as a piece of a neural network.
        Usually modules are those pieces of a network, that we use over and over
        again. In essence you create a neural network by defining and stacking
        modules. As we need to apply affine transformations several times, we
        put the logic of a linear layer into a separate class and we call that
        class `),la=i(Y,"CODE",{});var fi=d(la);cr=n(fi,"Module"),fi.forEach(t),fr=n(Y,`. This module initializes a weight matrix and a
        bias vector. For easier access at a later point we create an attribute
        `),ia=i(Y,"CODE",{});var hi=d(ia);hr=n(hi,"parameters"),hi.forEach(t),pr=n(Y,`, which is just a list holding the weights and
        biases. We also implement the `),da=i(Y,"CODE",{});var pi=d(da);mr=n(pi,"__call__"),pi.forEach(t),ur=n(Y,` method, which contains
        the logic for the forward pass.`),Y.forEach(t),Ao=f(e),u(Ae.$$.fragment,e),Wo=f(e),yt=i(e,"P",{});var mi=d(yt);_r=n(mi,`Our model needs an activation function, so we implement a sigmoid
        function.`),mi.forEach(t),Bo=f(e),u(We.$$.fragment,e),jo=f(e),A=i(e,"P",{});var X=d(A);wr=n(X,"The "),ca=i(X,"CODE",{});var ui=d(ca);$r=n(ui,"Model"),ui.forEach(t),Er=n(X,` class is the abstraction of the neural network.
        We will need three fully connected layers, so the model initializes
        three linear modules. In the `),fa=i(X,"CODE",{});var _i=d(fa);br=n(_i,"__call__"),_i.forEach(t),vr=n(X,` method we implement
        forward pass of the neural network. So when we call
        `),ha=i(X,"CODE",{});var wi=d(ha);yr=n(wi,"model(features)"),wi.forEach(t),Dr=n(X,`, the features are processed by the neural
        network, until the last layer is reached. Additionally we implement the
        `),pa=i(X,"CODE",{});var $i=d(pa);gr=n($i,"parameters"),$i.forEach(t),Lr=n(X,` method, which returns the full list of the parameters
        of the model.`),X.forEach(t),Uo=f(e),u(Be.$$.fragment,e),Ho=f(e),Dt=i(e,"P",{});var Ei=d(Dt);Tr=n(Ei,`Below we test the forward pass with random numbers. Applying the forward
        pass of a predefined model should feel more intuitive than our previous
        implementations.`),Ei.forEach(t),Ro=f(e),u(je.$$.fragment,e),qo=f(e),F=i(e,"P",{});var zt=d(F);Pr=n(zt,`The optimizer class is responsible for applying gradient descent and for
        clearing the gradients. Ours is a simple implementation of stochastic
        (or batch) gradient descent, but PyTorch has many more implementations.
        We will study those in future chapters. Our optimizer class needs the
        learning rate (alpha) and the parameters of the model. When we call `),ma=i(zt,"CODE",{});var bi=d(ma);Ir=n(bi,"step()"),bi.forEach(t),zr=n(zt,`
        we loop over all parameters and apply gradient descent and when we call
        `),ua=i(zt,"CODE",{});var vi=d(ua);Cr=n(vi,"zero_grad()"),vi.forEach(t),Or=n(zt,` we clear all the gradients. Notice that the optimizer
        logic works independent of the exact architecture of the model, making the
        code more managable.`),zt.forEach(t),Zo=f(e),u(Ue.$$.fragment,e),Fo=f(e),gt=i(e,"P",{});var yi=d(gt);kr=n(yi,`Finally we implement the loss function. Once again the calculation of
        the loss is independent of the model or the optimizer. When we change
        one of the components, we do not introduce any breaking changes. If we
        replace the cross-entropy by mean squared error, our training loop will
        still keep working.`),yi.forEach(t),Vo=f(e),u(He.$$.fragment,e),Go=f(e),Lt=i(e,"P",{});var Di=d(Lt);Nr=n(Di,"Now we have all components, that are required by our training loop."),Di.forEach(t),Yo=f(e),u(Re.$$.fragment,e),Xo=f(e),u(qe.$$.fragment,e),Ko=f(e),Ze=i(e,"PRE",{class:!0});var gi=d(Ze);xr=n(gi,`Epoch: 1 Loss: 0.44153448939323425
Epoch: 2 Loss: 0.26614147424697876
Epoch: 3 Loss: 0.1991310715675354
Epoch: 4 Loss: 0.16552086174488068
Epoch: 5 Loss: 0.14674726128578186
Epoch: 6 Loss: 0.13339845836162567
Epoch: 7 Loss: 0.12402357161045074
Epoch: 8 Loss: 0.11728055775165558
Epoch: 9 Loss: 0.11224914342164993
Epoch: 10 Loss: 0.1082562804222107
`),gi.forEach(t),Jo=f(e),he=i(e,"P",{});var Ts=d(he);Sr=n(Ts,`You can probaly guess, that PyTorch provides classes and functions, that
        we implemented above, out of the box. The PyTorch module `),_a=i(Ts,"CODE",{});var Li=d(_a);Mr=n(Li,"torch.nn"),Li.forEach(t),Ar=n(Ts," contains most of the classes and functions, that we will require."),Ts.forEach(t),Qo=f(e),u(Fe.$$.fragment,e),es=f(e),L=i(e,"P",{});var N=d(L);Wr=n(N,"When we write custom PyTorch modules we need to subclass "),wa=i(N,"CODE",{});var Ti=d(wa);Br=n(Ti,"nn.Module"),Ti.forEach(t),jr=n(N,`. We need to putall trainable parameters into the
        `),$a=i(N,"CODE",{});var Pi=d($a);Ur=n(Pi,"nn.parameter.Parameter()"),Pi.forEach(t),Hr=n(N,`
        class. This tells PyTorch to put those tensors into the parameters list
        (which is used by the optimizer) and the tensors are automatically
        tracked for gradient computation. Instad of defining
        `),Ea=i(N,"CODE",{});var Ii=d(Ea);Rr=n(Ii,"__call__"),Ii.forEach(t),qr=n(N,`
        as we did before, we define the `),ba=i(N,"CODE",{});var zi=d(ba);Zr=n(zi,"forward"),zi.forEach(t),Fr=n(N,` method. PyTorch
        calls `),va=i(N,"CODE",{});var Ci=d(va);Vr=n(Ci,"forward"),Ci.forEach(t),Gr=n(N,` automatically, when we call the module
        object. You must never call this method directly, as PyTorch does
        additional calculations during the forward pass, so instead of using
        `),ya=i(N,"CODE",{});var Oi=d(ya);Yr=n(Oi,"module.forward(features)"),Oi.forEach(t),Xr=n(N,`
        use `),Da=i(N,"CODE",{});var ki=d(Da);Kr=n(ki,"module(features)"),ki.forEach(t),Jr=n(N,"."),N.forEach(t),ts=f(e),u(Ve.$$.fragment,e),as=f(e),V=i(e,"P",{});var Ct=d(V);Qr=n(Ct,`The great thing about PyTorch modules is their composability. Earlier
        created modules can be used in subsequent modules. Below for example we
        use the above defined `),ga=i(Ct,"CODE",{});var Ni=d(ga);el=n(Ni,"Module"),Ni.forEach(t),tl=n(Ct,` class in the
        `),La=i(Ct,"CODE",{});var xi=d(La);al=n(xi,"Model"),xi.forEach(t),ol=n(Ct,` module. In later chapter we will see how we can create
        blocks of arbitrary complexity using this simple approach.`),Ct.forEach(t),os=f(e),u(Ge.$$.fragment,e),ss=f(e),G=i(e,"P",{});var Ot=d(G);sl=n(Ot,"PyTorch obviously provides loss functions and optimizers. We will use "),Ta=i(Ot,"CODE",{});var Si=d(Ta);nl=n(Si,"BCELoss"),Si.forEach(t),rl=n(Ot,`, which calculates the binary cross-entropy loss. Optimizers are
        located in `),Pa=i(Ot,"CODE",{});var Mi=d(Pa);ll=n(Mi,"torch.optim"),Mi.forEach(t),il=n(Ot,`. For now we will use stochastic
        gradient descent, but there are many more optimizers that we will
        encounter soon.`),Ot.forEach(t),ns=f(e),u(Ye.$$.fragment,e),rs=f(e),u(Xe.$$.fragment,e),ls=f(e),Ke=i(e,"PRE",{class:!0});var Ai=d(Ke);dl=n(Ai,`Epoch: 1 Loss: 0.4358866512775421
Epoch: 2 Loss: 0.26300883293151855
Epoch: 3 Loss: 0.1951223760843277
Epoch: 4 Loss: 0.16517716646194458
Epoch: 5 Loss: 0.14785249531269073
Epoch: 6 Loss: 0.1351807564496994
Epoch: 7 Loss: 0.12569186091423035
Epoch: 8 Loss: 0.11819736659526825
Epoch: 9 Loss: 0.11242685467004776
Epoch: 10 Loss: 0.10799615830183029
  `),Ai.forEach(t),is=f(e),pe=i(e,"P",{});var Ps=d(pe);cl=n(Ps,`PyTorch provides a lot of modules out of the box. An affine/linear
        transformation layer is a common procedure, therefore you should use `),Ia=i(Ps,"CODE",{});var Wi=d(Ia);fl=n(Wi,"nn.Linear"),Wi.forEach(t),hl=n(Ps," instead of implementing your solutions from scratch."),Ps.forEach(t),ds=f(e),u(Je.$$.fragment,e),cs=f(e),u(Qe.$$.fragment,e),fs=f(e),u(et.$$.fragment,e),hs=f(e),tt=i(e,"PRE",{class:!0});var Bi=d(tt);pl=n(Bi,`Epoch: 1 Loss: 0.46121323108673096
Epoch: 2 Loss: 0.345653235912323
Epoch: 3 Loss: 0.26799750328063965
Epoch: 4 Loss: 0.20885568857192993
Epoch: 5 Loss: 0.16782595217227936
Epoch: 6 Loss: 0.14582592248916626
Epoch: 7 Loss: 0.1313050240278244
Epoch: 8 Loss: 0.12312141805887222
Epoch: 9 Loss: 0.11707331985235214
Epoch: 10 Loss: 0.11287659406661987
`),Bi.forEach(t),ps=f(e),me=i(e,"P",{});var Is=d(me);ml=n(Is,`To finish this chapter let us discuss an additional PyTorch
        convenience.You might have noticed, that all modules and activation
        functions are called one after another, where the output of one module
        (or activation) is used as the input into the next. In that case we can
        pack all modules and activations into a `),za=i(Is,"CODE",{});var ji=d(za);ul=n(ji,"nn.Sequential"),ji.forEach(t),_l=n(Is,` object.
        When we call that object, the components will be executed in a sequential
        order.`),Is.forEach(t),ms=f(e),u(at.$$.fragment,e),us=f(e),u(ot.$$.fragment,e),_s=f(e),u(st.$$.fragment,e),ws=f(e),nt=i(e,"PRE",{class:!0});var Ui=d(nt);wl=n(Ui,`Epoch: 1 Loss: 0.4605180025100708
Epoch: 2 Loss: 0.3372548818588257
Epoch: 3 Loss: 0.27341559529304504
Epoch: 4 Loss: 0.22028055787086487
Epoch: 5 Loss: 0.17632894217967987
Epoch: 6 Loss: 0.15047569572925568
Epoch: 7 Loss: 0.1337045431137085
Epoch: 8 Loss: 0.12339214235544205
Epoch: 9 Loss: 0.11565018445253372
Epoch: 10 Loss: 0.11087213456630707
 `),Ui.forEach(t),$s=f(e),Tt=i(e,"DIV",{class:!0}),d(Tt).forEach(t),this.h()},h(){C(U,"class","separator"),C(Ee,"class","text-sm"),C(Le,"class","text-sm"),C(Ie,"class","text-sm"),C(Ce,"class","text-sm"),C(ce,"href","https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"),C(ce,"target","_blank"),C(ce,"rel","noreferrer"),C($t,"class","separator"),C(Ze,"class","text-sm"),C(Ke,"class","text-sm"),C(tt,"class","text-sm"),C(nt,"class","text-sm"),C(Tt,"class","separator")},m(e,o){r(e,p,o),a(p,b),r(e,D,o),r(e,U,o),r(e,H,o),r(e,x,o),a(x,K),r(e,S,o),r(e,O,o),a(O,y),a(O,T),a(T,R),a(O,Na),a(O,rt),a(rt,xa),a(O,Sa),r(e,kt,o),_(Q,e,o),r(e,Nt,o),r(e,P,o),a(P,Ma),a(P,lt),a(lt,Aa),a(P,Wa),a(P,it),a(it,Ba),a(P,ja),a(P,dt),a(dt,Ua),a(P,Ha),a(P,ct),a(ct,Ra),a(P,qa),a(P,ft),a(ft,Za),a(P,Cs),a(P,xt),a(xt,Os),a(P,ks),r(e,Fa,o),_(we,e,o),r(e,Va,o),r(e,q,o),a(q,Ns),a(q,St),a(St,xs),a(q,Ss),a(q,Mt),a(Mt,Ms),a(q,As),r(e,Ga,o),_($e,e,o),r(e,Ya,o),r(e,Ee,o),a(Ee,Ws),r(e,Xa,o),r(e,ee,o),a(ee,Bs),a(ee,At),a(At,js),a(ee,Us),r(e,Ka,o),_(be,e,o),r(e,Ja,o),r(e,W,o),a(W,Hs),a(W,Wt),a(Wt,Rs),a(W,qs),a(W,Bt),a(Bt,Zs),a(W,Fs),a(W,jt),a(jt,Vs),a(W,Gs),r(e,Qa,o),r(e,te,o),a(te,Ys),_(ae,te,null),a(te,Xs),r(e,eo,o),r(e,oe,o),a(oe,Ks),_(se,oe,null),a(oe,Js),r(e,to,o),r(e,ve,o),_(ne,ve,null),a(ve,Qs),r(e,ao,o),r(e,g,o),a(g,en),a(g,Ut),a(Ut,tn),a(g,an),a(g,Ht),a(Ht,on),a(g,sn),a(g,Rt),a(Rt,nn),a(g,rn),a(g,qt),a(qt,ln),a(g,dn),a(g,Zt),a(Zt,cn),a(g,fn),a(g,Ft),a(Ft,hn),a(g,pn),a(g,Vt),a(Vt,mn),a(g,un),a(g,Gt),a(Gt,_n),a(g,wn),r(e,oo,o),r(e,ht,o),a(ht,$n),r(e,so,o),_(ye,e,o),r(e,no,o),r(e,pt,o),a(pt,En),r(e,ro,o),_(De,e,o),r(e,lo,o),r(e,mt,o),a(mt,bn),r(e,io,o),_(ge,e,o),r(e,co,o),r(e,Le,o),a(Le,vn),r(e,fo,o),r(e,B,o),a(B,yn),a(B,Yt),a(Yt,Dn),a(B,gn),a(B,Xt),a(Xt,Ln),a(B,Tn),a(B,Kt),a(Kt,Pn),a(B,In),r(e,ho,o),_(Te,e,o),r(e,po,o),r(e,ut,o),a(ut,zn),r(e,mo,o),_(Pe,e,o),r(e,uo,o),r(e,Ie,o),a(Ie,Cn),r(e,_o,o),r(e,re,o),a(re,On),_(le,re,null),a(re,kn),r(e,wo,o),_(ie,e,o),r(e,$o,o),r(e,_t,o),a(_t,Nn),r(e,Eo,o),_(ze,e,o),r(e,bo,o),r(e,Ce,o),a(Ce,xn),r(e,vo,o),r(e,de,o),a(de,Sn),a(de,Jt),a(Jt,Mn),a(de,An),r(e,yo,o),_(Oe,e,o),r(e,Do,o),r(e,wt,o),a(wt,Wn),r(e,go,o),r(e,Z,o),a(Z,Bn),a(Z,Qt),a(Qt,jn),a(Z,Un),a(Z,ce),a(ce,Hn),a(Z,Rn),r(e,Lo,o),r(e,$t,o),r(e,To,o),r(e,Et,o),a(Et,qn),r(e,Po,o),r(e,bt,o),a(bt,Zn),r(e,Io,o),_(ke,e,o),r(e,zo,o),r(e,vt,o),a(vt,Fn),r(e,Co,o),_(Ne,e,o),r(e,Oo,o),r(e,fe,o),a(fe,Vn),a(fe,ea),a(ea,Gn),a(fe,Yn),r(e,ko,o),_(xe,e,o),r(e,No,o),_(Se,e,o),r(e,xo,o),r(e,k,o),a(k,Xn),a(k,ta),a(ta,Kn),a(k,Jn),a(k,aa),a(aa,Qn),a(k,er),a(k,oa),a(oa,tr),a(k,ar),a(k,sa),a(sa,or),a(k,sr),a(k,na),a(na,nr),a(k,rr),r(e,So,o),_(Me,e,o),r(e,Mo,o),r(e,M,o),a(M,lr),a(M,ra),a(ra,ir),a(M,dr),a(M,la),a(la,cr),a(M,fr),a(M,ia),a(ia,hr),a(M,pr),a(M,da),a(da,mr),a(M,ur),r(e,Ao,o),_(Ae,e,o),r(e,Wo,o),r(e,yt,o),a(yt,_r),r(e,Bo,o),_(We,e,o),r(e,jo,o),r(e,A,o),a(A,wr),a(A,ca),a(ca,$r),a(A,Er),a(A,fa),a(fa,br),a(A,vr),a(A,ha),a(ha,yr),a(A,Dr),a(A,pa),a(pa,gr),a(A,Lr),r(e,Uo,o),_(Be,e,o),r(e,Ho,o),r(e,Dt,o),a(Dt,Tr),r(e,Ro,o),_(je,e,o),r(e,qo,o),r(e,F,o),a(F,Pr),a(F,ma),a(ma,Ir),a(F,zr),a(F,ua),a(ua,Cr),a(F,Or),r(e,Zo,o),_(Ue,e,o),r(e,Fo,o),r(e,gt,o),a(gt,kr),r(e,Vo,o),_(He,e,o),r(e,Go,o),r(e,Lt,o),a(Lt,Nr),r(e,Yo,o),_(Re,e,o),r(e,Xo,o),_(qe,e,o),r(e,Ko,o),r(e,Ze,o),a(Ze,xr),r(e,Jo,o),r(e,he,o),a(he,Sr),a(he,_a),a(_a,Mr),a(he,Ar),r(e,Qo,o),_(Fe,e,o),r(e,es,o),r(e,L,o),a(L,Wr),a(L,wa),a(wa,Br),a(L,jr),a(L,$a),a($a,Ur),a(L,Hr),a(L,Ea),a(Ea,Rr),a(L,qr),a(L,ba),a(ba,Zr),a(L,Fr),a(L,va),a(va,Vr),a(L,Gr),a(L,ya),a(ya,Yr),a(L,Xr),a(L,Da),a(Da,Kr),a(L,Jr),r(e,ts,o),_(Ve,e,o),r(e,as,o),r(e,V,o),a(V,Qr),a(V,ga),a(ga,el),a(V,tl),a(V,La),a(La,al),a(V,ol),r(e,os,o),_(Ge,e,o),r(e,ss,o),r(e,G,o),a(G,sl),a(G,Ta),a(Ta,nl),a(G,rl),a(G,Pa),a(Pa,ll),a(G,il),r(e,ns,o),_(Ye,e,o),r(e,rs,o),_(Xe,e,o),r(e,ls,o),r(e,Ke,o),a(Ke,dl),r(e,is,o),r(e,pe,o),a(pe,cl),a(pe,Ia),a(Ia,fl),a(pe,hl),r(e,ds,o),_(Je,e,o),r(e,cs,o),_(Qe,e,o),r(e,fs,o),_(et,e,o),r(e,hs,o),r(e,tt,o),a(tt,pl),r(e,ps,o),r(e,me,o),a(me,ml),a(me,za),a(za,ul),a(me,_l),r(e,ms,o),_(at,e,o),r(e,us,o),_(ot,e,o),r(e,_s,o),_(st,e,o),r(e,ws,o),r(e,nt,o),a(nt,wl),r(e,$s,o),r(e,Tt,o),Es=!0},p(e,o){const Ca={};o[1]&16&&(Ca.$$scope={dirty:o,ctx:e}),ae.$set(Ca);const J={};o[1]&16&&(J.$$scope={dirty:o,ctx:e}),se.$set(J);const Oa={};o[1]&16&&(Oa.$$scope={dirty:o,ctx:e}),ne.$set(Oa);const ka={};o[1]&16&&(ka.$$scope={dirty:o,ctx:e}),le.$set(ka);const z={};o[1]&16&&(z.$$scope={dirty:o,ctx:e}),ie.$set(z)},i(e){Es||(w(Q.$$.fragment,e),w(we.$$.fragment,e),w($e.$$.fragment,e),w(be.$$.fragment,e),w(ae.$$.fragment,e),w(se.$$.fragment,e),w(ne.$$.fragment,e),w(ye.$$.fragment,e),w(De.$$.fragment,e),w(ge.$$.fragment,e),w(Te.$$.fragment,e),w(Pe.$$.fragment,e),w(le.$$.fragment,e),w(ie.$$.fragment,e),w(ze.$$.fragment,e),w(Oe.$$.fragment,e),w(ke.$$.fragment,e),w(Ne.$$.fragment,e),w(xe.$$.fragment,e),w(Se.$$.fragment,e),w(Me.$$.fragment,e),w(Ae.$$.fragment,e),w(We.$$.fragment,e),w(Be.$$.fragment,e),w(je.$$.fragment,e),w(Ue.$$.fragment,e),w(He.$$.fragment,e),w(Re.$$.fragment,e),w(qe.$$.fragment,e),w(Fe.$$.fragment,e),w(Ve.$$.fragment,e),w(Ge.$$.fragment,e),w(Ye.$$.fragment,e),w(Xe.$$.fragment,e),w(Je.$$.fragment,e),w(Qe.$$.fragment,e),w(et.$$.fragment,e),w(at.$$.fragment,e),w(ot.$$.fragment,e),w(st.$$.fragment,e),Es=!0)},o(e){$(Q.$$.fragment,e),$(we.$$.fragment,e),$($e.$$.fragment,e),$(be.$$.fragment,e),$(ae.$$.fragment,e),$(se.$$.fragment,e),$(ne.$$.fragment,e),$(ye.$$.fragment,e),$(De.$$.fragment,e),$(ge.$$.fragment,e),$(Te.$$.fragment,e),$(Pe.$$.fragment,e),$(le.$$.fragment,e),$(ie.$$.fragment,e),$(ze.$$.fragment,e),$(Oe.$$.fragment,e),$(ke.$$.fragment,e),$(Ne.$$.fragment,e),$(xe.$$.fragment,e),$(Se.$$.fragment,e),$(Me.$$.fragment,e),$(Ae.$$.fragment,e),$(We.$$.fragment,e),$(Be.$$.fragment,e),$(je.$$.fragment,e),$(Ue.$$.fragment,e),$(He.$$.fragment,e),$(Re.$$.fragment,e),$(qe.$$.fragment,e),$(Fe.$$.fragment,e),$(Ve.$$.fragment,e),$(Ge.$$.fragment,e),$(Ye.$$.fragment,e),$(Xe.$$.fragment,e),$(Je.$$.fragment,e),$(Qe.$$.fragment,e),$(et.$$.fragment,e),$(at.$$.fragment,e),$(ot.$$.fragment,e),$(st.$$.fragment,e),Es=!1},d(e){e&&t(p),e&&t(D),e&&t(U),e&&t(H),e&&t(x),e&&t(S),e&&t(O),e&&t(kt),E(Q,e),e&&t(Nt),e&&t(P),e&&t(Fa),E(we,e),e&&t(Va),e&&t(q),e&&t(Ga),E($e,e),e&&t(Ya),e&&t(Ee),e&&t(Xa),e&&t(ee),e&&t(Ka),E(be,e),e&&t(Ja),e&&t(W),e&&t(Qa),e&&t(te),E(ae),e&&t(eo),e&&t(oe),E(se),e&&t(to),e&&t(ve),E(ne),e&&t(ao),e&&t(g),e&&t(oo),e&&t(ht),e&&t(so),E(ye,e),e&&t(no),e&&t(pt),e&&t(ro),E(De,e),e&&t(lo),e&&t(mt),e&&t(io),E(ge,e),e&&t(co),e&&t(Le),e&&t(fo),e&&t(B),e&&t(ho),E(Te,e),e&&t(po),e&&t(ut),e&&t(mo),E(Pe,e),e&&t(uo),e&&t(Ie),e&&t(_o),e&&t(re),E(le),e&&t(wo),E(ie,e),e&&t($o),e&&t(_t),e&&t(Eo),E(ze,e),e&&t(bo),e&&t(Ce),e&&t(vo),e&&t(de),e&&t(yo),E(Oe,e),e&&t(Do),e&&t(wt),e&&t(go),e&&t(Z),e&&t(Lo),e&&t($t),e&&t(To),e&&t(Et),e&&t(Po),e&&t(bt),e&&t(Io),E(ke,e),e&&t(zo),e&&t(vt),e&&t(Co),E(Ne,e),e&&t(Oo),e&&t(fe),e&&t(ko),E(xe,e),e&&t(No),E(Se,e),e&&t(xo),e&&t(k),e&&t(So),E(Me,e),e&&t(Mo),e&&t(M),e&&t(Ao),E(Ae,e),e&&t(Wo),e&&t(yt),e&&t(Bo),E(We,e),e&&t(jo),e&&t(A),e&&t(Uo),E(Be,e),e&&t(Ho),e&&t(Dt),e&&t(Ro),E(je,e),e&&t(qo),e&&t(F),e&&t(Zo),E(Ue,e),e&&t(Fo),e&&t(gt),e&&t(Vo),E(He,e),e&&t(Go),e&&t(Lt),e&&t(Yo),E(Re,e),e&&t(Xo),E(qe,e),e&&t(Ko),e&&t(Ze),e&&t(Jo),e&&t(he),e&&t(Qo),E(Fe,e),e&&t(es),e&&t(L),e&&t(ts),E(Ve,e),e&&t(as),e&&t(V),e&&t(os),E(Ge,e),e&&t(ss),e&&t(G),e&&t(ns),E(Ye,e),e&&t(rs),E(Xe,e),e&&t(ls),e&&t(Ke),e&&t(is),e&&t(pe),e&&t(ds),E(Je,e),e&&t(cs),E(Qe,e),e&&t(fs),E(et,e),e&&t(hs),e&&t(tt),e&&t(ps),e&&t(me),e&&t(ms),E(at,e),e&&t(us),E(ot,e),e&&t(_s),E(st,e),e&&t(ws),e&&t(nt),e&&t($s),e&&t(Tt)}}}function ed(h){let p,b,D,U,H,x,K,S,O;return S=new Fi({props:{$$slots:{default:[Qi]},$$scope:{ctx:h}}}),{c(){p=l("meta"),b=c(),D=l("h1"),U=s("Data, Modules, Optimizers, Losses"),H=c(),x=l("div"),K=c(),m(S.$$.fragment),this.h()},l(y){const T=Zi("svelte-100a60v",document.head);p=i(T,"META",{name:!0,content:!0}),T.forEach(t),b=f(y),D=i(y,"H1",{});var R=d(D);U=n(R,"Data, Modules, Optimizers, Losses"),R.forEach(t),H=f(y),x=i(y,"DIV",{class:!0}),d(x).forEach(t),K=f(y),u(S.$$.fragment,y),this.h()},h(){document.title="PyTorch Data, Modules, Optimizers, Losses - World4AI",C(p,"name","description"),C(p,"content","PyTorch provides Datasets, DataLoaders, Modules, Optimizers and Loss functions for an efficient and scalable code structure. Try to avoid code replications, instead try to use as many built-in functioality as possible."),C(x,"class","separator")},m(y,T){a(document.head,p),r(y,b,T),r(y,D,T),a(D,U),r(y,H,T),r(y,x,T),r(y,K,T),_(S,y,T),O=!0},p(y,T){const R={};T[1]&16&&(R.$$scope={dirty:T,ctx:y}),S.$set(R)},i(y){O||(w(S.$$.fragment,y),O=!0)},o(y){$(S.$$.fragment,y),O=!1},d(y){t(p),y&&t(b),y&&t(D),y&&t(H),y&&t(x),y&&t(K),E(S,y)}}}function td(h){return["from torch.utils.data import Dataset, DataLoader",`class ListDataset(Dataset):
    def __init__(self, size):
        self.data = list(range(size))
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx]`,`dataset = ListDataset(100)
print(len(dataset))
print(dataset[42])`,`class ImagesDataset(Dataset):
    def __init__(self, images_list):
        # list containing information about the image
        # "[/images/image0.jpg", "/images/image1.jpg]"
        self.images_list = images_list
    
    def __len__(self):
        return len(self.images_list)
    
    def __getitem__(self, idx):
        file = self.images_list[idx]
        image = open_image(file)
        return image`,"dataset = ListDataset(5)","dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=True)",`for batch_num, data in enumerate(dataloader):
    print(f'Batch Nr: {batch_num+1} Data: {data}')`,"dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=True, drop_last=True)",`for batch_num, data in enumerate(dataloader):
    print(f'Batch Nr: {batch_num+1} Data: {data}')`,`for epoch_num in range(2):
    for batch_num, data in enumerate(dataloader):
        print(f'Epoch Nr: {epoch_num + 1} Batch Nr: {batch_num+1} Data: {data}')`,"dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=True, drop_last=True, num_workers=4)",`import torch
import sklearn.datasets as datasets
from torch.utils.data import DataLoader, Dataset`,`# parameters
DEVICE = ("cuda:0" if torch.cuda.is_available() else "cpu")
NUM_EPOCHS=10
BATCH_SIZE=1024
NUM_SAMPLES=1_000_000
NUM_FEATURES=10
ALPHA = 0.1

#number of hidden units in the first and second hidden layer
HIDDEN_SIZE_1 = 1000
HIDDEN_SIZE_2 = 500`,`class Data(Dataset):
    def __init__(self):
        X, y = datasets.make_classification(
            n_samples=NUM_SAMPLES, 
            n_features=NUM_FEATURES, 
            n_informative=7, 
            n_classes=2, 
        )

        self.X = torch.from_numpy(X).to(torch.float32)
        self.y = torch.from_numpy(y).to(torch.float32).view(-1, 1)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]`,`dataset = Data()
dataloader = DataLoader(dataset=dataset, 
                              batch_size=BATCH_SIZE,
                              shuffle=True,
                              drop_last=True,
                              num_workers=4)`,`def train(dataloader, model, criterion, optimizer):
    for epoch in range(NUM_EPOCHS):
        loss_sum = 0
        batch_nums = 0
        for batch_idx, (features, labels) in enumerate(dataloader):
            # move features and labels to GPU
            features = features.to(DEVICE)
            labels = labels.to(DEVICE)

            # ------ FORWARD PASS --------
            probs = model(features)

            # ------CALCULATE LOSS --------
            loss = criterion(probs, labels)

            # ------BACKPROPAGATION --------
            loss.backward()

            # ------GRADIENT DESCENT --------
            optimizer.step()

            # ------CLEAR GRADIENTS --------
            optimizer.zero_grad()

            # ------TRACK LOSS --------
            batch_nums += 1
            # detach() removes a tensor from a computational graph 
            # and cpu() move the tensor from GPU to CPU 
            loss_sum += loss.detach().cpu()

        print(f'Epoch: {epoch+1} Loss: {loss_sum / batch_nums}')`,`class Module:
    
    def __init__(self, in_features, out_features):
        self.W = torch.normal(mean=0, 
                              std=0.1, 
                              size=(out_features, in_features), 
                              requires_grad=True, 
                              device=DEVICE, 
                              dtype=torch.float32)
        self.b = torch.zeros(1, 
                             out_features, 
                             requires_grad=True, 
                             device=DEVICE, 
                             dtype=torch.float32)
        self.parameters = [self.W, self.b]
                
    def __call__(self, features):
        return features @ self.W.T + self.b`,`def sigmoid(z):
    return 1 / (1 + torch.exp(-z))`,`class Model:
    
    def __init__(self):
        self.linear_1 = Module(NUM_FEATURES, HIDDEN_SIZE_1)
        self.linear_2 = Module(HIDDEN_SIZE_1, HIDDEN_SIZE_2)
        self.linear_3 = Module(HIDDEN_SIZE_2, 1)
        
    def __call__(self, features):
        x = self.linear_1(features)
        x = sigmoid(x)
        x = self.linear_2(x)
        x = sigmoid(x)
        x = self.linear_3(x)
        x = sigmoid(x)
        return x
    
    def parameters(self):
        parameters = [*self.linear_1.parameters, 
                      *self.linear_2.parameters,
                       *self.linear_3.parameters]
        return parameters`,`features = torch.randn(BATCH_SIZE, NUM_FEATURES).to(DEVICE)
model = Model()
output = model(features)`,`class SGDOptimizer:
    
    def __init__(self, parameters, alpha):
        self.alpha = alpha
        self.parameters = parameters
    
    def step(self):
        with torch.inference_mode():
            for parameter in self.parameters:
                parameter.sub_(self.alpha * parameter.grad)
                
    def zero_grad(self):
        with torch.inference_mode():
            for parameter in self.parameters:
                parameter.grad.zero_()`,`def bce_loss(outputs, labels):
    loss =  -(labels * torch.log(outputs) + (1 - labels) * torch.log(1 - outputs)).mean()
    return loss`,`model = Model()
optimizer = SGDOptimizer(model.parameters(), ALPHA)
criterion = bce_loss`,"train(dataloader, model, criterion, optimizer)","import torch.nn as nn",`class Module(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.W = nn.parameter.Parameter(torch.normal(mean=0, std=0.1, 
                              size=(out_features, in_features)))
        self.b = nn.parameter.Parameter(torch.zeros(1, out_features))

    def forward(self, features):
        return features @ self.W.T + self.b`,`class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear_1 = Module(NUM_FEATURES, HIDDEN_SIZE_1)
        self.linear_2 = Module(HIDDEN_SIZE_1, HIDDEN_SIZE_2)
        self.linear_3 = Module(HIDDEN_SIZE_2, 1)
        
    def forward(self, features):
        x = self.linear_1(features)
        x = torch.sigmoid(x)
        x = self.linear_2(x)
        x = torch.sigmoid(x)
        x = self.linear_3(x)
        x = torch.sigmoid(x)
        return x`,`model = Model().to(DEVICE)
criterion = nn.BCELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=ALPHA)`,"train(dataloader, model, criterion, optimizer)",`class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear_1 = nn.Linear(NUM_FEATURES, HIDDEN_SIZE_1)
        self.linear_2 = nn.Linear(HIDDEN_SIZE_1, HIDDEN_SIZE_2)
        self.linear_3 = nn.Linear(HIDDEN_SIZE_2, 1)
    
    def forward(self, features):
        x = self.linear_1(features)
        x = torch.sigmoid(x)
        x = self.linear_2(x)
        x = torch.sigmoid(x)
        x = self.linear_3(x)
        x = torch.sigmoid(x)
        return x`,`model = Model().to(DEVICE)
criterion = nn.BCELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=ALPHA)`,"train(dataloader, model, criterion, optimizer)",`class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.layers = nn.Sequential(
                nn.Linear(NUM_FEATURES, HIDDEN_SIZE_1),
                nn.Sigmoid(),
                nn.Linear(HIDDEN_SIZE_1, HIDDEN_SIZE_2),
                nn.Sigmoid(),
                nn.Linear(HIDDEN_SIZE_2, 1),
            )
    
    def forward(self, features):
        return self.layers(features)`,`model = Model().to(DEVICE)
criterion = nn.BCELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=ALPHA)`,"train(dataloader, model, criterion, optimizer)"]}class ld extends Hi{constructor(p){super(),Ri(this,p,td,ed,qi,{},null,[-1,-1])}}export{ld as default};
