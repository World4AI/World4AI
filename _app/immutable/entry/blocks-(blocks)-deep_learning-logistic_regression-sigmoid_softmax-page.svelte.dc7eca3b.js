import{S as Xa,i as Ja,s as Ka,k as P,a as p,y as h,W as Qa,l as I,h as f,c as g,z as w,n as Me,N as S,b as l,A as b,g as _,d as c,B as d,w as At,a9 as Vt,q as u,m as O,r as m,aa as Bt,C as A}from"../chunks/index.4d92b023.js";import{C as Za}from"../chunks/Container.b0705c7b.js";import{L as D}from"../chunks/Latex.e0b308c0.js";import{S as Ht}from"../chunks/Slider.93409d64.js";import{H as xa}from"../chunks/Highlight.b7c1de53.js";import{A as Na}from"../chunks/Alert.25a852b3.js";import{P as ut,T as mt}from"../chunks/Ticks.45eca5c5.js";import{C as X}from"../chunks/Circle.f281e92b.js";import{X as pt,Y as gt}from"../chunks/YLabel.182e66a3.js";import{P as ht}from"../chunks/Path.7e6df014.js";function en(r){let n=String.raw`\mathbf{w}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function tn(r){let n;return{c(){n=u("b")},l(s){n=m(s,"b")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function sn(r){let n,s,a,$,v,x,T,k,o,E,W,z;return n=new mt({props:{xTicks:[0,1,2,3,4,5,6,7,8,9,10],yTicks:[0,1],xOffset:-15,yOffset:15}}),a=new pt({props:{text:"Feature",fontSize:15}}),v=new gt({props:{text:"Label",fontSize:15}}),T=new ht({props:{data:[{x:0,y:0},{x:10,y:1}]}}),o=new X({props:{data:r[8][0]}}),W=new X({props:{data:r[8][1],color:"var(--main-color-2)"}}),{c(){h(n.$$.fragment),s=p(),h(a.$$.fragment),$=p(),h(v.$$.fragment),x=p(),h(T.$$.fragment),k=p(),h(o.$$.fragment),E=p(),h(W.$$.fragment)},l(t){w(n.$$.fragment,t),s=g(t),w(a.$$.fragment,t),$=g(t),w(v.$$.fragment,t),x=g(t),w(T.$$.fragment,t),k=g(t),w(o.$$.fragment,t),E=g(t),w(W.$$.fragment,t)},m(t,y){b(n,t,y),l(t,s,y),b(a,t,y),l(t,$,y),b(v,t,y),l(t,x,y),b(T,t,y),l(t,k,y),b(o,t,y),l(t,E,y),b(W,t,y),z=!0},p:A,i(t){z||(_(n.$$.fragment,t),_(a.$$.fragment,t),_(v.$$.fragment,t),_(T.$$.fragment,t),_(o.$$.fragment,t),_(W.$$.fragment,t),z=!0)},o(t){c(n.$$.fragment,t),c(a.$$.fragment,t),c(v.$$.fragment,t),c(T.$$.fragment,t),c(o.$$.fragment,t),c(W.$$.fragment,t),z=!1},d(t){d(n,t),t&&f(s),d(a,t),t&&f($),d(v,t),t&&f(x),d(T,t),t&&f(k),d(o,t),t&&f(E),d(W,t)}}}function an(r){let n,s,a,$,v,x,T,k,o,E,W,z;return n=new mt({props:{xTicks:[-2,-1,0,1,2,3,4,5,6,7,8,9,10,11,12],yTicks:[0,1],xOffset:-15,yOffset:15}}),a=new pt({props:{text:"Feature",fontSize:15}}),v=new gt({props:{text:"Label",fontSize:15}}),T=new ht({props:{data:[{x:-2,y:-.2},{x:12,y:1.2}]}}),o=new X({props:{data:r[7][0]}}),W=new X({props:{data:r[7][1],color:"var(--main-color-2)"}}),{c(){h(n.$$.fragment),s=p(),h(a.$$.fragment),$=p(),h(v.$$.fragment),x=p(),h(T.$$.fragment),k=p(),h(o.$$.fragment),E=p(),h(W.$$.fragment)},l(t){w(n.$$.fragment,t),s=g(t),w(a.$$.fragment,t),$=g(t),w(v.$$.fragment,t),x=g(t),w(T.$$.fragment,t),k=g(t),w(o.$$.fragment,t),E=g(t),w(W.$$.fragment,t)},m(t,y){b(n,t,y),l(t,s,y),b(a,t,y),l(t,$,y),b(v,t,y),l(t,x,y),b(T,t,y),l(t,k,y),b(o,t,y),l(t,E,y),b(W,t,y),z=!0},p:A,i(t){z||(_(n.$$.fragment,t),_(a.$$.fragment,t),_(v.$$.fragment,t),_(T.$$.fragment,t),_(o.$$.fragment,t),_(W.$$.fragment,t),z=!0)},o(t){c(n.$$.fragment,t),c(a.$$.fragment,t),c(v.$$.fragment,t),c(T.$$.fragment,t),c(o.$$.fragment,t),c(W.$$.fragment,t),z=!1},d(t){d(n,t),t&&f(s),d(a,t),t&&f($),d(v,t),t&&f(x),d(T,t),t&&f(k),d(o,t),t&&f(E),d(W,t)}}}function nn(r){let n;return{c(){n=u(`Never use linear regression for classification tasks. There is no built-in
    mechanism that prevents linear regression from producing nonsencical
    probabiilty results.`)},l(s){n=m(s,`Never use linear regression for classification tasks. There is no built-in
    mechanism that prevents linear regression from producing nonsencical
    probabiilty results.`)},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function fn(r){let n=String.raw`
      f(x) = 
      \left\{ 
      \begin{array}{rcl}
      0 & for & x \leq 5 \\ 
      1 & for & x > 5 \\
      \end{array}
      \right.
    `+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function ln(r){let n,s,a,$,v,x,T,k,o,E,W,z;return n=new mt({props:{xTicks:[-2,-1,0,1,2,3,4,5,6,7,8,9,10,11,12],yTicks:[0,1],xOffset:-15,yOffset:15}}),a=new pt({props:{text:"Feature",fontSize:15}}),v=new gt({props:{text:"Label",fontSize:15}}),T=new ht({props:{data:r[9]}}),o=new X({props:{data:r[7][0]}}),W=new X({props:{data:r[7][1],color:"var(--main-color-2)"}}),{c(){h(n.$$.fragment),s=p(),h(a.$$.fragment),$=p(),h(v.$$.fragment),x=p(),h(T.$$.fragment),k=p(),h(o.$$.fragment),E=p(),h(W.$$.fragment)},l(t){w(n.$$.fragment,t),s=g(t),w(a.$$.fragment,t),$=g(t),w(v.$$.fragment,t),x=g(t),w(T.$$.fragment,t),k=g(t),w(o.$$.fragment,t),E=g(t),w(W.$$.fragment,t)},m(t,y){b(n,t,y),l(t,s,y),b(a,t,y),l(t,$,y),b(v,t,y),l(t,x,y),b(T,t,y),l(t,k,y),b(o,t,y),l(t,E,y),b(W,t,y),z=!0},p:A,i(t){z||(_(n.$$.fragment,t),_(a.$$.fragment,t),_(v.$$.fragment,t),_(T.$$.fragment,t),_(o.$$.fragment,t),_(W.$$.fragment,t),z=!0)},o(t){c(n.$$.fragment,t),c(a.$$.fragment,t),c(v.$$.fragment,t),c(T.$$.fragment,t),c(o.$$.fragment,t),c(W.$$.fragment,t),z=!1},d(t){d(n,t),t&&f(s),d(a,t),t&&f($),d(v,t),t&&f(x),d(T,t),t&&f(k),d(o,t),t&&f(E),d(W,t)}}}function rn(r){let n;return{c(){n=u("sigmoid")},l(s){n=m(s,"sigmoid")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function $n(r){let n=String.raw`\sigma(x) = \dfrac{1}{1 + e^{-x}}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function on(r){let n,s,a,$,v,x,T,k;return n=new mt({props:{xTicks:[-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6],yTicks:[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1],xOffset:-15,yOffset:15}}),a=new pt({props:{text:"x",fontSize:10,type:"latex"}}),v=new gt({props:{text:"f(x)",fontSize:10,x:-2,type:"latex"}}),T=new ht({props:{data:r[10]}}),{c(){h(n.$$.fragment),s=p(),h(a.$$.fragment),$=p(),h(v.$$.fragment),x=p(),h(T.$$.fragment)},l(o){w(n.$$.fragment,o),s=g(o),w(a.$$.fragment,o),$=g(o),w(v.$$.fragment,o),x=g(o),w(T.$$.fragment,o)},m(o,E){b(n,o,E),l(o,s,E),b(a,o,E),l(o,$,E),b(v,o,E),l(o,x,E),b(T,o,E),k=!0},p:A,i(o){k||(_(n.$$.fragment,o),_(a.$$.fragment,o),_(v.$$.fragment,o),_(T.$$.fragment,o),k=!0)},o(o){c(n.$$.fragment,o),c(a.$$.fragment,o),c(v.$$.fragment,o),c(T.$$.fragment,o),k=!1},d(o){d(n,o),o&&f(s),d(a,o),o&&f($),d(v,o),o&&f(x),d(T,o)}}}function un(r){let n;return{c(){n=u("\\sigma(x)")},l(s){n=m(s,"\\sigma(x)")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function mn(r){let n=String.raw`z = \mathbf{x} \mathbf{w}^T + b`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function pn(r){let n=String.raw`\hat{y} = \dfrac{1}{1 + e^{-z}}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function gn(r){let n,s,a,$,v;return s=new D({props:{$$slots:{default:[mn]},$$scope:{ctx:r}}}),$=new D({props:{$$slots:{default:[pn]},$$scope:{ctx:r}}}),{c(){n=u(`Logistic regression uses linear regression
    `),h(s.$$.fragment),a=u(` as an input into
    the sigmoid
    `),h($.$$.fragment)},l(x){n=m(x,`Logistic regression uses linear regression
    `),w(s.$$.fragment,x),a=m(x,` as an input into
    the sigmoid
    `),w($.$$.fragment,x)},m(x,T){l(x,n,T),b(s,x,T),l(x,a,T),b($,x,T),v=!0},p(x,T){const k={};T&524288&&(k.$$scope={dirty:T,ctx:x}),s.$set(k);const o={};T&524288&&(o.$$scope={dirty:T,ctx:x}),$.$set(o)},i(x){v||(_(s.$$.fragment,x),_($.$$.fragment,x),v=!0)},o(x){c(s.$$.fragment,x),c($.$$.fragment,x),v=!1},d(x){x&&f(n),d(s,x),x&&f(a),d($,x)}}}function hn(r){let n=String.raw`\mathbf{w}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function wn(r){let n;return{c(){n=u("b")},l(s){n=m(s,"b")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function bn(r){let n=String.raw`\mathbf{y}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function _n(r){let n=String.raw`\mathbf{\hat{y}}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function cn(r){let n,s,a,$,v,x,T,k,o,E,W,z;return n=new mt({props:{xTicks:[-16,-14,-12,-10,-8,-6,-4,-2,0,2,4,6,8,10,12,14,16],yTicks:[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1],xOffset:-15,yOffset:15}}),a=new pt({props:{text:"x",fontSize:10,type:"latex"}}),v=new gt({props:{text:"f(x)",fontSize:10,x:-2,type:"latex"}}),T=new ht({props:{data:r[5]}}),o=new X({props:{data:r[7][0]}}),W=new X({props:{data:r[7][1],color:"var(--main-color-2)"}}),{c(){h(n.$$.fragment),s=p(),h(a.$$.fragment),$=p(),h(v.$$.fragment),x=p(),h(T.$$.fragment),k=p(),h(o.$$.fragment),E=p(),h(W.$$.fragment)},l(t){w(n.$$.fragment,t),s=g(t),w(a.$$.fragment,t),$=g(t),w(v.$$.fragment,t),x=g(t),w(T.$$.fragment,t),k=g(t),w(o.$$.fragment,t),E=g(t),w(W.$$.fragment,t)},m(t,y){b(n,t,y),l(t,s,y),b(a,t,y),l(t,$,y),b(v,t,y),l(t,x,y),b(T,t,y),l(t,k,y),b(o,t,y),l(t,E,y),b(W,t,y),z=!0},p(t,y){const H={};y&32&&(H.data=t[5]),T.$set(H)},i(t){z||(_(n.$$.fragment,t),_(a.$$.fragment,t),_(v.$$.fragment,t),_(T.$$.fragment,t),_(o.$$.fragment,t),_(W.$$.fragment,t),z=!0)},o(t){c(n.$$.fragment,t),c(a.$$.fragment,t),c(v.$$.fragment,t),c(T.$$.fragment,t),c(o.$$.fragment,t),c(W.$$.fragment,t),z=!1},d(t){d(n,t),t&&f(s),d(a,t),t&&f($),d(v,t),t&&f(x),d(T,t),t&&f(k),d(o,t),t&&f(E),d(W,t)}}}function dn(r){let n;return{c(){n=u("w_1")},l(s){n=m(s,"w_1")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function vn(r){let n;return{c(){n=u("w_2")},l(s){n=m(s,"w_2")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function xn(r){let n;return{c(){n=u("b")},l(s){n=m(s,"b")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function yn(r){let n=String.raw`\dfrac{1}{1 + e^{-(x_1w_1 + x_2w_2 + b)}} > 0.5`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function Tn(r){let n=String.raw`\dfrac{1}{1 + e^{-(x_1w_1 + x_2w_2 + b)}} < 0.5`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function Sn(r){let n,s,a,$,v,x,T,k,o,E,W,z;return n=new mt({props:{xTicks:[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1],yTicks:[0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1],xOffset:-15,yOffset:15}}),a=new pt({props:{text:"Feature 1",fontSize:15}}),v=new gt({props:{text:"Feature 2",fontSize:15}}),T=new ht({props:{data:r[6]}}),o=new X({props:{data:r[11][0]}}),W=new X({props:{data:r[11][1],color:"var(--main-color-2)"}}),{c(){h(n.$$.fragment),s=p(),h(a.$$.fragment),$=p(),h(v.$$.fragment),x=p(),h(T.$$.fragment),k=p(),h(o.$$.fragment),E=p(),h(W.$$.fragment)},l(t){w(n.$$.fragment,t),s=g(t),w(a.$$.fragment,t),$=g(t),w(v.$$.fragment,t),x=g(t),w(T.$$.fragment,t),k=g(t),w(o.$$.fragment,t),E=g(t),w(W.$$.fragment,t)},m(t,y){b(n,t,y),l(t,s,y),b(a,t,y),l(t,$,y),b(v,t,y),l(t,x,y),b(T,t,y),l(t,k,y),b(o,t,y),l(t,E,y),b(W,t,y),z=!0},p(t,y){const H={};y&64&&(H.data=t[6]),T.$set(H)},i(t){z||(_(n.$$.fragment,t),_(a.$$.fragment,t),_(v.$$.fragment,t),_(T.$$.fragment,t),_(o.$$.fragment,t),_(W.$$.fragment,t),z=!0)},o(t){c(n.$$.fragment,t),c(a.$$.fragment,t),c(v.$$.fragment,t),c(T.$$.fragment,t),c(o.$$.fragment,t),c(W.$$.fragment,t),z=!1},d(t){d(n,t),t&&f(s),d(a,t),t&&f($),d(v,t),t&&f(x),d(T,t),t&&f(k),d(o,t),t&&f(E),d(W,t)}}}function kn(r){let n;return{c(){n=u("d")},l(s){n=m(s,"d")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function En(r){let n;return{c(){n=u("softmax")},l(s){n=m(s,"softmax")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function Wn(r){let n;return{c(){n=u("d")},l(s){n=m(s,"d")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function zn(r){let n=String.raw`\mathbf{z}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function Pn(r){let n=String.raw`
softmax(\mathbf{z}) = 
softmax
\begin{pmatrix}
\begin{bmatrix}
   z_1  \\
   z_2 \\ 
   z_3 \\ 
   \vdots \\
   z_d 
\end{bmatrix}
\end{pmatrix}
=
\begin{bmatrix}
   p_1 \\
   p_2 \\ 
   p_3 \\ 
   \vdots \\
   p_d
\end{bmatrix}
\\
    `+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function In(r){let n=String.raw`
softmax(\mathbf{z}) = 

\begin{bmatrix}
   0.05 \\
   0.1 \\ 
   0.8 \\ 
   0.05
\end{bmatrix}
\\
    `+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function On(r){let n=String.raw`\mathbf{z}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function Ln(r){let n;return{c(){n=u("logits")},l(s){n=m(s,"logits")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function Dn(r){let n;return{c(){n=u("d")},l(s){n=m(s,"d")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function An(r){let n=String.raw`z = \mathbf{x} \mathbf{w}^T + b`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function Vn(r){let n;return{c(){n=u("k")},l(s){n=m(s,"k")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function Bn(r){let n;return{c(){n=u("d")},l(s){n=m(s,"d")},m(s,a){l(s,n,a)},d(s){s&&f(n)}}}function Hn(r){let n=String.raw`softmax(z_k) = \dfrac{e^{z_k}}{\sum_d e^{z_d}}`+"",s;return{c(){s=u(n)},l(a){s=m(a,n)},m(a,$){l(a,s,$)},p:A,d(a){a&&f(s)}}}function Cn(r){let n,s,a,$,v,x,T,k,o,E,W,z,t,y,H,ne,Ue,ie,wt,Ye,fe,L,V,C,Ne,Ct,le,qt,Re,Ws,Ft,re,Mt,$e,Nt,Ge,jt,Xe,zs,Ut,Je,Ps,Yt,Ke,Is,Rt,oe,Gt,ue,Xt,Qe,Os,Jt,Ze,Kt,et,Ls,Qt,R,Ds,me,As,pe,Vs,Zt,ge,es,he,Bs,we,Hs,ts,tt,Cs,ss,st,qs,as,be,ns,F,Fs,_e,Ms,ce,Ns,de,js,ve,Us,is,xe,fs,J,Ys,ls,K,Rs,rs,B,Gs,ye,Xs,Te,Js,Se,Ks,ke,Qs,Ee,Zs,$s,We,os,Q,ea,us,Z,ta,ms,ee,sa,ps,at,aa,gs,nt,hs,it,na,ws,ft,ia,bs,M,fa,ze,la,Pe,ra,Ie,$a,Oe,oa,_s,Le,cs,lt,ua,ds,De,vs,rt,ma,xs,N,pa,Ae,ga,Ve,ha,Be,wa,He,ba,ys,G,_a,Ce,ca,qe,da,Ts,Fe,Ss,$t,va,ks,ot,Es;k=new D({props:{$$slots:{default:[en]},$$scope:{ctx:r}}}),E=new D({props:{$$slots:{default:[tn]},$$scope:{ctx:r}}}),le=new ut({props:{width:500,height:250,maxWidth:800,domain:[0,10],range:[0,1],$$slots:{default:[sn]},$$scope:{ctx:r}}}),re=new ut({props:{width:500,height:250,maxWidth:800,domain:[-2,12],range:[0,1],$$slots:{default:[an]},$$scope:{ctx:r}}}),$e=new Na({props:{type:"warning",$$slots:{default:[nn]},$$scope:{ctx:r}}}),oe=new D({props:{$$slots:{default:[fn]},$$scope:{ctx:r}}}),ue=new ut({props:{width:500,height:250,maxWidth:800,domain:[-2,12],range:[0,1],$$slots:{default:[ln]},$$scope:{ctx:r}}}),me=new xa({props:{$$slots:{default:[rn]},$$scope:{ctx:r}}}),pe=new D({props:{$$slots:{default:[$n]},$$scope:{ctx:r}}}),ge=new ut({props:{width:500,height:250,maxWidth:800,domain:[-6,6],range:[0,1],$$slots:{default:[on]},$$scope:{ctx:r}}}),we=new D({props:{$$slots:{default:[un]},$$scope:{ctx:r}}}),be=new Na({props:{type:"info",$$slots:{default:[gn]},$$scope:{ctx:r}}}),_e=new D({props:{$$slots:{default:[hn]},$$scope:{ctx:r}}}),ce=new D({props:{$$slots:{default:[wn]},$$scope:{ctx:r}}}),de=new D({props:{$$slots:{default:[bn]},$$scope:{ctx:r}}}),ve=new D({props:{$$slots:{default:[_n]},$$scope:{ctx:r}}}),xe=new ut({props:{width:500,height:250,maxWidth:800,domain:[-16,16],range:[0,1],$$slots:{default:[cn]},$$scope:{ctx:r}}});function ja(e){r[12](e)}let ya={label:"Weight",labelId:"weight",showValue:!0,min:-5,max:5,step:.1};r[0]!==void 0&&(ya.value=r[0]),J=new Ht({props:ya}),At.push(()=>Vt(J,"value",ja));function Ua(e){r[13](e)}let Ta={label:"Bias",labelId:"bias",showValue:!0,min:-30,max:30,step:.1};r[1]!==void 0&&(Ta.value=r[1]),K=new Ht({props:Ta}),At.push(()=>Vt(K,"value",Ua)),ye=new D({props:{$$slots:{default:[dn]},$$scope:{ctx:r}}}),Te=new D({props:{$$slots:{default:[vn]},$$scope:{ctx:r}}}),Se=new D({props:{$$slots:{default:[xn]},$$scope:{ctx:r}}}),ke=new D({props:{$$slots:{default:[yn]},$$scope:{ctx:r}}}),Ee=new D({props:{$$slots:{default:[Tn]},$$scope:{ctx:r}}}),We=new ut({props:{width:500,height:250,maxWidth:800,domain:[0,1],range:[0,1],$$slots:{default:[Sn]},$$scope:{ctx:r}}});function Ya(e){r[14](e)}let Sa={label:"Weight 1",labelId:"w1",showValue:!0,min:-5,max:5,step:.01};r[2]!==void 0&&(Sa.value=r[2]),Q=new Ht({props:Sa}),At.push(()=>Vt(Q,"value",Ya));function Ra(e){r[15](e)}let ka={label:"Weight 2",labelId:"w2",showValue:!0,min:-5,max:5,step:.01};r[3]!==void 0&&(ka.value=r[3]),Z=new Ht({props:ka}),At.push(()=>Vt(Z,"value",Ra));function Ga(e){r[16](e)}let Ea={label:"Bias",labelId:"b",showValue:!0,min:-5,max:5,step:.01};return r[4]!==void 0&&(Ea.value=r[4]),ee=new Ht({props:Ea}),At.push(()=>Vt(ee,"value",Ga)),ze=new D({props:{$$slots:{default:[kn]},$$scope:{ctx:r}}}),Pe=new xa({props:{$$slots:{default:[En]},$$scope:{ctx:r}}}),Ie=new D({props:{$$slots:{default:[Wn]},$$scope:{ctx:r}}}),Oe=new D({props:{$$slots:{default:[zn]},$$scope:{ctx:r}}}),Le=new D({props:{$$slots:{default:[Pn]},$$scope:{ctx:r}}}),De=new D({props:{$$slots:{default:[In]},$$scope:{ctx:r}}}),Ae=new D({props:{$$slots:{default:[On]},$$scope:{ctx:r}}}),Ve=new xa({props:{$$slots:{default:[Ln]},$$scope:{ctx:r}}}),Be=new D({props:{$$slots:{default:[Dn]},$$scope:{ctx:r}}}),He=new D({props:{$$slots:{default:[An]},$$scope:{ctx:r}}}),Ce=new D({props:{$$slots:{default:[Vn]},$$scope:{ctx:r}}}),qe=new D({props:{$$slots:{default:[Bn]},$$scope:{ctx:r}}}),Fe=new D({props:{$$slots:{default:[Hn]},$$scope:{ctx:r}}}),{c(){n=P("h1"),s=u("Sigmoid and Softmax"),a=p(),$=P("div"),v=p(),x=P("p"),T=u(`Let us assume that no classification algorithms have been invented yet and
    that we want to come up with the first classification algorithm. We are
    assuming that there should be learnable parameters `),h(k.$$.fragment),o=u(" and "),h(E.$$.fragment),W=u(` and the output of the model should correspond the probability
    to belong to one of two categories. We will expand our ideas to more categories
    at a later step.`),z=p(),t=P("div"),y=p(),H=P("h2"),ne=u("Linear Regression"),Ue=p(),ie=P("p"),wt=u(`Let's see what happens when we simply use linear regression for
    classification tasks.`),Ye=p(),fe=P("p"),L=u(`Our dataset contains two classes. We assign each of the classes eather the
    label 0 or 1 and we need to train a model that produces values between 0 and
    1. These values can be regarded as probabilities to belong to the category
    1. If the output is 0.3 for example, the model predicts that we are dealing
    with category 1 with 30% probability and with 70% probability we are dealing
    with category 0.`),V=p(),C=P("p"),Ne=u(`We could draw a line just like the one below and at first glance this seems
    to be a reasonable approach. Higher values of some feature correspond to a
    higher probability to belong to the "blue" category and lower values of the
    same feature correspond to a lower probability.`),Ct=p(),h(le.$$.fragment),qt=p(),Re=P("p"),Ws=u(`While linear regression might work during training, when we start facing new
    datapoints we might get into trouble, because our model can theoretically
    produce results that are above 1 or below 0, values that can not be
    interpreted as probabilities.`),Ft=p(),h(re.$$.fragment),Mt=p(),h($e.$$.fragment),Nt=p(),Ge=P("div"),jt=p(),Xe=P("h2"),zs=u("Threshold Activation"),Ut=p(),Je=P("p"),Ps=u(`In our second attempt to construct a classification algorithm we could the
    use original threshold activation function that was used in the McCulloch
    and Pitts neuron.`),Yt=p(),Ke=P("p"),Is=u(`We could use the threshold of 5, which would mean that each sample with a
    feature value above 5 is classified into the "blue" category and the rest
    would be classified as the "red" category.`),Rt=p(),h(oe.$$.fragment),Gt=p(),h(ue.$$.fragment),Xt=p(),Qe=P("p"),Os=u(`While this rule perfectly separates the data into the two categories, the
    threshold function is not differentiable. A non differentiable function
    would prevent us from applying gradient descent, which would limit our
    ability to learn optimal weights and biases.`),Jt=p(),Ze=P("div"),Kt=p(),et=P("h2"),Ls=u("Sigmoid"),Qt=p(),R=P("p"),Ds=u("The "),h(me.$$.fragment),As=u(" function "),h(pe.$$.fragment),Vs=u(` is an S shaped function that is commonly used in machine learning to produce
    probabilites.`),Zt=p(),h(ge.$$.fragment),es=p(),he=P("p"),Bs=u(`The sigmoid does not display problems that we faced with the two approaches
    above.
    `),h(we.$$.fragment),Hs=u(` is always bounded between 0 and 1, no matter how large
    or how negative the inputs are. This allows us to interpret the results as probabilities.
    The sigmoid is also a softer version of the threshold function. It smoothly changes
    between the probabilities. The function is therefore differentiable, which allows
    us to use gradient descent to learn the weights and biases.`),ts=p(),tt=P("p"),Cs=u(`Usually the output of 0.5 (50%) is regarded as the cutoff point. That would
    mean that inputs above 0.5 would be classified as category one and inputs
    below 0.5 would be classified as category 0.`),ss=p(),st=P("p"),qs=u(`In practice we combine linear regression with a sigmoid function, which
    forms the basis for logistic regression. The output of logistic regression
    is used as the input into the sigmoid.`),as=p(),h(be.$$.fragment),ns=p(),F=P("p"),Fs=u("This procedure allows us to learn parameters "),h(_e.$$.fragment),Ms=u(" and "),h(ce.$$.fragment),Ns=u(" which align the true categories "),h(de.$$.fragment),js=u(`
    with predicted probabilities `),h(ve.$$.fragment),Us=u(`.
    Below is an interactive example that lets you change the weight and the
    bias. Observe how probabilities change based on the inputs. Using both
    sliders you can move and rotate the probabilities as much as you want. Try
    to find parameters that would fit the data.`),is=p(),h(xe.$$.fragment),fs=p(),h(J.$$.fragment),ls=p(),h(K.$$.fragment),rs=p(),B=P("p"),Gs=u(`When we are dealing with a classification problem, we are trying to draw a
    decision boundary between the different classes in order to separate the
    data as good as possible. In the below example we have a classification
    problem with two features and two classes. We utilize logistic regression
    (the sigmoid function) with two weights `),h(ye.$$.fragment),Xs=u(", "),h(Te.$$.fragment),Js=u(" and the bias "),h(Se.$$.fragment),Ks=u(` to draw a boundary. The boundary represents the
    exact cutoff, the 50% probability. On the one side of the boundary you would
    have
    `),h(ke.$$.fragment),Qs=u(", while on the other side of the boundary you have "),h(Ee.$$.fragment),Zs=u(`. By changing the weights and the bias you can rotate and move the decision
    boundary respectively.`),$s=p(),h(We.$$.fragment),os=p(),h(Q.$$.fragment),us=p(),h(Z.$$.fragment),ms=p(),h(ee.$$.fragment),ps=p(),at=P("p"),aa=u(`When we apply gradient descent to logistic regression, essentially we are
    adjusting the weights and the bias to shift the decision boundary.`),gs=p(),nt=P("div"),hs=p(),it=P("h2"),na=u("Softmax"),ws=p(),ft=P("p"),ia=u(`Before we move on to the next section, let us shortly discuss what function
    can be used if we are faced with more than two categories.`),bs=p(),M=P("p"),fa=u("Let us assume, that we face a classification problem with "),h(ze.$$.fragment),la=u(`
    possible categories. Our goal is to calculate the probabilities to belong to
    each of these categories. The `),h(Pe.$$.fragment),ra=u(` function takes a
    `),h(Ie.$$.fragment),$a=u(` dimensional vector
    `),h(Oe.$$.fragment),oa=u(` and returns a vector of the same size
    that contains the corresponding probabilities.`),_s=p(),h(Le.$$.fragment),cs=p(),lt=P("p"),ua=u("If we had four categories for example, the results might look as follows."),ds=p(),h(De.$$.fragment),vs=p(),rt=P("p"),ma=u(`Given these numbers, we would assume that it is most likely that the
    features belong to the category Nr. 3.`),xs=p(),N=P("p"),pa=u("The values "),h(Ae.$$.fragment),ga=u(` that are used as input into
    the softmax function are called `),h(Ve.$$.fragment),ha=u(`. You can
    imagine that each of the `),h(Be.$$.fragment),wa=u(` logits is a separate linear regression
    of the form `),h(He.$$.fragment),ba=u("."),ys=p(),G=P("p"),_a=u("We calculate the probability for the "),h(Ce.$$.fragment),ca=u(" of "),h(qe.$$.fragment),da=u(` categories
    using the following softmax equation.`),Ts=p(),h(Fe.$$.fragment),Ss=p(),$t=P("p"),va=u(`Similar to the sigmoid function, the softmax function has several
    advantageous properties. The equation for example guarantees, that the sum
    of probabilities is exactly 1, thus avoiding any violations of the law of
    probabilities. Additionally as the name suggest the function is "soft",
    which indicates that it is differentiable and can be used in gradient
    descent.`),ks=p(),ot=P("div"),this.h()},l(e){n=I(e,"H1",{});var i=O(n);s=m(i,"Sigmoid and Softmax"),i.forEach(f),a=g(e),$=I(e,"DIV",{class:!0}),O($).forEach(f),v=g(e),x=I(e,"P",{});var te=O(x);T=m(te,`Let us assume that no classification algorithms have been invented yet and
    that we want to come up with the first classification algorithm. We are
    assuming that there should be learnable parameters `),w(k.$$.fragment,te),o=m(te," and "),w(E.$$.fragment,te),W=m(te,` and the output of the model should correspond the probability
    to belong to one of two categories. We will expand our ideas to more categories
    at a later step.`),te.forEach(f),z=g(e),t=I(e,"DIV",{class:!0}),O(t).forEach(f),y=g(e),H=I(e,"H2",{});var bt=O(H);ne=m(bt,"Linear Regression"),bt.forEach(f),Ue=g(e),ie=I(e,"P",{});var _t=O(ie);wt=m(_t,`Let's see what happens when we simply use linear regression for
    classification tasks.`),_t.forEach(f),Ye=g(e),fe=I(e,"P",{});var ct=O(fe);L=m(ct,`Our dataset contains two classes. We assign each of the classes eather the
    label 0 or 1 and we need to train a model that produces values between 0 and
    1. These values can be regarded as probabilities to belong to the category
    1. If the output is 0.3 for example, the model predicts that we are dealing
    with category 1 with 30% probability and with 70% probability we are dealing
    with category 0.`),ct.forEach(f),V=g(e),C=I(e,"P",{});var dt=O(C);Ne=m(dt,`We could draw a line just like the one below and at first glance this seems
    to be a reasonable approach. Higher values of some feature correspond to a
    higher probability to belong to the "blue" category and lower values of the
    same feature correspond to a lower probability.`),dt.forEach(f),Ct=g(e),w(le.$$.fragment,e),qt=g(e),Re=I(e,"P",{});var vt=O(Re);Ws=m(vt,`While linear regression might work during training, when we start facing new
    datapoints we might get into trouble, because our model can theoretically
    produce results that are above 1 or below 0, values that can not be
    interpreted as probabilities.`),vt.forEach(f),Ft=g(e),w(re.$$.fragment,e),Mt=g(e),w($e.$$.fragment,e),Nt=g(e),Ge=I(e,"DIV",{class:!0}),O(Ge).forEach(f),jt=g(e),Xe=I(e,"H2",{});var xt=O(Xe);zs=m(xt,"Threshold Activation"),xt.forEach(f),Ut=g(e),Je=I(e,"P",{});var yt=O(Je);Ps=m(yt,`In our second attempt to construct a classification algorithm we could the
    use original threshold activation function that was used in the McCulloch
    and Pitts neuron.`),yt.forEach(f),Yt=g(e),Ke=I(e,"P",{});var Tt=O(Ke);Is=m(Tt,`We could use the threshold of 5, which would mean that each sample with a
    feature value above 5 is classified into the "blue" category and the rest
    would be classified as the "red" category.`),Tt.forEach(f),Rt=g(e),w(oe.$$.fragment,e),Gt=g(e),w(ue.$$.fragment,e),Xt=g(e),Qe=I(e,"P",{});var St=O(Qe);Os=m(St,`While this rule perfectly separates the data into the two categories, the
    threshold function is not differentiable. A non differentiable function
    would prevent us from applying gradient descent, which would limit our
    ability to learn optimal weights and biases.`),St.forEach(f),Jt=g(e),Ze=I(e,"DIV",{class:!0}),O(Ze).forEach(f),Kt=g(e),et=I(e,"H2",{});var kt=O(et);Ls=m(kt,"Sigmoid"),kt.forEach(f),Qt=g(e),R=I(e,"P",{});var se=O(R);Ds=m(se,"The "),w(me.$$.fragment,se),As=m(se," function "),w(pe.$$.fragment,se),Vs=m(se,` is an S shaped function that is commonly used in machine learning to produce
    probabilites.`),se.forEach(f),Zt=g(e),w(ge.$$.fragment,e),es=g(e),he=I(e,"P",{});var je=O(he);Bs=m(je,`The sigmoid does not display problems that we faced with the two approaches
    above.
    `),w(we.$$.fragment,je),Hs=m(je,` is always bounded between 0 and 1, no matter how large
    or how negative the inputs are. This allows us to interpret the results as probabilities.
    The sigmoid is also a softer version of the threshold function. It smoothly changes
    between the probabilities. The function is therefore differentiable, which allows
    us to use gradient descent to learn the weights and biases.`),je.forEach(f),ts=g(e),tt=I(e,"P",{});var Et=O(tt);Cs=m(Et,`Usually the output of 0.5 (50%) is regarded as the cutoff point. That would
    mean that inputs above 0.5 would be classified as category one and inputs
    below 0.5 would be classified as category 0.`),Et.forEach(f),ss=g(e),st=I(e,"P",{});var Wt=O(st);qs=m(Wt,`In practice we combine linear regression with a sigmoid function, which
    forms the basis for logistic regression. The output of logistic regression
    is used as the input into the sigmoid.`),Wt.forEach(f),as=g(e),w(be.$$.fragment,e),ns=g(e),F=I(e,"P",{});var j=O(F);Fs=m(j,"This procedure allows us to learn parameters "),w(_e.$$.fragment,j),Ms=m(j," and "),w(ce.$$.fragment,j),Ns=m(j," which align the true categories "),w(de.$$.fragment,j),js=m(j,`
    with predicted probabilities `),w(ve.$$.fragment,j),Us=m(j,`.
    Below is an interactive example that lets you change the weight and the
    bias. Observe how probabilities change based on the inputs. Using both
    sliders you can move and rotate the probabilities as much as you want. Try
    to find parameters that would fit the data.`),j.forEach(f),is=g(e),w(xe.$$.fragment,e),fs=g(e),w(J.$$.fragment,e),ls=g(e),w(K.$$.fragment,e),rs=g(e),B=I(e,"P",{});var q=O(B);Gs=m(q,`When we are dealing with a classification problem, we are trying to draw a
    decision boundary between the different classes in order to separate the
    data as good as possible. In the below example we have a classification
    problem with two features and two classes. We utilize logistic regression
    (the sigmoid function) with two weights `),w(ye.$$.fragment,q),Xs=m(q,", "),w(Te.$$.fragment,q),Js=m(q," and the bias "),w(Se.$$.fragment,q),Ks=m(q,` to draw a boundary. The boundary represents the
    exact cutoff, the 50% probability. On the one side of the boundary you would
    have
    `),w(ke.$$.fragment,q),Qs=m(q,", while on the other side of the boundary you have "),w(Ee.$$.fragment,q),Zs=m(q,`. By changing the weights and the bias you can rotate and move the decision
    boundary respectively.`),q.forEach(f),$s=g(e),w(We.$$.fragment,e),os=g(e),w(Q.$$.fragment,e),us=g(e),w(Z.$$.fragment,e),ms=g(e),w(ee.$$.fragment,e),ps=g(e),at=I(e,"P",{});var zt=O(at);aa=m(zt,`When we apply gradient descent to logistic regression, essentially we are
    adjusting the weights and the bias to shift the decision boundary.`),zt.forEach(f),gs=g(e),nt=I(e,"DIV",{class:!0}),O(nt).forEach(f),hs=g(e),it=I(e,"H2",{});var Pt=O(it);na=m(Pt,"Softmax"),Pt.forEach(f),ws=g(e),ft=I(e,"P",{});var It=O(ft);ia=m(It,`Before we move on to the next section, let us shortly discuss what function
    can be used if we are faced with more than two categories.`),It.forEach(f),bs=g(e),M=I(e,"P",{});var U=O(M);fa=m(U,"Let us assume, that we face a classification problem with "),w(ze.$$.fragment,U),la=m(U,`
    possible categories. Our goal is to calculate the probabilities to belong to
    each of these categories. The `),w(Pe.$$.fragment,U),ra=m(U,` function takes a
    `),w(Ie.$$.fragment,U),$a=m(U,` dimensional vector
    `),w(Oe.$$.fragment,U),oa=m(U,` and returns a vector of the same size
    that contains the corresponding probabilities.`),U.forEach(f),_s=g(e),w(Le.$$.fragment,e),cs=g(e),lt=I(e,"P",{});var Ot=O(lt);ua=m(Ot,"If we had four categories for example, the results might look as follows."),Ot.forEach(f),ds=g(e),w(De.$$.fragment,e),vs=g(e),rt=I(e,"P",{});var Lt=O(rt);ma=m(Lt,`Given these numbers, we would assume that it is most likely that the
    features belong to the category Nr. 3.`),Lt.forEach(f),xs=g(e),N=I(e,"P",{});var Y=O(N);pa=m(Y,"The values "),w(Ae.$$.fragment,Y),ga=m(Y,` that are used as input into
    the softmax function are called `),w(Ve.$$.fragment,Y),ha=m(Y,`. You can
    imagine that each of the `),w(Be.$$.fragment,Y),wa=m(Y,` logits is a separate linear regression
    of the form `),w(He.$$.fragment,Y),ba=m(Y,"."),Y.forEach(f),ys=g(e),G=I(e,"P",{});var ae=O(G);_a=m(ae,"We calculate the probability for the "),w(Ce.$$.fragment,ae),ca=m(ae," of "),w(qe.$$.fragment,ae),da=m(ae,` categories
    using the following softmax equation.`),ae.forEach(f),Ts=g(e),w(Fe.$$.fragment,e),Ss=g(e),$t=I(e,"P",{});var Dt=O($t);va=m(Dt,`Similar to the sigmoid function, the softmax function has several
    advantageous properties. The equation for example guarantees, that the sum
    of probabilities is exactly 1, thus avoiding any violations of the law of
    probabilities. Additionally as the name suggest the function is "soft",
    which indicates that it is differentiable and can be used in gradient
    descent.`),Dt.forEach(f),ks=g(e),ot=I(e,"DIV",{class:!0}),O(ot).forEach(f),this.h()},h(){Me($,"class","separator"),Me(t,"class","separator"),Me(Ge,"class","separator"),Me(Ze,"class","separator"),Me(nt,"class","separator"),Me(ot,"class","separator")},m(e,i){l(e,n,i),S(n,s),l(e,a,i),l(e,$,i),l(e,v,i),l(e,x,i),S(x,T),b(k,x,null),S(x,o),b(E,x,null),S(x,W),l(e,z,i),l(e,t,i),l(e,y,i),l(e,H,i),S(H,ne),l(e,Ue,i),l(e,ie,i),S(ie,wt),l(e,Ye,i),l(e,fe,i),S(fe,L),l(e,V,i),l(e,C,i),S(C,Ne),l(e,Ct,i),b(le,e,i),l(e,qt,i),l(e,Re,i),S(Re,Ws),l(e,Ft,i),b(re,e,i),l(e,Mt,i),b($e,e,i),l(e,Nt,i),l(e,Ge,i),l(e,jt,i),l(e,Xe,i),S(Xe,zs),l(e,Ut,i),l(e,Je,i),S(Je,Ps),l(e,Yt,i),l(e,Ke,i),S(Ke,Is),l(e,Rt,i),b(oe,e,i),l(e,Gt,i),b(ue,e,i),l(e,Xt,i),l(e,Qe,i),S(Qe,Os),l(e,Jt,i),l(e,Ze,i),l(e,Kt,i),l(e,et,i),S(et,Ls),l(e,Qt,i),l(e,R,i),S(R,Ds),b(me,R,null),S(R,As),b(pe,R,null),S(R,Vs),l(e,Zt,i),b(ge,e,i),l(e,es,i),l(e,he,i),S(he,Bs),b(we,he,null),S(he,Hs),l(e,ts,i),l(e,tt,i),S(tt,Cs),l(e,ss,i),l(e,st,i),S(st,qs),l(e,as,i),b(be,e,i),l(e,ns,i),l(e,F,i),S(F,Fs),b(_e,F,null),S(F,Ms),b(ce,F,null),S(F,Ns),b(de,F,null),S(F,js),b(ve,F,null),S(F,Us),l(e,is,i),b(xe,e,i),l(e,fs,i),b(J,e,i),l(e,ls,i),b(K,e,i),l(e,rs,i),l(e,B,i),S(B,Gs),b(ye,B,null),S(B,Xs),b(Te,B,null),S(B,Js),b(Se,B,null),S(B,Ks),b(ke,B,null),S(B,Qs),b(Ee,B,null),S(B,Zs),l(e,$s,i),b(We,e,i),l(e,os,i),b(Q,e,i),l(e,us,i),b(Z,e,i),l(e,ms,i),b(ee,e,i),l(e,ps,i),l(e,at,i),S(at,aa),l(e,gs,i),l(e,nt,i),l(e,hs,i),l(e,it,i),S(it,na),l(e,ws,i),l(e,ft,i),S(ft,ia),l(e,bs,i),l(e,M,i),S(M,fa),b(ze,M,null),S(M,la),b(Pe,M,null),S(M,ra),b(Ie,M,null),S(M,$a),b(Oe,M,null),S(M,oa),l(e,_s,i),b(Le,e,i),l(e,cs,i),l(e,lt,i),S(lt,ua),l(e,ds,i),b(De,e,i),l(e,vs,i),l(e,rt,i),S(rt,ma),l(e,xs,i),l(e,N,i),S(N,pa),b(Ae,N,null),S(N,ga),b(Ve,N,null),S(N,ha),b(Be,N,null),S(N,wa),b(He,N,null),S(N,ba),l(e,ys,i),l(e,G,i),S(G,_a),b(Ce,G,null),S(G,ca),b(qe,G,null),S(G,da),l(e,Ts,i),b(Fe,e,i),l(e,Ss,i),l(e,$t,i),S($t,va),l(e,ks,i),l(e,ot,i),Es=!0},p(e,i){const te={};i&524288&&(te.$$scope={dirty:i,ctx:e}),k.$set(te);const bt={};i&524288&&(bt.$$scope={dirty:i,ctx:e}),E.$set(bt);const _t={};i&524288&&(_t.$$scope={dirty:i,ctx:e}),le.$set(_t);const ct={};i&524288&&(ct.$$scope={dirty:i,ctx:e}),re.$set(ct);const dt={};i&524288&&(dt.$$scope={dirty:i,ctx:e}),$e.$set(dt);const vt={};i&524288&&(vt.$$scope={dirty:i,ctx:e}),oe.$set(vt);const xt={};i&524288&&(xt.$$scope={dirty:i,ctx:e}),ue.$set(xt);const yt={};i&524288&&(yt.$$scope={dirty:i,ctx:e}),me.$set(yt);const Tt={};i&524288&&(Tt.$$scope={dirty:i,ctx:e}),pe.$set(Tt);const St={};i&524288&&(St.$$scope={dirty:i,ctx:e}),ge.$set(St);const kt={};i&524288&&(kt.$$scope={dirty:i,ctx:e}),we.$set(kt);const se={};i&524288&&(se.$$scope={dirty:i,ctx:e}),be.$set(se);const je={};i&524288&&(je.$$scope={dirty:i,ctx:e}),_e.$set(je);const Et={};i&524288&&(Et.$$scope={dirty:i,ctx:e}),ce.$set(Et);const Wt={};i&524288&&(Wt.$$scope={dirty:i,ctx:e}),de.$set(Wt);const j={};i&524288&&(j.$$scope={dirty:i,ctx:e}),ve.$set(j);const q={};i&524320&&(q.$$scope={dirty:i,ctx:e}),xe.$set(q);const zt={};!Ys&&i&1&&(Ys=!0,zt.value=e[0],Bt(()=>Ys=!1)),J.$set(zt);const Pt={};!Rs&&i&2&&(Rs=!0,Pt.value=e[1],Bt(()=>Rs=!1)),K.$set(Pt);const It={};i&524288&&(It.$$scope={dirty:i,ctx:e}),ye.$set(It);const U={};i&524288&&(U.$$scope={dirty:i,ctx:e}),Te.$set(U);const Ot={};i&524288&&(Ot.$$scope={dirty:i,ctx:e}),Se.$set(Ot);const Lt={};i&524288&&(Lt.$$scope={dirty:i,ctx:e}),ke.$set(Lt);const Y={};i&524288&&(Y.$$scope={dirty:i,ctx:e}),Ee.$set(Y);const ae={};i&524352&&(ae.$$scope={dirty:i,ctx:e}),We.$set(ae);const Dt={};!ea&&i&4&&(ea=!0,Dt.value=e[2],Bt(()=>ea=!1)),Q.$set(Dt);const Wa={};!ta&&i&8&&(ta=!0,Wa.value=e[3],Bt(()=>ta=!1)),Z.$set(Wa);const za={};!sa&&i&16&&(sa=!0,za.value=e[4],Bt(()=>sa=!1)),ee.$set(za);const Pa={};i&524288&&(Pa.$$scope={dirty:i,ctx:e}),ze.$set(Pa);const Ia={};i&524288&&(Ia.$$scope={dirty:i,ctx:e}),Pe.$set(Ia);const Oa={};i&524288&&(Oa.$$scope={dirty:i,ctx:e}),Ie.$set(Oa);const La={};i&524288&&(La.$$scope={dirty:i,ctx:e}),Oe.$set(La);const Da={};i&524288&&(Da.$$scope={dirty:i,ctx:e}),Le.$set(Da);const Aa={};i&524288&&(Aa.$$scope={dirty:i,ctx:e}),De.$set(Aa);const Va={};i&524288&&(Va.$$scope={dirty:i,ctx:e}),Ae.$set(Va);const Ba={};i&524288&&(Ba.$$scope={dirty:i,ctx:e}),Ve.$set(Ba);const Ha={};i&524288&&(Ha.$$scope={dirty:i,ctx:e}),Be.$set(Ha);const Ca={};i&524288&&(Ca.$$scope={dirty:i,ctx:e}),He.$set(Ca);const qa={};i&524288&&(qa.$$scope={dirty:i,ctx:e}),Ce.$set(qa);const Fa={};i&524288&&(Fa.$$scope={dirty:i,ctx:e}),qe.$set(Fa);const Ma={};i&524288&&(Ma.$$scope={dirty:i,ctx:e}),Fe.$set(Ma)},i(e){Es||(_(k.$$.fragment,e),_(E.$$.fragment,e),_(le.$$.fragment,e),_(re.$$.fragment,e),_($e.$$.fragment,e),_(oe.$$.fragment,e),_(ue.$$.fragment,e),_(me.$$.fragment,e),_(pe.$$.fragment,e),_(ge.$$.fragment,e),_(we.$$.fragment,e),_(be.$$.fragment,e),_(_e.$$.fragment,e),_(ce.$$.fragment,e),_(de.$$.fragment,e),_(ve.$$.fragment,e),_(xe.$$.fragment,e),_(J.$$.fragment,e),_(K.$$.fragment,e),_(ye.$$.fragment,e),_(Te.$$.fragment,e),_(Se.$$.fragment,e),_(ke.$$.fragment,e),_(Ee.$$.fragment,e),_(We.$$.fragment,e),_(Q.$$.fragment,e),_(Z.$$.fragment,e),_(ee.$$.fragment,e),_(ze.$$.fragment,e),_(Pe.$$.fragment,e),_(Ie.$$.fragment,e),_(Oe.$$.fragment,e),_(Le.$$.fragment,e),_(De.$$.fragment,e),_(Ae.$$.fragment,e),_(Ve.$$.fragment,e),_(Be.$$.fragment,e),_(He.$$.fragment,e),_(Ce.$$.fragment,e),_(qe.$$.fragment,e),_(Fe.$$.fragment,e),Es=!0)},o(e){c(k.$$.fragment,e),c(E.$$.fragment,e),c(le.$$.fragment,e),c(re.$$.fragment,e),c($e.$$.fragment,e),c(oe.$$.fragment,e),c(ue.$$.fragment,e),c(me.$$.fragment,e),c(pe.$$.fragment,e),c(ge.$$.fragment,e),c(we.$$.fragment,e),c(be.$$.fragment,e),c(_e.$$.fragment,e),c(ce.$$.fragment,e),c(de.$$.fragment,e),c(ve.$$.fragment,e),c(xe.$$.fragment,e),c(J.$$.fragment,e),c(K.$$.fragment,e),c(ye.$$.fragment,e),c(Te.$$.fragment,e),c(Se.$$.fragment,e),c(ke.$$.fragment,e),c(Ee.$$.fragment,e),c(We.$$.fragment,e),c(Q.$$.fragment,e),c(Z.$$.fragment,e),c(ee.$$.fragment,e),c(ze.$$.fragment,e),c(Pe.$$.fragment,e),c(Ie.$$.fragment,e),c(Oe.$$.fragment,e),c(Le.$$.fragment,e),c(De.$$.fragment,e),c(Ae.$$.fragment,e),c(Ve.$$.fragment,e),c(Be.$$.fragment,e),c(He.$$.fragment,e),c(Ce.$$.fragment,e),c(qe.$$.fragment,e),c(Fe.$$.fragment,e),Es=!1},d(e){e&&f(n),e&&f(a),e&&f($),e&&f(v),e&&f(x),d(k),d(E),e&&f(z),e&&f(t),e&&f(y),e&&f(H),e&&f(Ue),e&&f(ie),e&&f(Ye),e&&f(fe),e&&f(V),e&&f(C),e&&f(Ct),d(le,e),e&&f(qt),e&&f(Re),e&&f(Ft),d(re,e),e&&f(Mt),d($e,e),e&&f(Nt),e&&f(Ge),e&&f(jt),e&&f(Xe),e&&f(Ut),e&&f(Je),e&&f(Yt),e&&f(Ke),e&&f(Rt),d(oe,e),e&&f(Gt),d(ue,e),e&&f(Xt),e&&f(Qe),e&&f(Jt),e&&f(Ze),e&&f(Kt),e&&f(et),e&&f(Qt),e&&f(R),d(me),d(pe),e&&f(Zt),d(ge,e),e&&f(es),e&&f(he),d(we),e&&f(ts),e&&f(tt),e&&f(ss),e&&f(st),e&&f(as),d(be,e),e&&f(ns),e&&f(F),d(_e),d(ce),d(de),d(ve),e&&f(is),d(xe,e),e&&f(fs),d(J,e),e&&f(ls),d(K,e),e&&f(rs),e&&f(B),d(ye),d(Te),d(Se),d(ke),d(Ee),e&&f($s),d(We,e),e&&f(os),d(Q,e),e&&f(us),d(Z,e),e&&f(ms),d(ee,e),e&&f(ps),e&&f(at),e&&f(gs),e&&f(nt),e&&f(hs),e&&f(it),e&&f(ws),e&&f(ft),e&&f(bs),e&&f(M),d(ze),d(Pe),d(Ie),d(Oe),e&&f(_s),d(Le,e),e&&f(cs),e&&f(lt),e&&f(ds),d(De,e),e&&f(vs),e&&f(rt),e&&f(xs),e&&f(N),d(Ae),d(Ve),d(Be),d(He),e&&f(ys),e&&f(G),d(Ce),d(qe),e&&f(Ts),d(Fe,e),e&&f(Ss),e&&f($t),e&&f(ks),e&&f(ot)}}}function qn(r){let n,s,a,$;return a=new Za({props:{$$slots:{default:[Cn]},$$scope:{ctx:r}}}),{c(){n=P("meta"),s=p(),h(a.$$.fragment),this.h()},l(v){const x=Qa("svelte-1e806ap",document.head);n=I(x,"META",{name:!0,content:!0}),x.forEach(f),s=g(v),w(a.$$.fragment,v),this.h()},h(){document.title="Sigmoid and Softmax - World4AI",Me(n,"name","description"),Me(n,"content","The sigmoid activation function bounds the outputs between 0 and 1, allowing the results to be interpreted as probabilities. The softmax activation function works in a similar manner, but unlike the sigmoid works for more than 2 categories.")},m(v,x){S(document.head,n),l(v,s,x),b(a,v,x),$=!0},p(v,[x]){const T={};x&524415&&(T.$$scope={dirty:x,ctx:v}),a.$set(T)},i(v){$||(_(a.$$.fragment,v),$=!0)},o(v){c(a.$$.fragment,v),$=!1},d(v){f(n),v&&f(s),d(a,v)}}}function Fn(r,n,s){const a=[[{x:0,y:0},{x:-2,y:0},{x:-1,y:0},{x:1,y:0},{x:2,y:0},{x:3,y:0},{x:4,y:0}],[{x:6,y:1},{x:7,y:1},{x:8,y:1},{x:9,y:1},{x:10,y:1},{x:11,y:1},{x:12,y:1}]],$=[[{x:0,y:0},{x:1,y:0},{x:2,y:0},{x:3,y:0},{x:4,y:0}],[{x:6,y:1},{x:7,y:1},{x:8,y:1},{x:9,y:1},{x:10,y:1}]];let v=[];for(let L=-2;L<=12;L++){let V=L,C=1;V<=5&&(C=0),v.push({x:V,y:C}),V==5&&v.push({x:5,y:1})}let x=[];for(let L=-6;L<=6;L+=.1){let V=L,C=1/(1+Math.exp(-V));x.push({x:V,y:C})}let T=1,k=0,o=[];function E(){s(5,o=[]);for(let L=-16;L<=16;L+=.1){let V=L,C=T*V+k,Ne=1/(1+Math.exp(-C));o.push({x:V,y:Ne})}}E();let W=[[{x:0,y:0},{x:.1,y:.23},{x:.25,y:.93},{x:.15,y:.63},{x:.25,y:.13},{x:.1,y:.93},{x:.12,y:.53},{x:.32,y:.23},{x:.22,y:.5},{x:.49,y:.1},{x:.45,y:.3},{x:.4,y:.7},{x:.35,y:.5},{x:.25,y:.7},{x:.2,y:.2}],[{x:1,y:1},{x:.75,y:.89},{x:.75,y:.75},{x:.95,y:.7},{x:.85,y:.7},{x:.65,y:.8},{x:.85,y:.4},{x:.75,y:.25},{x:.75,y:.55},{x:.95,y:.35},{x:.85,y:.15},{x:.85,y:.95},{x:.9,y:.55},{x:.9,y:.28},{x:.98,y:.95}]],z=-.15,t=.2,y=-.01,H=[];function ne(){let L=0,V=1,C=(-y-z*L)/t,Ne=(-y-z*V)/t;s(6,H=[{x:L,y:C},{x:V,y:Ne}])}ne();function Ue(L){T=L,s(0,T)}function ie(L){k=L,s(1,k)}function wt(L){z=L,s(2,z)}function Ye(L){t=L,s(3,t)}function fe(L){y=L,s(4,y)}return r.$$.update=()=>{r.$$.dirty&1&&T&&E(),r.$$.dirty&2&&k&&E(),r.$$.dirty&4&&z&&ne(),r.$$.dirty&8&&t&&ne(),r.$$.dirty&16&&y&&ne()},[T,k,z,t,y,o,H,a,$,v,x,W,Ue,ie,wt,Ye,fe]}class Qn extends Xa{constructor(n){super(),Ja(this,n,Fn,qn,Ka,{})}}export{Qn as default};
