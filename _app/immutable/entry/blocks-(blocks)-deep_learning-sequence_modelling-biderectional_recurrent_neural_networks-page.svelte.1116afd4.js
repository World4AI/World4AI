import{S as We,i as De,s as qe,k as P,a as z,q as y,y as v,W as Se,l as T,h as r,c as E,m as R,r as k,z as b,n as S,N as _,b as f,A as x,g,d as w,B as N,C as Ne,Q as Pe,R as Te,P as Be}from"../chunks/index.4d92b023.js";import{C as Ce}from"../chunks/Container.b0705c7b.js";import{L as Ie}from"../chunks/Latex.e0b308c0.js";import{H as Re}from"../chunks/Highlight.b7c1de53.js";import{P as Y}from"../chunks/PythonCode.212ba7a6.js";import{S as Le}from"../chunks/SvgContainer.f70b5745.js";import{B as Z}from"../chunks/Block.059eddcd.js";import{A as he}from"../chunks/Arrow.ae91874c.js";function He(c,t,a){const s=c.slice();return s[0]=t[a],s[2]=a,s}function Oe(c){let t;return{c(){t=y("biderectional recurrent neural network")},l(a){t=k(a,"biderectional recurrent neural network")},m(a,s){f(a,t,s)},d(a){a&&r(t)}}}function Ue(c){let t=String.raw`\mathbf{y_t}`+"",a;return{c(){a=y(t)},l(s){a=k(s,t)},m(s,u){f(s,a,u)},p:Ne,d(s){s&&r(a)}}}function Ve(c){let t,a,s,u,i,$,m,h,A,o,p;return a=new he({props:{strokeWidth:"2",data:[{x:31,y:45},{x:76,y:45}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),s=new he({props:{strokeWidth:"2",data:[{x:120,y:45},{x:164,y:45}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),u=new he({props:{strokeWidth:"2",data:[{x:87,y:62},{x:87,y:140}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),i=new he({props:{strokeWidth:"2",data:[{x:112,y:145},{x:112,y:68}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),$=new Z({props:{x:"100",y:"45",width:"30",height:"30",class:"fill-slate-500"}}),m=new Z({props:{text:"x_"+(c[2]+1),type:"latex",fontSize:12,x:"15",y:"45",width:"25",height:"25",class:"fill-blue-100"}}),h=new Z({props:{type:"latex",text:"y_"+(c[2]+1),fontSize:12,x:"185",y:"45",width:"25",height:"25",class:"fill-blue-100"}}),A=new Z({props:{type:"latex",text:"h_"+(c[2]+1),fontSize:12,x:"80",y:"100",width:"25",height:"25",class:"fill-yellow-100"}}),o=new Z({props:{type:"latex",text:"h_"+(c[2]+1),fontSize:12,x:"115",y:"100",width:"25",height:"25",class:"fill-red-100"}}),{c(){t=Pe("g"),v(a.$$.fragment),v(s.$$.fragment),v(u.$$.fragment),v(i.$$.fragment),v($.$$.fragment),v(m.$$.fragment),v(h.$$.fragment),v(A.$$.fragment),v(o.$$.fragment),this.h()},l(l){t=Te(l,"g",{transform:!0});var d=R(t);b(a.$$.fragment,d),b(s.$$.fragment,d),b(u.$$.fragment,d),b(i.$$.fragment,d),b($.$$.fragment,d),b(m.$$.fragment,d),b(h.$$.fragment,d),b(A.$$.fragment,d),b(o.$$.fragment,d),d.forEach(r),this.h()},h(){S(t,"transform","translate(0, "+(c[2]*120-20)+")")},m(l,d){f(l,t,d),x(a,t,null),x(s,t,null),x(u,t,null),x(i,t,null),x($,t,null),x(m,t,null),x(h,t,null),x(A,t,null),x(o,t,null),p=!0},p:Ne,i(l){p||(g(a.$$.fragment,l),g(s.$$.fragment,l),g(u.$$.fragment,l),g(i.$$.fragment,l),g($.$$.fragment,l),g(m.$$.fragment,l),g(h.$$.fragment,l),g(A.$$.fragment,l),g(o.$$.fragment,l),p=!0)},o(l){w(a.$$.fragment,l),w(s.$$.fragment,l),w(u.$$.fragment,l),w(i.$$.fragment,l),w($.$$.fragment,l),w(m.$$.fragment,l),w(h.$$.fragment,l),w(A.$$.fragment,l),w(o.$$.fragment,l),p=!1},d(l){l&&r(t),N(a),N(s),N(u),N(i),N($),N(m),N(h),N(A),N(o)}}}function Fe(c){let t,a,s=Array(4),u=[];for(let i=0;i<s.length;i+=1)u[i]=Ve(He(c,s,i));return{c(){t=Pe("svg");for(let i=0;i<u.length;i+=1)u[i].c();this.h()},l(i){t=Te(i,"svg",{viewBox:!0});var $=R(t);for(let m=0;m<u.length;m+=1)u[m].l($);$.forEach(r),this.h()},h(){S(t,"viewBox","0 0 200 470")},m(i,$){f(i,t,$);for(let m=0;m<u.length;m+=1)u[m]&&u[m].m(t,null);a=!0},p:Ne,i(i){if(!a){for(let $=0;$<s.length;$+=1)g(u[$]);a=!0}},o(i){u=u.filter(Boolean);for(let $=0;$<u.length;$+=1)w(u[$]);a=!1},d(i){i&&r(t),Be(u,i)}}}function Me(c){let t;return{c(){t=y("data leakage")},l(a){t=k(a,"data leakage")},m(a,s){f(a,t,s)},d(a){a&&r(t)}}}function Qe(c){let t,a,s,u,i,$,m,h,A,o,p,l,d,pe,ee,B,ce,te,U,de,re,D,ge,q,we,ne,W,_e,Q,ye,ke,j,ve,be,ae,C,se,I,oe,L,ie,V,xe,le,H,fe,O,ue,F,$e;return s=new Re({props:{$$slots:{default:[Oe]},$$scope:{ctx:c}}}),i=new Ie({props:{$$slots:{default:[Ue]},$$scope:{ctx:c}}}),h=new Le({props:{maxWidth:"250px",$$slots:{default:[Fe]},$$scope:{ctx:c}}}),q=new Re({props:{$$slots:{default:[Me]},$$scope:{ctx:c}}}),C=new Y({props:{code:`batch_size=4
sequence_length=5
input_size=6
hidden_size=3
num_layers=2`}}),I=new Y({props:{code:`rnn = nn.RNN(input_size=input_size, 
             hidden_size=hidden_size, 
             num_layers=num_layers, 
             bidirectional=True)`}}),L=new Y({props:{code:`sequence = torch.randn(sequence_length, batch_size, input_size)
# 2*num_layers due to biderectional model
h_0 = torch.zeros(2*num_layers, batch_size, hidden_size)`}}),H=new Y({props:{code:`with torch.inference_mode():
    output, h_n = rnn(sequence, h_0)
print(output.shape, h_n.shape)`}}),O=new Y({props:{code:"torch.Size([5, 4, 6]) torch.Size([4, 4, 3])",isOutput:!0}}),{c(){t=P("p"),a=y(`A recurrent neural network processes one part of the sequence at a time.
    When we are dealing with a sentence for example, the neural network starts
    with the very first word and moves forward through the sentence. A
    `),v(s.$$.fragment),u=y(` traverses the sequence
    from two directions. As usual from the start to finish and in the reverse direction,
    from finish to start. The output of the network, `),v(i.$$.fragment),$=y(", simply concatenates the two vectors that come from different directions."),m=z(),v(h.$$.fragment),A=z(),o=P("p"),p=y(`A biderectional recurrent neural network is especially well suited for
    language tasks. Look at the two sentences below.`),l=z(),d=P("p"),pe=y("The bank opens ..."),ee=z(),B=P("p"),ce=y("The bank of the river ..."),te=z(),U=P("p"),de=y(`While the sentences start out with the same two words, the meaning can only
    be understood by reading through the whole sentence.`),re=z(),D=P("p"),ge=y(`A biderectional RNN is not suited for every task though. If you intend to
    predict future points of a time series data and you use a biderectional RNN,
    you will introduce `),v(q.$$.fragment),we=y(`. Data leakage means
    that during training your network has access to the type of information,
    that is not available during inference. Using a biderectional RNN would
    imply that you use future time series information to train your neural
    network, like training a RNN to predict the stock price, that the network
    has already observed.`),ne=z(),W=P("p"),_e=y("We can implement a biderectional RNN in PyTorch by simply setting the "),Q=P("code"),ye=y("bidirectional"),ke=y(`
    flag to `),j=P("code"),ve=y("True"),be=y("."),ae=z(),v(C.$$.fragment),se=z(),v(I.$$.fragment),oe=z(),v(L.$$.fragment),ie=z(),V=P("p"),xe=y(`Due to the biderectional nature of the recurrent neural network, the
    dimensions of the outputs and the hidden states increase.`),le=z(),v(H.$$.fragment),fe=z(),v(O.$$.fragment),ue=z(),F=P("div"),this.h()},l(e){t=T(e,"P",{});var n=R(t);a=k(n,`A recurrent neural network processes one part of the sequence at a time.
    When we are dealing with a sentence for example, the neural network starts
    with the very first word and moves forward through the sentence. A
    `),b(s.$$.fragment,n),u=k(n,` traverses the sequence
    from two directions. As usual from the start to finish and in the reverse direction,
    from finish to start. The output of the network, `),b(i.$$.fragment,n),$=k(n,", simply concatenates the two vectors that come from different directions."),n.forEach(r),m=E(e),b(h.$$.fragment,e),A=E(e),o=T(e,"P",{});var G=R(o);p=k(G,`A biderectional recurrent neural network is especially well suited for
    language tasks. Look at the two sentences below.`),G.forEach(r),l=E(e),d=T(e,"P",{class:!0});var J=R(d);pe=k(J,"The bank opens ..."),J.forEach(r),ee=E(e),B=T(e,"P",{class:!0});var K=R(B);ce=k(K,"The bank of the river ..."),K.forEach(r),te=E(e),U=T(e,"P",{});var X=R(U);de=k(X,`While the sentences start out with the same two words, the meaning can only
    be understood by reading through the whole sentence.`),X.forEach(r),re=E(e),D=T(e,"P",{});var me=R(D);ge=k(me,`A biderectional RNN is not suited for every task though. If you intend to
    predict future points of a time series data and you use a biderectional RNN,
    you will introduce `),b(q.$$.fragment,me),we=k(me,`. Data leakage means
    that during training your network has access to the type of information,
    that is not available during inference. Using a biderectional RNN would
    imply that you use future time series information to train your neural
    network, like training a RNN to predict the stock price, that the network
    has already observed.`),me.forEach(r),ne=E(e),W=T(e,"P",{});var M=R(W);_e=k(M,"We can implement a biderectional RNN in PyTorch by simply setting the "),Q=T(M,"CODE",{});var Ae=R(Q);ye=k(Ae,"bidirectional"),Ae.forEach(r),ke=k(M,`
    flag to `),j=T(M,"CODE",{});var ze=R(j);ve=k(ze,"True"),ze.forEach(r),be=k(M,"."),M.forEach(r),ae=E(e),b(C.$$.fragment,e),se=E(e),b(I.$$.fragment,e),oe=E(e),b(L.$$.fragment,e),ie=E(e),V=T(e,"P",{});var Ee=R(V);xe=k(Ee,`Due to the biderectional nature of the recurrent neural network, the
    dimensions of the outputs and the hidden states increase.`),Ee.forEach(r),le=E(e),b(H.$$.fragment,e),fe=E(e),b(O.$$.fragment,e),ue=E(e),F=T(e,"DIV",{class:!0}),R(F).forEach(r),this.h()},h(){S(d,"class","bg-slate-200 py-2 px-0 text-center rounded-xl"),S(B,"class","bg-red-200 py-2 px-0 text-center rounded-xl"),S(F,"class","separator")},m(e,n){f(e,t,n),_(t,a),x(s,t,null),_(t,u),x(i,t,null),_(t,$),f(e,m,n),x(h,e,n),f(e,A,n),f(e,o,n),_(o,p),f(e,l,n),f(e,d,n),_(d,pe),f(e,ee,n),f(e,B,n),_(B,ce),f(e,te,n),f(e,U,n),_(U,de),f(e,re,n),f(e,D,n),_(D,ge),x(q,D,null),_(D,we),f(e,ne,n),f(e,W,n),_(W,_e),_(W,Q),_(Q,ye),_(W,ke),_(W,j),_(j,ve),_(W,be),f(e,ae,n),x(C,e,n),f(e,se,n),x(I,e,n),f(e,oe,n),x(L,e,n),f(e,ie,n),f(e,V,n),_(V,xe),f(e,le,n),x(H,e,n),f(e,fe,n),x(O,e,n),f(e,ue,n),f(e,F,n),$e=!0},p(e,n){const G={};n&8&&(G.$$scope={dirty:n,ctx:e}),s.$set(G);const J={};n&8&&(J.$$scope={dirty:n,ctx:e}),i.$set(J);const K={};n&8&&(K.$$scope={dirty:n,ctx:e}),h.$set(K);const X={};n&8&&(X.$$scope={dirty:n,ctx:e}),q.$set(X)},i(e){$e||(g(s.$$.fragment,e),g(i.$$.fragment,e),g(h.$$.fragment,e),g(q.$$.fragment,e),g(C.$$.fragment,e),g(I.$$.fragment,e),g(L.$$.fragment,e),g(H.$$.fragment,e),g(O.$$.fragment,e),$e=!0)},o(e){w(s.$$.fragment,e),w(i.$$.fragment,e),w(h.$$.fragment,e),w(q.$$.fragment,e),w(C.$$.fragment,e),w(I.$$.fragment,e),w(L.$$.fragment,e),w(H.$$.fragment,e),w(O.$$.fragment,e),$e=!1},d(e){e&&r(t),N(s),N(i),e&&r(m),N(h,e),e&&r(A),e&&r(o),e&&r(l),e&&r(d),e&&r(ee),e&&r(B),e&&r(te),e&&r(U),e&&r(re),e&&r(D),N(q),e&&r(ne),e&&r(W),e&&r(ae),N(C,e),e&&r(se),N(I,e),e&&r(oe),N(L,e),e&&r(ie),e&&r(V),e&&r(le),N(H,e),e&&r(fe),N(O,e),e&&r(ue),e&&r(F)}}}function je(c){let t,a,s,u,i,$,m,h,A;return h=new Ce({props:{$$slots:{default:[Qe]},$$scope:{ctx:c}}}),{c(){t=P("meta"),a=z(),s=P("h1"),u=y("Biderectional Recurrent Neural Networks"),i=z(),$=P("div"),m=z(),v(h.$$.fragment),this.h()},l(o){const p=Se("svelte-k3uls0",document.head);t=T(p,"META",{name:!0,content:!0}),p.forEach(r),a=E(o),s=T(o,"H1",{});var l=R(s);u=k(l,"Biderectional Recurrent Neural Networks"),l.forEach(r),i=E(o),$=T(o,"DIV",{class:!0}),R($).forEach(r),m=E(o),b(h.$$.fragment,o),this.h()},h(){document.title="Bidirectional Recurrent Neural Network - World4AI",S(t,"name","description"),S(t,"content","Unlike a plain vanilla recurrent neural network, a biderectional rnn traverses the sequence in two directions. From front to back and from back to front. The output concatenates the two sets of hidden units."),S($,"class","separator")},m(o,p){_(document.head,t),f(o,a,p),f(o,s,p),_(s,u),f(o,i,p),f(o,$,p),f(o,m,p),x(h,o,p),A=!0},p(o,[p]){const l={};p&8&&(l.$$scope={dirty:p,ctx:o}),h.$set(l)},i(o){A||(g(h.$$.fragment,o),A=!0)},o(o){w(h.$$.fragment,o),A=!1},d(o){r(t),o&&r(a),o&&r(s),o&&r(i),o&&r($),o&&r(m),N(h,o)}}}class rt extends We{constructor(t){super(),De(this,t,null,je,qe,{})}}export{rt as default};
