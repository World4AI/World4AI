import{S as _r,i as yr,s as vr,k as D,a as z,q as k,y as m,W as br,l as R,h as s,c as C,m as T,r as W,z as p,n as L,N as b,b as d,A as g,g as i,d as u,B as c,C as j,Q as Z,R as ee,v as xr,f as kr,P as or}from"../chunks/index.4d92b023.js";import{C as Wr}from"../chunks/Container.b0705c7b.js";import{L as Ne}from"../chunks/Latex.e0b308c0.js";import{H as an}from"../chunks/Highlight.b7c1de53.js";import{P as re}from"../chunks/PythonCode.212ba7a6.js";import{S as Ie}from"../chunks/SvgContainer.f70b5745.js";import{B as S}from"../chunks/Block.059eddcd.js";import{A as O}from"../chunks/Arrow.ae91874c.js";import{C as kt}from"../chunks/Circle.6709e74f.js";import{B as ar}from"../chunks/ButtonContainer.e9aac418.js";import{P as lr}from"../chunks/PlayButton.85103c5a.js";function Nr(_,t,n){const r=_.slice();return r[14]=t[n],r[16]=n,r}function Er(_,t,n){const r=_.slice();return r[14]=t[n],r[16]=n,r}function dr(_,t,n){const r=_.slice();return r[14]=t[n],r[16]=n,r}function qr(_){let t,n;return t=new lr({props:{f:_[10],delta:5}}),{c(){m(t.$$.fragment)},l(r){p(t.$$.fragment,r)},m(r,o){g(t,r,o),n=!0},p:j,i(r){n||(i(t.$$.fragment,r),n=!0)},o(r){u(t.$$.fragment,r),n=!1},d(r){c(t,r)}}}function Ar(_){let t,n,r,o,l,h,$;return n=new O({props:{strokeWidth:"2",data:[{x:130,y:50},{x:215,y:50}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),r=new O({props:{strokeWidth:"2",data:[{x:280,y:50},{x:380,y:50}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),o=new S({props:{x:"100",y:"50",width:"20",height:"20",class:"fill-slate-300"}}),l=new S({props:{x:"250",y:"50",width:"50",height:"50",class:"fill-slate-600"}}),h=new kt({props:{x:_[0],y:es,r:"5",class:"fill-yellow-400"}}),{c(){t=Z("svg"),m(n.$$.fragment),m(r.$$.fragment),m(o.$$.fragment),m(l.$$.fragment),m(h.$$.fragment),this.h()},l(w){t=ee(w,"svg",{viewBox:!0});var N=T(t);p(n.$$.fragment,N),p(r.$$.fragment,N),p(o.$$.fragment,N),p(l.$$.fragment,N),p(h.$$.fragment,N),N.forEach(s),this.h()},h(){L(t,"viewBox","0 0 400 100")},m(w,N){d(w,t,N),g(n,t,null),g(r,t,null),g(o,t,null),g(l,t,null),g(h,t,null),$=!0},p(w,N){const f={};N&1&&(f.x=w[0]),h.$set(f)},i(w){$||(i(n.$$.fragment,w),i(r.$$.fragment,w),i(o.$$.fragment,w),i(l.$$.fragment,w),i(h.$$.fragment,w),$=!0)},o(w){u(n.$$.fragment,w),u(r.$$.fragment,w),u(o.$$.fragment,w),u(l.$$.fragment,w),u(h.$$.fragment,w),$=!1},d(w){w&&s(t),c(n),c(r),c(o),c(l),c(h)}}}function Tr(_){let t,n;return t=new lr({props:{f:_[11],delta:5}}),{c(){m(t.$$.fragment)},l(r){p(t.$$.fragment,r)},m(r,o){g(t,r,o),n=!0},p:j,i(r){n||(i(t.$$.fragment,r),n=!0)},o(r){u(t.$$.fragment,r),n=!1},d(r){c(t,r)}}}function zr(_){let t,n,r,o,l,h,$,w,N,f,x,q;return n=new O({props:{strokeWidth:"2",data:[{x:5,y:50},{x:65,y:50}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),r=new O({props:{strokeWidth:"2",data:[{x:5,y:150},{x:65,y:150}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),o=new O({props:{strokeWidth:"2",data:[{x:130,y:50},{x:215,y:90}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),l=new O({props:{strokeWidth:"2",data:[{x:130,y:150},{x:215,y:110}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),h=new O({props:{strokeWidth:"2",data:[{x:280,y:100},{x:380,y:100}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),$=new S({props:{x:"100",y:"50",width:"20",height:"20",class:"fill-slate-300"}}),w=new S({props:{x:"100",y:"150",width:"20",height:"20",class:"fill-slate-300"}}),N=new S({props:{x:"250",y:"100",width:"50",height:"50",class:"fill-slate-600"}}),f=new kt({props:{x:_[1],y:_[3],r:"5",class:"fill-yellow-400"}}),x=new kt({props:{x:_[2],y:_[4],r:"5",class:"fill-yellow-400"}}),{c(){t=Z("svg"),m(n.$$.fragment),m(r.$$.fragment),m(o.$$.fragment),m(l.$$.fragment),m(h.$$.fragment),m($.$$.fragment),m(w.$$.fragment),m(N.$$.fragment),m(f.$$.fragment),m(x.$$.fragment),this.h()},l(E){t=ee(E,"svg",{viewBox:!0});var v=T(t);p(n.$$.fragment,v),p(r.$$.fragment,v),p(o.$$.fragment,v),p(l.$$.fragment,v),p(h.$$.fragment,v),p($.$$.fragment,v),p(w.$$.fragment,v),p(N.$$.fragment,v),p(f.$$.fragment,v),p(x.$$.fragment,v),v.forEach(s),this.h()},h(){L(t,"viewBox","0 0 400 200")},m(E,v){d(E,t,v),g(n,t,null),g(r,t,null),g(o,t,null),g(l,t,null),g(h,t,null),g($,t,null),g(w,t,null),g(N,t,null),g(f,t,null),g(x,t,null),q=!0},p(E,v){const y={};v&2&&(y.x=E[1]),v&8&&(y.y=E[3]),f.$set(y);const B={};v&4&&(B.x=E[2]),v&16&&(B.y=E[4]),x.$set(B)},i(E){q||(i(n.$$.fragment,E),i(r.$$.fragment,E),i(o.$$.fragment,E),i(l.$$.fragment,E),i(h.$$.fragment,E),i($.$$.fragment,E),i(w.$$.fragment,E),i(N.$$.fragment,E),i(f.$$.fragment,E),i(x.$$.fragment,E),q=!0)},o(E){u(n.$$.fragment,E),u(r.$$.fragment,E),u(o.$$.fragment,E),u(l.$$.fragment,E),u(h.$$.fragment,E),u($.$$.fragment,E),u(w.$$.fragment,E),u(N.$$.fragment,E),u(f.$$.fragment,E),u(x.$$.fragment,E),q=!1},d(E){E&&s(t),c(n),c(r),c(o),c(l),c(h),c($),c(w),c(N),c(f),c(x)}}}function Cr(_){let t;return{c(){t=k("recurrent neural network")},l(n){t=W(n,"recurrent neural network")},m(n,r){d(n,t,r)},d(n){n&&s(t)}}}function Dr(_){let t,n;return t=new lr({props:{f:_[12],delta:5}}),{c(){m(t.$$.fragment)},l(r){p(t.$$.fragment,r)},m(r,o){g(t,r,o),n=!0},p:j,i(r){n||(i(t.$$.fragment,r),n=!0)},o(r){u(t.$$.fragment,r),n=!1},d(r){c(t,r)}}}function wr(_){let t,n;return t=new S({props:{x:50+_[16]*40,y:"30",width:"20",height:"20",text:_[16]+1,fontSize:15,color:_[9]===_[16]?"var(--main-color-1)":"var(--main-color-4)"}}),{c(){m(t.$$.fragment)},l(r){p(t.$$.fragment,r)},m(r,o){g(t,r,o),n=!0},p(r,o){const l={};o&512&&(l.color=r[9]===r[16]?"var(--main-color-1)":"var(--main-color-4)"),t.$set(l)},i(r){n||(i(t.$$.fragment,r),n=!0)},o(r){u(t.$$.fragment,r),n=!1},d(r){c(t,r)}}}function Rr(_){let t,n,r,o,l,h,$,w,N,f,x,q,E,v=Array(4),y=[];for(let A=0;A<v.length;A+=1)y[A]=wr(dr(_,v,A));const B=A=>u(y[A],1,1,()=>{y[A]=null});return r=new O({props:{strokeWidth:"2",data:[{x:5,y:50},{x:65,y:50}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),o=new O({props:{strokeWidth:"2",data:[{x:250,y:125},{x:250,y:190},{x:10,y:190},{x:10,y:150},{x:65,y:150}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),l=new O({props:{strokeWidth:"2",data:[{x:130,y:50},{x:215,y:90}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),h=new O({props:{strokeWidth:"2",data:[{x:130,y:150},{x:215,y:110}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),$=new O({props:{strokeWidth:"2",data:[{x:280,y:100},{x:380,y:100}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),w=new S({props:{x:"100",y:"50",width:"20",height:"20",class:"fill-slate-300"}}),N=new S({props:{x:"100",y:"150",width:"20",height:"20",class:"fill-slate-300"}}),f=new S({props:{x:"250",y:"100",width:"50",height:"50",class:"fill-slate-500"}}),x=new kt({props:{x:_[5],y:_[7],r:"5",color:"var(--main-color-1)"}}),q=new kt({props:{x:_[6],y:_[8],r:"5",color:"var(--main-color-1)"}}),{c(){t=Z("svg");for(let A=0;A<y.length;A+=1)y[A].c();n=Z("g"),m(r.$$.fragment),m(o.$$.fragment),m(l.$$.fragment),m(h.$$.fragment),m($.$$.fragment),m(w.$$.fragment),m(N.$$.fragment),m(f.$$.fragment),m(x.$$.fragment),m(q.$$.fragment),this.h()},l(A){t=ee(A,"svg",{viewBox:!0});var P=T(t);for(let G=0;G<y.length;G+=1)y[G].l(P);n=ee(P,"g",{transform:!0});var I=T(n);p(r.$$.fragment,I),p(o.$$.fragment,I),p(l.$$.fragment,I),p(h.$$.fragment,I),p($.$$.fragment,I),p(w.$$.fragment,I),p(N.$$.fragment,I),p(f.$$.fragment,I),p(x.$$.fragment,I),p(q.$$.fragment,I),I.forEach(s),P.forEach(s),this.h()},h(){L(n,"transform","translate(0 50)"),L(t,"viewBox","0 0 400 250")},m(A,P){d(A,t,P);for(let I=0;I<y.length;I+=1)y[I]&&y[I].m(t,null);b(t,n),g(r,n,null),g(o,n,null),g(l,n,null),g(h,n,null),g($,n,null),g(w,n,null),g(N,n,null),g(f,n,null),g(x,n,null),g(q,n,null),E=!0},p(A,P){if(P&512){v=Array(4);let F;for(F=0;F<v.length;F+=1){const Ee=dr(A,v,F);y[F]?(y[F].p(Ee,P),i(y[F],1)):(y[F]=wr(Ee),y[F].c(),i(y[F],1),y[F].m(t,n))}for(xr(),F=v.length;F<y.length;F+=1)B(F);kr()}const I={};P&32&&(I.x=A[5]),P&128&&(I.y=A[7]),x.$set(I);const G={};P&64&&(G.x=A[6]),P&256&&(G.y=A[8]),q.$set(G)},i(A){if(!E){for(let P=0;P<v.length;P+=1)i(y[P]);i(r.$$.fragment,A),i(o.$$.fragment,A),i(l.$$.fragment,A),i(h.$$.fragment,A),i($.$$.fragment,A),i(w.$$.fragment,A),i(N.$$.fragment,A),i(f.$$.fragment,A),i(x.$$.fragment,A),i(q.$$.fragment,A),E=!0}},o(A){y=y.filter(Boolean);for(let P=0;P<y.length;P+=1)u(y[P]);u(r.$$.fragment,A),u(o.$$.fragment,A),u(l.$$.fragment,A),u(h.$$.fragment,A),u($.$$.fragment,A),u(w.$$.fragment,A),u(N.$$.fragment,A),u(f.$$.fragment,A),u(x.$$.fragment,A),u(q.$$.fragment,A),E=!1},d(A){A&&s(t),or(y,A),c(r),c(o),c(l),c(h),c($),c(w),c(N),c(f),c(x),c(q)}}}function Br(_){let t,n,r,o,l,h;return n=new O({props:{strokeWidth:"1.2",data:[{x:40,y:150},{x:40,y:100}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),r=new O({props:{strokeWidth:"1.2",data:[{x:50,y:55},{x:50,y:10}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),o=new O({props:{strokeWidth:"1.2",data:[{x:70,y:75},{x:90,y:75},{x:90,y:115},{x:60,y:115},{x:60,y:100}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),l=new S({props:{x:"50",y:"75",width:"30",height:"30",class:"fill-slate-500"}}),{c(){t=Z("svg"),m(n.$$.fragment),m(r.$$.fragment),m(o.$$.fragment),m(l.$$.fragment),this.h()},l($){t=ee($,"svg",{viewBox:!0});var w=T(t);p(n.$$.fragment,w),p(r.$$.fragment,w),p(o.$$.fragment,w),p(l.$$.fragment,w),w.forEach(s),this.h()},h(){L(t,"viewBox","0 0 100 150")},m($,w){d($,t,w),g(n,t,null),g(r,t,null),g(o,t,null),g(l,t,null),h=!0},p:j,i($){h||(i(n.$$.fragment,$),i(r.$$.fragment,$),i(o.$$.fragment,$),i(l.$$.fragment,$),h=!0)},o($){u(n.$$.fragment,$),u(r.$$.fragment,$),u(o.$$.fragment,$),u(l.$$.fragment,$),h=!1},d($){$&&s(t),c(n),c(r),c(o),c(l)}}}function Pr(_){let t;return{c(){t=k("memory cell")},l(n){t=W(n,"memory cell")},m(n,r){d(n,t,r)},d(n){n&&s(t)}}}function Sr(_){let t;return{c(){t=k("cell")},l(n){t=W(n,"cell")},m(n,r){d(n,t,r)},d(n){n&&s(t)}}}function Or(_){let t,n,r,o,l,h,$,w,N,f,x,q,E,v;return n=new O({props:{strokeWidth:"1",data:[{x:40,y:150},{x:40,y:100}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),r=new O({props:{strokeWidth:"1",data:[{x:50,y:55},{x:50,y:10}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),o=new O({props:{strokeWidth:"1",data:[{x:70,y:75},{x:90,y:75},{x:90,y:115},{x:60,y:115},{x:60,y:100}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),l=new S({props:{x:"50",y:"75",width:"30",height:"30",class:"fill-slate-500"}}),h=new S({props:{x:"39",y:"85",width:"5",height:"5",class:"fill-blue-200"}}),$=new S({props:{x:"46",y:"85",width:"5",height:"5",class:"fill-blue-200"}}),w=new S({props:{x:"53",y:"85",width:"5",height:"5",class:"fill-red-400"}}),N=new S({props:{x:"60",y:"85",width:"5",height:"5",class:"fill-red-400"}}),f=new S({props:{x:"70",y:"75",width:"5",height:"5",class:"fill-red-400"}}),x=new S({props:{x:"78",y:"75",width:"5",height:"5",class:"fill-red-400"}}),q=new S({props:{x:"40",y:"130",width:"5",height:"5",class:"fill-blue-200"}}),E=new S({props:{x:"40",y:"140",width:"5",height:"5",class:"fill-blue-200"}}),{c(){t=Z("svg"),m(n.$$.fragment),m(r.$$.fragment),m(o.$$.fragment),m(l.$$.fragment),m(h.$$.fragment),m($.$$.fragment),m(w.$$.fragment),m(N.$$.fragment),m(f.$$.fragment),m(x.$$.fragment),m(q.$$.fragment),m(E.$$.fragment),this.h()},l(y){t=ee(y,"svg",{viewBox:!0});var B=T(t);p(n.$$.fragment,B),p(r.$$.fragment,B),p(o.$$.fragment,B),p(l.$$.fragment,B),p(h.$$.fragment,B),p($.$$.fragment,B),p(w.$$.fragment,B),p(N.$$.fragment,B),p(f.$$.fragment,B),p(x.$$.fragment,B),p(q.$$.fragment,B),p(E.$$.fragment,B),B.forEach(s),this.h()},h(){L(t,"viewBox","0 0 100 150")},m(y,B){d(y,t,B),g(n,t,null),g(r,t,null),g(o,t,null),g(l,t,null),g(h,t,null),g($,t,null),g(w,t,null),g(N,t,null),g(f,t,null),g(x,t,null),g(q,t,null),g(E,t,null),v=!0},p:j,i(y){v||(i(n.$$.fragment,y),i(r.$$.fragment,y),i(o.$$.fragment,y),i(l.$$.fragment,y),i(h.$$.fragment,y),i($.$$.fragment,y),i(w.$$.fragment,y),i(N.$$.fragment,y),i(f.$$.fragment,y),i(x.$$.fragment,y),i(q.$$.fragment,y),i(E.$$.fragment,y),v=!0)},o(y){u(n.$$.fragment,y),u(r.$$.fragment,y),u(o.$$.fragment,y),u(l.$$.fragment,y),u(h.$$.fragment,y),u($.$$.fragment,y),u(w.$$.fragment,y),u(N.$$.fragment,y),u(f.$$.fragment,y),u(x.$$.fragment,y),u(q.$$.fragment,y),u(E.$$.fragment,y),v=!1},d(y){y&&s(t),c(n),c(r),c(o),c(l),c(h),c($),c(w),c(N),c(f),c(x),c(q),c(E)}}}function Ir(_){let t,n,r,o,l,h,$,w,N;return n=new O({props:{strokeWidth:"2",data:[{x:31,y:45},{x:76,y:45}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),r=new O({props:{strokeWidth:"2",data:[{x:120,y:45},{x:164,y:45}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),o=new O({props:{strokeWidth:"2",data:[{x:100,y:62},{x:100,y:140}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),l=new S({props:{x:"100",y:"45",width:"30",height:"30",class:"fill-slate-500"}}),h=new S({props:{text:"x_"+(_[16]+1),type:"latex",fontSize:12,x:"15",y:"45",width:"25",height:"25",class:"fill-blue-100"}}),$=new S({props:{type:"latex",text:"y_"+(_[16]+1),fontSize:12,x:"185",y:"45",width:"25",height:"25",class:"fill-blue-100"}}),w=new S({props:{type:"latex",text:"h_"+(_[16]+1),fontSize:12,x:"100",y:"100",width:"25",height:"25",class:"fill-yellow-100"}}),{c(){t=Z("g"),m(n.$$.fragment),m(r.$$.fragment),m(o.$$.fragment),m(l.$$.fragment),m(h.$$.fragment),m($.$$.fragment),m(w.$$.fragment),this.h()},l(f){t=ee(f,"g",{transform:!0});var x=T(t);p(n.$$.fragment,x),p(r.$$.fragment,x),p(o.$$.fragment,x),p(l.$$.fragment,x),p(h.$$.fragment,x),p($.$$.fragment,x),p(w.$$.fragment,x),x.forEach(s),this.h()},h(){L(t,"transform","translate(0, "+(_[16]*120-20)+")")},m(f,x){d(f,t,x),g(n,t,null),g(r,t,null),g(o,t,null),g(l,t,null),g(h,t,null),g($,t,null),g(w,t,null),N=!0},p:j,i(f){N||(i(n.$$.fragment,f),i(r.$$.fragment,f),i(o.$$.fragment,f),i(l.$$.fragment,f),i(h.$$.fragment,f),i($.$$.fragment,f),i(w.$$.fragment,f),N=!0)},o(f){u(n.$$.fragment,f),u(r.$$.fragment,f),u(o.$$.fragment,f),u(l.$$.fragment,f),u(h.$$.fragment,f),u($.$$.fragment,f),u(w.$$.fragment,f),N=!1},d(f){f&&s(t),c(n),c(r),c(o),c(l),c(h),c($),c(w)}}}function Lr(_){let t,n,r=Array(4),o=[];for(let l=0;l<r.length;l+=1)o[l]=Ir(Er(_,r,l));return{c(){t=Z("svg");for(let l=0;l<o.length;l+=1)o[l].c();this.h()},l(l){t=ee(l,"svg",{viewBox:!0});var h=T(t);for(let $=0;$<o.length;$+=1)o[$].l(h);h.forEach(s),this.h()},h(){L(t,"viewBox","0 0 200 470")},m(l,h){d(l,t,h);for(let $=0;$<o.length;$+=1)o[$]&&o[$].m(t,null);n=!0},p:j,i(l){if(!n){for(let h=0;h<r.length;h+=1)i(o[h]);n=!0}},o(l){o=o.filter(Boolean);for(let h=0;h<o.length;h+=1)u(o[h]);n=!1},d(l){l&&s(t),or(o,l)}}}function Fr(_){let t=String.raw`\mathbf{y_t}`+"",n;return{c(){n=k(t)},l(r){n=W(r,t)},m(r,o){d(r,n,o)},p:j,d(r){r&&s(n)}}}function Hr(_){let t=String.raw`\mathbf{h_t}`+"",n;return{c(){n=k(t)},l(r){n=W(r,t)},m(r,o){d(r,n,o)},p:j,d(r){r&&s(n)}}}function Mr(_){let t=String.raw`\mathbf{h}_t`+"",n;return{c(){n=k(t)},l(r){n=W(r,t)},m(r,o){d(r,n,o)},p:j,d(r){r&&s(n)}}}function jr(_){let t=String.raw`\mathbf{W_h}`+"",n;return{c(){n=k(t)},l(r){n=W(r,t)},m(r,o){d(r,n,o)},p:j,d(r){r&&s(n)}}}function Gr(_){let t=String.raw`\mathbf{W_x}`+"",n;return{c(){n=k(t)},l(r){n=W(r,t)},m(r,o){d(r,n,o)},p:j,d(r){r&&s(n)}}}function Vr(_){let t=String.raw`\mathbf{h_t} = f(\mathbf{h_{t-1}}\mathbf{W_h}^T + \mathbf{x_t} \mathbf{W_x}^T + b)`+"",n;return{c(){n=k(t)},l(r){n=W(r,t)},m(r,o){d(r,n,o)},p:j,d(r){r&&s(n)}}}function Qr(_){let t;return{c(){t=k("backpropagation through time")},l(n){t=W(n,"backpropagation through time")},m(n,r){d(n,t,r)},d(n){n&&s(t)}}}function Jr(_){let t,n,r,o,l,h,$,w,N,f,x,q,E;return n=new O({props:{strokeWidth:"2",data:[{x:31,y:45},{x:76,y:45}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),r=new O({props:{strokeWidth:"2",data:[{x:120,y:45},{x:160,y:45}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),o=new O({props:{strokeWidth:"2",data:[{x:205,y:45},{x:260,y:45}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),l=new O({props:{strokeWidth:"2",data:[{x:100,y:62},{x:100,y:140}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),h=new O({props:{strokeWidth:"2",data:[{x:185,y:62},{x:185,y:140}],dashed:!0,moving:!0,strokeDashArray:"4 4"}}),$=new S({props:{x:"100",y:"45",width:"30",height:"30",class:"fill-slate-500"}}),w=new S({props:{text:"x_"+(_[16]+1),type:"latex",fontSize:12,x:"15",y:"45",width:"25",height:"25",class:"fill-blue-100"}}),N=new S({props:{x:"185",y:"45",width:"30",height:"30",class:"fill-red-500"}}),f=new S({props:{type:"latex",text:"y_"+(_[16]+1),fontSize:12,x:"285",y:"45",width:"25",height:"25",class:"fill-blue-100"}}),x=new S({props:{type:"latex",text:"h_"+(_[16]+1),fontSize:12,x:"100",y:"100",width:"25",height:"25",class:"fill-yellow-100"}}),q=new S({props:{type:"latex",text:"h_"+(_[16]+1),fontSize:12,x:"185",y:"100",width:"25",height:"25",class:"fill-green-100"}}),{c(){t=Z("g"),m(n.$$.fragment),m(r.$$.fragment),m(o.$$.fragment),m(l.$$.fragment),m(h.$$.fragment),m($.$$.fragment),m(w.$$.fragment),m(N.$$.fragment),m(f.$$.fragment),m(x.$$.fragment),m(q.$$.fragment),this.h()},l(v){t=ee(v,"g",{transform:!0});var y=T(t);p(n.$$.fragment,y),p(r.$$.fragment,y),p(o.$$.fragment,y),p(l.$$.fragment,y),p(h.$$.fragment,y),p($.$$.fragment,y),p(w.$$.fragment,y),p(N.$$.fragment,y),p(f.$$.fragment,y),p(x.$$.fragment,y),p(q.$$.fragment,y),y.forEach(s),this.h()},h(){L(t,"transform","translate(0, "+(_[16]*120-20)+")")},m(v,y){d(v,t,y),g(n,t,null),g(r,t,null),g(o,t,null),g(l,t,null),g(h,t,null),g($,t,null),g(w,t,null),g(N,t,null),g(f,t,null),g(x,t,null),g(q,t,null),E=!0},p:j,i(v){E||(i(n.$$.fragment,v),i(r.$$.fragment,v),i(o.$$.fragment,v),i(l.$$.fragment,v),i(h.$$.fragment,v),i($.$$.fragment,v),i(w.$$.fragment,v),i(N.$$.fragment,v),i(f.$$.fragment,v),i(x.$$.fragment,v),i(q.$$.fragment,v),E=!0)},o(v){u(n.$$.fragment,v),u(r.$$.fragment,v),u(o.$$.fragment,v),u(l.$$.fragment,v),u(h.$$.fragment,v),u($.$$.fragment,v),u(w.$$.fragment,v),u(N.$$.fragment,v),u(f.$$.fragment,v),u(x.$$.fragment,v),u(q.$$.fragment,v),E=!1},d(v){v&&s(t),c(n),c(r),c(o),c(l),c(h),c($),c(w),c(N),c(f),c(x),c(q)}}}function Kr(_){let t,n,r=Array(4),o=[];for(let l=0;l<r.length;l+=1)o[l]=Jr(Nr(_,r,l));return{c(){t=Z("svg");for(let l=0;l<o.length;l+=1)o[l].c();this.h()},l(l){t=ee(l,"svg",{viewBox:!0});var h=T(t);for(let $=0;$<o.length;$+=1)o[$].l(h);h.forEach(s),this.h()},h(){L(t,"viewBox","0 0 300 470")},m(l,h){d(l,t,h);for(let $=0;$<o.length;$+=1)o[$]&&o[$].m(t,null);n=!0},p:j,i(l){if(!n){for(let h=0;h<r.length;h+=1)i(o[h]);n=!0}},o(l){o=o.filter(Boolean);for(let h=0;h<o.length;h+=1)u(o[h]);n=!1},d(l){l&&s(t),or(o,l)}}}function Ur(_){let t=String.raw`\mathbf{y}`+"",n;return{c(){n=k(t)},l(r){n=W(r,t)},m(r,o){d(r,n,o)},p:j,d(r){r&&s(n)}}}function Xr(_){let t=String.raw`\mathbf{h}_n`+"",n;return{c(){n=k(t)},l(r){n=W(r,t)},m(r,o){d(r,n,o)},p:j,d(r){r&&s(n)}}}function Yr(_){let t,n,r,o,l,h,$,w,N,f,x,q,E,v,y,B,A,P,I,G,F,Ee,Le,on,Wt,Fe,ln,Nt,se,Et,ae,qt,He,fn,At,oe,Tt,U,un,le,$n,fe,hn,zt,Me,mn,Ct,ie,Dt,je,pn,Rt,ue,Bt,X,gn,$e,cn,he,dn,Pt,V,wn,me,_n,pe,yn,ge,vn,ce,bn,St,de,xn,we,kn,Ot,Ge,Wn,It,_e,Lt,Ve,Nn,Ft,H,En,ye,Ue,qn,An,ve,Xe,Tn,zn,Ye,Cn,Dn,Ze,Rn,Bn,et,Pn,Sn,tt,On,In,Ht,qe,Mt,K,Ln,nt,Fn,Hn,rt,Mn,jn,st,Gn,Vn,jt,Qe,Qn,Gt,Ae,Vt,Te,Qt,Q,Jn,at,Kn,Un,be,Xn,ot,Yn,Zn,xe,er,Jt,ze,Kt,Ce,Ut,ke,tr,lt,nr,rr,Xt,De,Yt,Re,Zt,Je,sr,en,Be,tn,Pe,nn,Ke,rn;return $=new ar({props:{$$slots:{default:[qr]},$$scope:{ctx:_}}}),N=new Ie({props:{maxWidth:"600px",$$slots:{default:[Ar]},$$scope:{ctx:_}}}),v=new ar({props:{$$slots:{default:[Tr]},$$scope:{ctx:_}}}),B=new Ie({props:{maxWidth:"600px",$$slots:{default:[zr]},$$scope:{ctx:_}}}),G=new an({props:{$$slots:{default:[Cr]},$$scope:{ctx:_}}}),se=new ar({props:{$$slots:{default:[Dr]},$$scope:{ctx:_}}}),ae=new Ie({props:{maxWidth:"600px",$$slots:{default:[Rr]},$$scope:{ctx:_}}}),oe=new Ie({props:{maxWidth:"200px",$$slots:{default:[Br]},$$scope:{ctx:_}}}),le=new an({props:{$$slots:{default:[Pr]},$$scope:{ctx:_}}}),fe=new an({props:{$$slots:{default:[Sr]},$$scope:{ctx:_}}}),ie=new Ie({props:{maxWidth:"300px",$$slots:{default:[Or]},$$scope:{ctx:_}}}),ue=new Ie({props:{maxWidth:"250px",$$slots:{default:[Lr]},$$scope:{ctx:_}}}),$e=new Ne({props:{$$slots:{default:[Fr]},$$scope:{ctx:_}}}),he=new Ne({props:{$$slots:{default:[Hr]},$$scope:{ctx:_}}}),me=new Ne({props:{$$slots:{default:[Mr]},$$scope:{ctx:_}}}),pe=new Ne({props:{$$slots:{default:[jr]},$$scope:{ctx:_}}}),ge=new Ne({props:{$$slots:{default:[Gr]},$$scope:{ctx:_}}}),ce=new Ne({props:{$$slots:{default:[Vr]},$$scope:{ctx:_}}}),we=new an({props:{$$slots:{default:[Qr]},$$scope:{ctx:_}}}),_e=new Ie({props:{maxWidth:"350px",$$slots:{default:[Kr]},$$scope:{ctx:_}}}),qe=new re({props:{code:`# number of samples in our dataset
batch_size=4
#sequence lengths represents for example the number of words in a sentence 
sequence_length=5
# dimensionality of each input in the sequence
# so each value in the sequence is a vector of length 6
input_size=6
# the output dimension of each RNN layer
hidden_size=3
# number of recurrent layers in the network
num_layers=2
`}}),Ae=new re({props:{code:`rnn = nn.RNN(input_size=input_size, 
             hidden_size=hidden_size, 
             num_layers=num_layers,
             nonlinearity='tanh')`}}),Te=new re({props:{code:`sequence = torch.randn(sequence_length, batch_size, input_size)
h_0 = torch.zeros(num_layers, batch_size, hidden_size)`}}),be=new Ne({props:{$$slots:{default:[Ur]},$$scope:{ctx:_}}}),xe=new Ne({props:{$$slots:{default:[Xr]},$$scope:{ctx:_}}}),ze=new re({props:{code:`with torch.inference_mode():
    output, h_n = rnn(sequence, h_0)
print(output.shape, h_n.shape)`}}),Ce=new re({props:{code:"torch.Size([5, 4, 3]) torch.Size([2, 4, 3])",isOutput:!0}}),De=new re({props:{code:`cell = nn.RNNCell(input_size=input_size, 
                    hidden_size=hidden_size, 
                    nonlinearity='tanh')`}}),Re=new re({props:{code:`sequence = torch.randn(sequence_length, batch_size, input_size)
h_n = torch.zeros(batch_size, hidden_size)`}}),Be=new re({props:{code:`with torch.inference_mode():
    for t in range(sequence_length):
        h_n = cell(sequence[t], h_t)
print(h_t.shape)`}}),Pe=new re({props:{code:"torch.Size([4, 3])",isOutput:!0}}),{c(){t=D("p"),n=k(`Let's start this section by contrasting and comparing a plain vanilla feed
    forward neural network with a recurrent neural network.`),r=z(),o=D("p"),l=k(`Let's assume for the moment that we are dealing with a single neuron that
    receives a single input. This input could for example be the current
    temperature level and our prediction is the temperature for the next day.
    The feedforward neural network processes the input and generates the output.
    Once the input has left the neuron it is forgotten. This neuron has no
    memory.`),h=z(),m($.$$.fragment),w=z(),m(N.$$.fragment),f=z(),x=D("p"),q=k(`When the model is dealing with sequences, it should probably remember at
    least some parts of the previous inputs. The meaning of a sentence for
    example depends on the understanding of the whole sentence and not a single
    word. A similar argument can be made for the prediction of the temperature.
    It would probably be useful for the model to remember the temperature of the
    previous couple of days. We could try to circumvent the problem by adding
    additional neuron. Two neurons for example could be used to represent the
    temperature from the past day and the day before that. The output of the two
    neurons would be passed to the next layer.`),E=z(),m(v.$$.fragment),y=z(),m(B.$$.fragment),A=z(),P=D("p"),I=k(`The above approach does not completely solve the problem though. Many
    sequences have a variable length. The length of a sentence that we would
    like to translate for example can change dramatically. We need a more
    flexible system. A `),m(G.$$.fragment),F=k(` offers a way
    out.`),Ee=z(),Le=D("p"),on=k(`A recurrent neural network (often abbreviated as RNN) processes each piece
    of a sequence at a time. At each time step the neuron takes a part of the
    sequence and its own output from the previous timestep as input. In the very
    first time step there is no output from the previous step, so it is common
    to use 0 instead.`),Wt=z(),Fe=D("p"),ln=k(`Below for example we are dealing with a sequence of size 4. This could for
    example be temperature measuremets from the 4 previous days. Once the
    sequence is exhaused, the output is sent to the next unit, for example the
    next recurrent layer.`),Nt=z(),m(se.$$.fragment),Et=z(),m(ae.$$.fragment),qt=z(),He=D("p"),fn=k(`When you start to study recurrent neural networks, you might encounter a
    specific visual notation for RNNs, similar to the one below. This notation
    represents a recurrent neural network as a self referential unit.`),At=z(),m(oe.$$.fragment),Tt=z(),U=D("p"),un=k(`As the neural network has to remember the output from the previous run, you
    can say that it posesses a type of a memory. Such a unit is therefore often
    called a `),m(le.$$.fragment),$n=k(" or simply "),m(fe.$$.fragment),hn=k("."),zt=z(),Me=D("p"),mn=k(`So far we used only two numbers as an input into a RNN: the current sequence
    value and the previous output. In reality this cell works with vectors just
    like a feedforward neural network. Below for example the unit takes four
    inputs: two come from the part of a sequence and two from the previous
    output.`),Ct=z(),m(ie.$$.fragment),Dt=z(),je=D("p"),pn=k(`We can unroll the recurrent neural network through time. Taking the example
    with a four part sequence from before, the unrolled network will look as
    follows.`),Rt=z(),m(ue.$$.fragment),Bt=z(),X=D("p"),gn=k(`While the unrolled network looks like it consists of four units, you
    shouldn't forget that we are dealing with the same layer. That means that
    each of the boxes in the middle has the same weights and the same bias. At
    this point we also make a distinction between outputs `),m($e.$$.fragment),cn=k(`
    and the hidden units `),m(he.$$.fragment),dn=k(`. For the time
    being there is no difference between the hidden units and the outputs, but
    we will see shortly that there might be differences.`),Pt=z(),V=D("p"),wn=k("We use two sets of weights to calculate the hidden value "),m(me.$$.fragment),_n=k(": the weight to process the previous hidden values "),m(pe.$$.fragment),yn=k(" and the weights to process the sequence "),m(ge.$$.fragment),vn=k(". The hidden value is therefore calculated as "),m(ce.$$.fragment),bn=k(`. The activation function that is used most commonly with recurrent neural
    networks is tanh. Because we use the very same weights for the whole
    sequence, if the weights are above 1, we will deal with exploding gradients,
    therefore a saturating activation function is preferred. On the other hand a
    long sequence like a sentence or a book, that can consist of hundreds of
    steps, will cause vanishing gradients. We will look into ways of dealing
    with those in the next sections.`),St=z(),de=D("p"),xn=k(`We will not go over the whole process of backpropagation for recurrent
    neural networks, called `),m(we.$$.fragment),kn=k(`.
    Still we will give you an intuition how you might approach calculating
    gradients for a RNN. In essence backpropagation for fully connected neural
    networks and RNNs is not different. We can use automatic differentiation the
    same way we did in the previous chapters. When you unroll a recurrent neural
    network, each part of a sequence is processed by the same weights and
    gradients are accumulated for those weights in the process. Once the whole
    sequence is exhausted, we can use backpropagation and apply gradient
    descent.`),Ot=z(),Ge=D("p"),Wn=k(`Often we will want to create several recurrent layers. In that case the
    hidden outputs of the series are used as the inputs into the next layer.`),It=z(),m(_e.$$.fragment),Lt=z(),Ve=D("p"),Nn=k(`This time around there is a destinction between the output and the hidden
    values. We regard the output to be the hidden values from the very last
    layer.`),Ft=z(),H=D("p"),En=k(`In PyTorch we can either use the
    `),ye=D("a"),Ue=D("code"),qn=k("nn.RNN"),An=k(`
    module or the
    `),ve=D("a"),Xe=D("code"),Tn=k("nn.RNNCell"),zn=k(`. Both can be used to achive the same goal, but
    `),Ye=D("code"),Cn=k("nn.RNN"),Dn=k(` unrolls the neural net automatically, while the
    `),Ze=D("code"),Rn=k("nn.RNNCell"),Bn=k(` module needs to be applied to each part of the
    sequence manually. Often it is more convenient to simply use
    `),et=D("code"),Pn=k("nn.RNN"),Sn=k(`, but some more complex architecures will require us to
    use of `),tt=D("code"),On=k("nn.RNNCell"),In=k("."),Ht=z(),m(qe.$$.fragment),Mt=z(),K=D("p"),Ln=k("A recurrent neural network in PyTorch uses an input of shape of "),nt=D("code"),Fn=k("(sequence length, batch size, input_size)"),Hn=k(`
    as the default. If you set the parameter `),rt=D("code"),Mn=k("batch_first"),jn=k(` to True,
    then you must provide the shape
    `),st=D("code"),Gn=k("(batch size, sequence length, input_size)"),Vn=k(`. For now we will use
    the default behaviour, but in some future examples it will be convenient to
    set this to True.`),jt=z(),Qe=D("p"),Qn=k(`We create a module and generate two tensors: the first is our dummy sequence
    and the second is the initial value for the hidden state.`),Gt=z(),m(Ae.$$.fragment),Vt=z(),m(Te.$$.fragment),Qt=z(),Q=D("p"),Jn=k("The recurrent network generates two outputs. The "),at=D("code"),Kn=k("output"),Un=k(` tensor
    corresponds to the `),m(be.$$.fragment),Xn=k(` values from the diagrams
    above. We get an output vector of dimension 3 for each of the 5 values in the
    sequence and each of the 4 batches, therefore the output dimension is (5, 4,
    3). The `),ot=D("code"),Yn=k("h_n"),Zn=k(`
    tensor contains the last hidden values for all layers. This would correspond
    to `),m(xe.$$.fragment),er=k(` values in the diagram above. Given
    that we have 2 layers, 4 batches and hidden units of dimension 3, the dimensionality
    is (2, 4, 3).`),Jt=z(),m(ze.$$.fragment),Kt=z(),m(Ce.$$.fragment),Ut=z(),ke=D("p"),tr=k(`When we want to have more control over the learning process, we might need
    to resort to `),lt=D("code"),nr=k("nn.RNNCell"),rr=k(`. Each such cell represents a recurrent
    layer, so if you want to use more leayers, you have to create more cells.`),Xt=z(),m(De.$$.fragment),Yt=z(),m(Re.$$.fragment),Zt=z(),Je=D("p"),sr=k(`This time we loop over the sequence manually, always using the last hidden
    state as the input in the next iteration.`),en=z(),m(Be.$$.fragment),tn=z(),m(Pe.$$.fragment),nn=z(),Ke=D("div"),this.h()},l(e){t=R(e,"P",{});var a=T(t);n=W(a,`Let's start this section by contrasting and comparing a plain vanilla feed
    forward neural network with a recurrent neural network.`),a.forEach(s),r=C(e),o=R(e,"P",{});var ft=T(o);l=W(ft,`Let's assume for the moment that we are dealing with a single neuron that
    receives a single input. This input could for example be the current
    temperature level and our prediction is the temperature for the next day.
    The feedforward neural network processes the input and generates the output.
    Once the input has left the neuron it is forgotten. This neuron has no
    memory.`),ft.forEach(s),h=C(e),p($.$$.fragment,e),w=C(e),p(N.$$.fragment,e),f=C(e),x=R(e,"P",{});var it=T(x);q=W(it,`When the model is dealing with sequences, it should probably remember at
    least some parts of the previous inputs. The meaning of a sentence for
    example depends on the understanding of the whole sentence and not a single
    word. A similar argument can be made for the prediction of the temperature.
    It would probably be useful for the model to remember the temperature of the
    previous couple of days. We could try to circumvent the problem by adding
    additional neuron. Two neurons for example could be used to represent the
    temperature from the past day and the day before that. The output of the two
    neurons would be passed to the next layer.`),it.forEach(s),E=C(e),p(v.$$.fragment,e),y=C(e),p(B.$$.fragment,e),A=C(e),P=R(e,"P",{});var Se=T(P);I=W(Se,`The above approach does not completely solve the problem though. Many
    sequences have a variable length. The length of a sentence that we would
    like to translate for example can change dramatically. We need a more
    flexible system. A `),p(G.$$.fragment,Se),F=W(Se,` offers a way
    out.`),Se.forEach(s),Ee=C(e),Le=R(e,"P",{});var ut=T(Le);on=W(ut,`A recurrent neural network (often abbreviated as RNN) processes each piece
    of a sequence at a time. At each time step the neuron takes a part of the
    sequence and its own output from the previous timestep as input. In the very
    first time step there is no output from the previous step, so it is common
    to use 0 instead.`),ut.forEach(s),Wt=C(e),Fe=R(e,"P",{});var $t=T(Fe);ln=W($t,`Below for example we are dealing with a sequence of size 4. This could for
    example be temperature measuremets from the 4 previous days. Once the
    sequence is exhaused, the output is sent to the next unit, for example the
    next recurrent layer.`),$t.forEach(s),Nt=C(e),p(se.$$.fragment,e),Et=C(e),p(ae.$$.fragment,e),qt=C(e),He=R(e,"P",{});var ht=T(He);fn=W(ht,`When you start to study recurrent neural networks, you might encounter a
    specific visual notation for RNNs, similar to the one below. This notation
    represents a recurrent neural network as a self referential unit.`),ht.forEach(s),At=C(e),p(oe.$$.fragment,e),Tt=C(e),U=R(e,"P",{});var te=T(U);un=W(te,`As the neural network has to remember the output from the previous run, you
    can say that it posesses a type of a memory. Such a unit is therefore often
    called a `),p(le.$$.fragment,te),$n=W(te," or simply "),p(fe.$$.fragment,te),hn=W(te,"."),te.forEach(s),zt=C(e),Me=R(e,"P",{});var mt=T(Me);mn=W(mt,`So far we used only two numbers as an input into a RNN: the current sequence
    value and the previous output. In reality this cell works with vectors just
    like a feedforward neural network. Below for example the unit takes four
    inputs: two come from the part of a sequence and two from the previous
    output.`),mt.forEach(s),Ct=C(e),p(ie.$$.fragment,e),Dt=C(e),je=R(e,"P",{});var pt=T(je);pn=W(pt,`We can unroll the recurrent neural network through time. Taking the example
    with a four part sequence from before, the unrolled network will look as
    follows.`),pt.forEach(s),Rt=C(e),p(ue.$$.fragment,e),Bt=C(e),X=R(e,"P",{});var ne=T(X);gn=W(ne,`While the unrolled network looks like it consists of four units, you
    shouldn't forget that we are dealing with the same layer. That means that
    each of the boxes in the middle has the same weights and the same bias. At
    this point we also make a distinction between outputs `),p($e.$$.fragment,ne),cn=W(ne,`
    and the hidden units `),p(he.$$.fragment,ne),dn=W(ne,`. For the time
    being there is no difference between the hidden units and the outputs, but
    we will see shortly that there might be differences.`),ne.forEach(s),Pt=C(e),V=R(e,"P",{});var J=T(V);wn=W(J,"We use two sets of weights to calculate the hidden value "),p(me.$$.fragment,J),_n=W(J,": the weight to process the previous hidden values "),p(pe.$$.fragment,J),yn=W(J," and the weights to process the sequence "),p(ge.$$.fragment,J),vn=W(J,". The hidden value is therefore calculated as "),p(ce.$$.fragment,J),bn=W(J,`. The activation function that is used most commonly with recurrent neural
    networks is tanh. Because we use the very same weights for the whole
    sequence, if the weights are above 1, we will deal with exploding gradients,
    therefore a saturating activation function is preferred. On the other hand a
    long sequence like a sentence or a book, that can consist of hundreds of
    steps, will cause vanishing gradients. We will look into ways of dealing
    with those in the next sections.`),J.forEach(s),St=C(e),de=R(e,"P",{});var Oe=T(de);xn=W(Oe,`We will not go over the whole process of backpropagation for recurrent
    neural networks, called `),p(we.$$.fragment,Oe),kn=W(Oe,`.
    Still we will give you an intuition how you might approach calculating
    gradients for a RNN. In essence backpropagation for fully connected neural
    networks and RNNs is not different. We can use automatic differentiation the
    same way we did in the previous chapters. When you unroll a recurrent neural
    network, each part of a sequence is processed by the same weights and
    gradients are accumulated for those weights in the process. Once the whole
    sequence is exhausted, we can use backpropagation and apply gradient
    descent.`),Oe.forEach(s),Ot=C(e),Ge=R(e,"P",{});var gt=T(Ge);Wn=W(gt,`Often we will want to create several recurrent layers. In that case the
    hidden outputs of the series are used as the inputs into the next layer.`),gt.forEach(s),It=C(e),p(_e.$$.fragment,e),Lt=C(e),Ve=R(e,"P",{});var ct=T(Ve);Nn=W(ct,`This time around there is a destinction between the output and the hidden
    values. We regard the output to be the hidden values from the very last
    layer.`),ct.forEach(s),Ft=C(e),H=R(e,"P",{});var M=T(H);En=W(M,`In PyTorch we can either use the
    `),ye=R(M,"A",{target:!0,rel:!0,href:!0});var dt=T(ye);Ue=R(dt,"CODE",{});var wt=T(Ue);qn=W(wt,"nn.RNN"),wt.forEach(s),dt.forEach(s),An=W(M,`
    module or the
    `),ve=R(M,"A",{target:!0,rel:!0,href:!0});var _t=T(ve);Xe=R(_t,"CODE",{});var yt=T(Xe);Tn=W(yt,"nn.RNNCell"),yt.forEach(s),_t.forEach(s),zn=W(M,`. Both can be used to achive the same goal, but
    `),Ye=R(M,"CODE",{});var vt=T(Ye);Cn=W(vt,"nn.RNN"),vt.forEach(s),Dn=W(M,` unrolls the neural net automatically, while the
    `),Ze=R(M,"CODE",{});var bt=T(Ze);Rn=W(bt,"nn.RNNCell"),bt.forEach(s),Bn=W(M,` module needs to be applied to each part of the
    sequence manually. Often it is more convenient to simply use
    `),et=R(M,"CODE",{});var xt=T(et);Pn=W(xt,"nn.RNN"),xt.forEach(s),Sn=W(M,`, but some more complex architecures will require us to
    use of `),tt=R(M,"CODE",{});var fr=T(tt);On=W(fr,"nn.RNNCell"),fr.forEach(s),In=W(M,"."),M.forEach(s),Ht=C(e),p(qe.$$.fragment,e),Mt=C(e),K=R(e,"P",{});var We=T(K);Ln=W(We,"A recurrent neural network in PyTorch uses an input of shape of "),nt=R(We,"CODE",{});var ir=T(nt);Fn=W(ir,"(sequence length, batch size, input_size)"),ir.forEach(s),Hn=W(We,`
    as the default. If you set the parameter `),rt=R(We,"CODE",{});var ur=T(rt);Mn=W(ur,"batch_first"),ur.forEach(s),jn=W(We,` to True,
    then you must provide the shape
    `),st=R(We,"CODE",{});var $r=T(st);Gn=W($r,"(batch size, sequence length, input_size)"),$r.forEach(s),Vn=W(We,`. For now we will use
    the default behaviour, but in some future examples it will be convenient to
    set this to True.`),We.forEach(s),jt=C(e),Qe=R(e,"P",{});var hr=T(Qe);Qn=W(hr,`We create a module and generate two tensors: the first is our dummy sequence
    and the second is the initial value for the hidden state.`),hr.forEach(s),Gt=C(e),p(Ae.$$.fragment,e),Vt=C(e),p(Te.$$.fragment,e),Qt=C(e),Q=R(e,"P",{});var Y=T(Q);Jn=W(Y,"The recurrent network generates two outputs. The "),at=R(Y,"CODE",{});var mr=T(at);Kn=W(mr,"output"),mr.forEach(s),Un=W(Y,` tensor
    corresponds to the `),p(be.$$.fragment,Y),Xn=W(Y,` values from the diagrams
    above. We get an output vector of dimension 3 for each of the 5 values in the
    sequence and each of the 4 batches, therefore the output dimension is (5, 4,
    3). The `),ot=R(Y,"CODE",{});var pr=T(ot);Yn=W(pr,"h_n"),pr.forEach(s),Zn=W(Y,`
    tensor contains the last hidden values for all layers. This would correspond
    to `),p(xe.$$.fragment,Y),er=W(Y,` values in the diagram above. Given
    that we have 2 layers, 4 batches and hidden units of dimension 3, the dimensionality
    is (2, 4, 3).`),Y.forEach(s),Jt=C(e),p(ze.$$.fragment,e),Kt=C(e),p(Ce.$$.fragment,e),Ut=C(e),ke=R(e,"P",{});var sn=T(ke);tr=W(sn,`When we want to have more control over the learning process, we might need
    to resort to `),lt=R(sn,"CODE",{});var gr=T(lt);nr=W(gr,"nn.RNNCell"),gr.forEach(s),rr=W(sn,`. Each such cell represents a recurrent
    layer, so if you want to use more leayers, you have to create more cells.`),sn.forEach(s),Xt=C(e),p(De.$$.fragment,e),Yt=C(e),p(Re.$$.fragment,e),Zt=C(e),Je=R(e,"P",{});var cr=T(Je);sr=W(cr,`This time we loop over the sequence manually, always using the last hidden
    state as the input in the next iteration.`),cr.forEach(s),en=C(e),p(Be.$$.fragment,e),tn=C(e),p(Pe.$$.fragment,e),nn=C(e),Ke=R(e,"DIV",{class:!0}),T(Ke).forEach(s),this.h()},h(){L(ye,"target","_blank"),L(ye,"rel","noreferrer"),L(ye,"href","https://pytorch.org/docs/stable/generated/torch.nn.RNN.html"),L(ve,"target","_blank"),L(ve,"rel","noreferrer"),L(ve,"href","https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html"),L(Ke,"class","separator")},m(e,a){d(e,t,a),b(t,n),d(e,r,a),d(e,o,a),b(o,l),d(e,h,a),g($,e,a),d(e,w,a),g(N,e,a),d(e,f,a),d(e,x,a),b(x,q),d(e,E,a),g(v,e,a),d(e,y,a),g(B,e,a),d(e,A,a),d(e,P,a),b(P,I),g(G,P,null),b(P,F),d(e,Ee,a),d(e,Le,a),b(Le,on),d(e,Wt,a),d(e,Fe,a),b(Fe,ln),d(e,Nt,a),g(se,e,a),d(e,Et,a),g(ae,e,a),d(e,qt,a),d(e,He,a),b(He,fn),d(e,At,a),g(oe,e,a),d(e,Tt,a),d(e,U,a),b(U,un),g(le,U,null),b(U,$n),g(fe,U,null),b(U,hn),d(e,zt,a),d(e,Me,a),b(Me,mn),d(e,Ct,a),g(ie,e,a),d(e,Dt,a),d(e,je,a),b(je,pn),d(e,Rt,a),g(ue,e,a),d(e,Bt,a),d(e,X,a),b(X,gn),g($e,X,null),b(X,cn),g(he,X,null),b(X,dn),d(e,Pt,a),d(e,V,a),b(V,wn),g(me,V,null),b(V,_n),g(pe,V,null),b(V,yn),g(ge,V,null),b(V,vn),g(ce,V,null),b(V,bn),d(e,St,a),d(e,de,a),b(de,xn),g(we,de,null),b(de,kn),d(e,Ot,a),d(e,Ge,a),b(Ge,Wn),d(e,It,a),g(_e,e,a),d(e,Lt,a),d(e,Ve,a),b(Ve,Nn),d(e,Ft,a),d(e,H,a),b(H,En),b(H,ye),b(ye,Ue),b(Ue,qn),b(H,An),b(H,ve),b(ve,Xe),b(Xe,Tn),b(H,zn),b(H,Ye),b(Ye,Cn),b(H,Dn),b(H,Ze),b(Ze,Rn),b(H,Bn),b(H,et),b(et,Pn),b(H,Sn),b(H,tt),b(tt,On),b(H,In),d(e,Ht,a),g(qe,e,a),d(e,Mt,a),d(e,K,a),b(K,Ln),b(K,nt),b(nt,Fn),b(K,Hn),b(K,rt),b(rt,Mn),b(K,jn),b(K,st),b(st,Gn),b(K,Vn),d(e,jt,a),d(e,Qe,a),b(Qe,Qn),d(e,Gt,a),g(Ae,e,a),d(e,Vt,a),g(Te,e,a),d(e,Qt,a),d(e,Q,a),b(Q,Jn),b(Q,at),b(at,Kn),b(Q,Un),g(be,Q,null),b(Q,Xn),b(Q,ot),b(ot,Yn),b(Q,Zn),g(xe,Q,null),b(Q,er),d(e,Jt,a),g(ze,e,a),d(e,Kt,a),g(Ce,e,a),d(e,Ut,a),d(e,ke,a),b(ke,tr),b(ke,lt),b(lt,nr),b(ke,rr),d(e,Xt,a),g(De,e,a),d(e,Yt,a),g(Re,e,a),d(e,Zt,a),d(e,Je,a),b(Je,sr),d(e,en,a),g(Be,e,a),d(e,tn,a),g(Pe,e,a),d(e,nn,a),d(e,Ke,a),rn=!0},p(e,a){const ft={};a&524288&&(ft.$$scope={dirty:a,ctx:e}),$.$set(ft);const it={};a&524289&&(it.$$scope={dirty:a,ctx:e}),N.$set(it);const Se={};a&524288&&(Se.$$scope={dirty:a,ctx:e}),v.$set(Se);const ut={};a&524318&&(ut.$$scope={dirty:a,ctx:e}),B.$set(ut);const $t={};a&524288&&($t.$$scope={dirty:a,ctx:e}),G.$set($t);const ht={};a&524288&&(ht.$$scope={dirty:a,ctx:e}),se.$set(ht);const te={};a&525280&&(te.$$scope={dirty:a,ctx:e}),ae.$set(te);const mt={};a&524288&&(mt.$$scope={dirty:a,ctx:e}),oe.$set(mt);const pt={};a&524288&&(pt.$$scope={dirty:a,ctx:e}),le.$set(pt);const ne={};a&524288&&(ne.$$scope={dirty:a,ctx:e}),fe.$set(ne);const J={};a&524288&&(J.$$scope={dirty:a,ctx:e}),ie.$set(J);const Oe={};a&524288&&(Oe.$$scope={dirty:a,ctx:e}),ue.$set(Oe);const gt={};a&524288&&(gt.$$scope={dirty:a,ctx:e}),$e.$set(gt);const ct={};a&524288&&(ct.$$scope={dirty:a,ctx:e}),he.$set(ct);const M={};a&524288&&(M.$$scope={dirty:a,ctx:e}),me.$set(M);const dt={};a&524288&&(dt.$$scope={dirty:a,ctx:e}),pe.$set(dt);const wt={};a&524288&&(wt.$$scope={dirty:a,ctx:e}),ge.$set(wt);const _t={};a&524288&&(_t.$$scope={dirty:a,ctx:e}),ce.$set(_t);const yt={};a&524288&&(yt.$$scope={dirty:a,ctx:e}),we.$set(yt);const vt={};a&524288&&(vt.$$scope={dirty:a,ctx:e}),_e.$set(vt);const bt={};a&524288&&(bt.$$scope={dirty:a,ctx:e}),be.$set(bt);const xt={};a&524288&&(xt.$$scope={dirty:a,ctx:e}),xe.$set(xt)},i(e){rn||(i($.$$.fragment,e),i(N.$$.fragment,e),i(v.$$.fragment,e),i(B.$$.fragment,e),i(G.$$.fragment,e),i(se.$$.fragment,e),i(ae.$$.fragment,e),i(oe.$$.fragment,e),i(le.$$.fragment,e),i(fe.$$.fragment,e),i(ie.$$.fragment,e),i(ue.$$.fragment,e),i($e.$$.fragment,e),i(he.$$.fragment,e),i(me.$$.fragment,e),i(pe.$$.fragment,e),i(ge.$$.fragment,e),i(ce.$$.fragment,e),i(we.$$.fragment,e),i(_e.$$.fragment,e),i(qe.$$.fragment,e),i(Ae.$$.fragment,e),i(Te.$$.fragment,e),i(be.$$.fragment,e),i(xe.$$.fragment,e),i(ze.$$.fragment,e),i(Ce.$$.fragment,e),i(De.$$.fragment,e),i(Re.$$.fragment,e),i(Be.$$.fragment,e),i(Pe.$$.fragment,e),rn=!0)},o(e){u($.$$.fragment,e),u(N.$$.fragment,e),u(v.$$.fragment,e),u(B.$$.fragment,e),u(G.$$.fragment,e),u(se.$$.fragment,e),u(ae.$$.fragment,e),u(oe.$$.fragment,e),u(le.$$.fragment,e),u(fe.$$.fragment,e),u(ie.$$.fragment,e),u(ue.$$.fragment,e),u($e.$$.fragment,e),u(he.$$.fragment,e),u(me.$$.fragment,e),u(pe.$$.fragment,e),u(ge.$$.fragment,e),u(ce.$$.fragment,e),u(we.$$.fragment,e),u(_e.$$.fragment,e),u(qe.$$.fragment,e),u(Ae.$$.fragment,e),u(Te.$$.fragment,e),u(be.$$.fragment,e),u(xe.$$.fragment,e),u(ze.$$.fragment,e),u(Ce.$$.fragment,e),u(De.$$.fragment,e),u(Re.$$.fragment,e),u(Be.$$.fragment,e),u(Pe.$$.fragment,e),rn=!1},d(e){e&&s(t),e&&s(r),e&&s(o),e&&s(h),c($,e),e&&s(w),c(N,e),e&&s(f),e&&s(x),e&&s(E),c(v,e),e&&s(y),c(B,e),e&&s(A),e&&s(P),c(G),e&&s(Ee),e&&s(Le),e&&s(Wt),e&&s(Fe),e&&s(Nt),c(se,e),e&&s(Et),c(ae,e),e&&s(qt),e&&s(He),e&&s(At),c(oe,e),e&&s(Tt),e&&s(U),c(le),c(fe),e&&s(zt),e&&s(Me),e&&s(Ct),c(ie,e),e&&s(Dt),e&&s(je),e&&s(Rt),c(ue,e),e&&s(Bt),e&&s(X),c($e),c(he),e&&s(Pt),e&&s(V),c(me),c(pe),c(ge),c(ce),e&&s(St),e&&s(de),c(we),e&&s(Ot),e&&s(Ge),e&&s(It),c(_e,e),e&&s(Lt),e&&s(Ve),e&&s(Ft),e&&s(H),e&&s(Ht),c(qe,e),e&&s(Mt),e&&s(K),e&&s(jt),e&&s(Qe),e&&s(Gt),c(Ae,e),e&&s(Vt),c(Te,e),e&&s(Qt),e&&s(Q),c(be),c(xe),e&&s(Jt),c(ze,e),e&&s(Kt),c(Ce,e),e&&s(Ut),e&&s(ke),e&&s(Xt),c(De,e),e&&s(Yt),c(Re,e),e&&s(Zt),e&&s(Je),e&&s(en),c(Be,e),e&&s(tn),c(Pe,e),e&&s(nn),e&&s(Ke)}}}function Zr(_){let t,n,r,o,l,h,$,w,N;return w=new Wr({props:{$$slots:{default:[Yr]},$$scope:{ctx:_}}}),{c(){t=D("meta"),n=z(),r=D("h1"),o=k("Recurrent Neural Networks"),l=z(),h=D("div"),$=z(),m(w.$$.fragment),this.h()},l(f){const x=br("svelte-7r8r05",document.head);t=R(x,"META",{name:!0,content:!0}),x.forEach(s),n=C(f),r=R(f,"H1",{});var q=T(r);o=W(q,"Recurrent Neural Networks"),q.forEach(s),l=C(f),h=R(f,"DIV",{class:!0}),T(h).forEach(s),$=C(f),p(w.$$.fragment,f),this.h()},h(){document.title="Recurrent Neural Networks - World4AI",L(t,"name","description"),L(t,"content","A recurrent neural network is very well suited to process sequential data. The RNN processes one piece at a time and keeps the outputs from the previous parts of the sequence in the memory which is used as an additional input in the next step."),L(h,"class","separator")},m(f,x){b(document.head,t),d(f,n,x),d(f,r,x),b(r,o),d(f,l,x),d(f,h,x),d(f,$,x),g(w,f,x),N=!0},p(f,[x]){const q={};x&525311&&(q.$$scope={dirty:x,ctx:f}),w.$set(q)},i(f){N||(i(w.$$.fragment,f),N=!0)},o(f){u(w.$$.fragment,f),N=!1},d(f){s(t),f&&s(n),f&&s(r),f&&s(l),f&&s(h),f&&s($),c(w,f)}}}let es=50,ts=3;function ns(_,t,n){let r=100;function o(){n(0,r+=1),r>=400&&n(0,r=100)}let l=10,h=10,$=50,w=150;function N(){n(1,l+=1),n(2,h+=1),l>=130&&$<100.5&&(n(3,$+=.45),n(4,w-=.45)),l>225&&(n(3,$=100),n(4,w=100)),l>=350&&(n(1,l=10),n(2,h=10),n(3,$=50),n(4,w=150))}let f=10,x=10,q=50,E=150,v=0,y=!1;function B(){y?q<190&&f>=250?(n(7,q+=1),n(8,E+=1)):q>=190&&f>10?(n(5,f-=1),n(6,x-=1)):f<=10&&q>150?(n(7,q-=1),n(8,E-=1)):(y=!1,n(5,f=10),n(6,x=10),n(7,q=50),n(8,E=150),n(9,v+=1)):(n(5,f+=1),n(6,x+=1),f>=130&&q<100.5&&(n(7,q+=.45),n(8,E-=.45)),f>225&&(n(7,q=100),n(8,E=100)),f>=250&&v<ts&&(y=!0),f>=350&&(n(5,f=10),n(6,x=10),n(7,q=50),n(8,E=150),n(9,v=0)))}return[r,l,h,$,w,f,x,q,E,v,o,N,B]}class ps extends _r{constructor(t){super(),yr(this,t,ns,Zr,vr,{})}}export{ps as default};
