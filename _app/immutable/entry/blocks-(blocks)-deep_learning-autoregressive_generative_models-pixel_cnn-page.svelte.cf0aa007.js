import{S as Ln,i as qn,s as Un,k as E,a as A,y as g,W as On,l as T,h,c as z,z as _,n as m,N as C,b as c,A as v,g as w,d as k,B as x,q as P,m as $,r as B,L as Gn,Q as I,R as L,P as q,e as M,C as j}from"../chunks/index.4d92b023.js";import{C as Hn}from"../chunks/Container.b0705c7b.js";import{F as Vn,I as Fn}from"../chunks/InternalLink.7deb899c.js";import{P as In}from"../chunks/PlayButton.85103c5a.js";import{B as rn}from"../chunks/ButtonContainer.e9aac418.js";import{H as bt}from"../chunks/Highlight.b7c1de53.js";import{P as Kt}from"../chunks/PythonCode.212ba7a6.js";import{S as ke}from"../chunks/SvgContainer.f70b5745.js";import{B as U}from"../chunks/Block.059eddcd.js";import{A as Me}from"../chunks/Arrow.ae91874c.js";import{P as jn}from"../chunks/Plus.fc904b16.js";const Kn=""+new URL("../assets/generated_images.d51f44b4.webp",import.meta.url).href;function on(f,t,r){const e=f.slice();return e[4]=t[r],e[6]=r,e}function an(f,t,r){const e=f.slice();return e[4]=t[r],e[8]=r,e}function sn(f,t,r){const e=f.slice();return e[4]=t[r],e[6]=r,e}function fn(f,t,r){const e=f.slice();return e[4]=t[r],e[8]=r,e}function hn(f,t,r){const e=f.slice();return e[4]=t[r],e[6]=r,e}function un(f,t,r){const e=f.slice();return e[4]=t[r],e[8]=r,e}function cn(f,t,r){const e=f.slice();return e[4]=t[r],e[6]=r,e}function mn(f,t,r){const e=f.slice();return e[4]=t[r],e[8]=r,e}function pn(f,t,r){const e=f.slice();return e[4]=t[r],e[6]=r,e}function dn(f,t,r){const e=f.slice();return e[4]=t[r],e[8]=r,e}function $n(f,t,r){const e=f.slice();return e[4]=t[r],e[6]=r,e}function gn(f,t,r){const e=f.slice();return e[4]=t[r],e[8]=r,e}function _n(f,t,r){const e=f.slice();return e[4]=t[r],e[6]=r,e}function vn(f,t,r){const e=f.slice();return e[4]=t[r],e[8]=r,e}function wn(f,t,r){const e=f.slice();return e[4]=t[r],e[6]=r,e}function kn(f,t,r){const e=f.slice();return e[4]=t[r],e[8]=r,e}function Yn(f){let t;return{c(){t=P("PixelCNN")},l(r){t=B(r,"PixelCNN")},m(r,e){c(r,t,e)},d(r){r&&h(t)}}}function Qn(f){let t;return{c(){t=P("masked convolutions")},l(r){t=B(r,"masked convolutions")},m(r,e){c(r,t,e)},d(r){r&&h(t)}}}function xn(f){let t;return{c(){t=I("rect"),this.h()},l(r){t=L(r,"rect",{x:!0,y:!0,width:!0,height:!0,class:!0,stroke:!0}),$(t).forEach(h),this.h()},h(){m(t,"x",2+f[6]*(b+5)),m(t,"y",2+f[8]*(b+5)),m(t,"width",b),m(t,"height",b),m(t,"class","fill-slate-300"),m(t,"stroke","black")},m(r,e){c(r,t,e)},p:j,d(r){r&&h(t)}}}function yn(f){let t,r=Array(S),e=[];for(let n=0;n<r.length;n+=1)e[n]=xn(kn(f,r,n));return{c(){for(let n=0;n<e.length;n+=1)e[n].c();t=M()},l(n){for(let a=0;a<e.length;a+=1)e[a].l(n);t=M()},m(n,a){for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(n,a);c(n,t,a)},p(n,a){if(a&0){r=Array(S);let l;for(l=0;l<r.length;l+=1){const o=kn(n,r,l);e[l]?e[l].p(o,a):(e[l]=xn(o),e[l].c(),e[l].m(t.parentNode,t))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){q(e,n),n&&h(t)}}}function Jn(f){let t,r=Array(S),e=[];for(let n=0;n<r.length;n+=1)e[n]=yn(wn(f,r,n));return{c(){t=I("svg");for(let n=0;n<e.length;n+=1)e[n].c();this.h()},l(n){t=L(n,"svg",{viewBox:!0});var a=$(t);for(let l=0;l<e.length;l+=1)e[l].l(a);a.forEach(h),this.h()},h(){m(t,"viewBox","0 0 120 120")},m(n,a){c(n,t,a);for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(t,null)},p(n,a){if(a&0){r=Array(S);let l;for(l=0;l<r.length;l+=1){const o=wn(n,r,l);e[l]?e[l].p(o,a):(e[l]=yn(o),e[l].c(),e[l].m(t,null))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){n&&h(t),q(e,n)}}}function bn(f){let t;return{c(){t=I("rect"),this.h()},l(r){t=L(r,"rect",{x:!0,y:!0,width:!0,height:!0,class:!0,stroke:!0}),$(t).forEach(h),this.h()},h(){m(t,"x",2+f[6]*(b+5)),m(t,"y",2+f[8]*(b+5)),m(t,"width",b),m(t,"height",b),m(t,"class",f[6]<N||f[8]<N||f[6]>=S+N||f[8]>=S+N?"fill-white":"fill-slate-300"),m(t,"stroke","black")},m(r,e){c(r,t,e)},p:j,d(r){r&&h(t)}}}function Nn(f){let t,r=Array(S+N*2),e=[];for(let n=0;n<r.length;n+=1)e[n]=bn(vn(f,r,n));return{c(){for(let n=0;n<e.length;n+=1)e[n].c();t=M()},l(n){for(let a=0;a<e.length;a+=1)e[a].l(n);t=M()},m(n,a){for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(n,a);c(n,t,a)},p(n,a){if(a&0){r=Array(S+N*2);let l;for(l=0;l<r.length;l+=1){const o=vn(n,r,l);e[l]?e[l].p(o,a):(e[l]=bn(o),e[l].c(),e[l].m(t.parentNode,t))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){q(e,n),n&&h(t)}}}function Xn(f){let t,r=Array(S+N*2),e=[];for(let n=0;n<r.length;n+=1)e[n]=Nn(_n(f,r,n));return{c(){t=I("svg");for(let n=0;n<e.length;n+=1)e[n].c();this.h()},l(n){t=L(n,"svg",{viewBox:!0});var a=$(t);for(let l=0;l<e.length;l+=1)e[l].l(a);a.forEach(h),this.h()},h(){m(t,"viewBox","0 0 180 180")},m(n,a){c(n,t,a);for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(t,null)},p(n,a){if(a&0){r=Array(S+N*2);let l;for(l=0;l<r.length;l+=1){const o=_n(n,r,l);e[l]?e[l].p(o,a):(e[l]=Nn(o),e[l].c(),e[l].m(t,null))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){n&&h(t),q(e,n)}}}function An(f){let t;return{c(){t=I("rect"),this.h()},l(r){t=L(r,"rect",{x:!0,y:!0,width:!0,height:!0,class:!0,stroke:!0}),$(t).forEach(h),this.h()},h(){m(t,"x",2+f[6]*(b+5)),m(t,"y",2+f[8]*(b+5)),m(t,"width",b),m(t,"height",b),m(t,"class",f[6]<N||f[8]<N||f[6]>=S+N||f[8]>=S+N?"fill-white":"fill-slate-300"),m(t,"stroke","black")},m(r,e){c(r,t,e)},p:j,d(r){r&&h(t)}}}function zn(f){let t,r=Array(S+N*2),e=[];for(let n=0;n<r.length;n+=1)e[n]=An(gn(f,r,n));return{c(){for(let n=0;n<e.length;n+=1)e[n].c();t=M()},l(n){for(let a=0;a<e.length;a+=1)e[a].l(n);t=M()},m(n,a){for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(n,a);c(n,t,a)},p(n,a){if(a&0){r=Array(S+N*2);let l;for(l=0;l<r.length;l+=1){const o=gn(n,r,l);e[l]?e[l].p(o,a):(e[l]=An(o),e[l].c(),e[l].m(t.parentNode,t))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){q(e,n),n&&h(t)}}}function Cn(f){let t;return{c(){t=I("circle"),this.h()},l(r){t=L(r,"circle",{cx:!0,cy:!0,r:!0,class:!0,stroke:!0}),$(t).forEach(h),this.h()},h(){m(t,"cx",2+f[6]*(b+5)+b/2),m(t,"cy",2+f[8]*(b+5)+b/2),m(t,"r",4),m(t,"class","fill-red-400"),m(t,"stroke","black")},m(r,e){c(r,t,e)},p:j,d(r){r&&h(t)}}}function Pn(f){let t,r=Array(O),e=[];for(let n=0;n<r.length;n+=1)e[n]=Cn(dn(f,r,n));return{c(){for(let n=0;n<e.length;n+=1)e[n].c();t=M()},l(n){for(let a=0;a<e.length;a+=1)e[a].l(n);t=M()},m(n,a){for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(n,a);c(n,t,a)},p(n,a){if(a&0){r=Array(O);let l;for(l=0;l<r.length;l+=1){const o=dn(n,r,l);e[l]?e[l].p(o,a):(e[l]=Cn(o),e[l].c(),e[l].m(t.parentNode,t))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){q(e,n),n&&h(t)}}}function Zn(f){let t,r,e=Array(S+N*2),n=[];for(let o=0;o<e.length;o+=1)n[o]=zn($n(f,e,o));let a=Array(O),l=[];for(let o=0;o<a.length;o+=1)l[o]=Pn(pn(f,a,o));return{c(){t=I("svg");for(let o=0;o<n.length;o+=1)n[o].c();r=M();for(let o=0;o<l.length;o+=1)l[o].c();this.h()},l(o){t=L(o,"svg",{viewBox:!0});var p=$(t);for(let s=0;s<n.length;s+=1)n[s].l(p);r=M();for(let s=0;s<l.length;s+=1)l[s].l(p);p.forEach(h),this.h()},h(){m(t,"viewBox","0 0 180 180")},m(o,p){c(o,t,p);for(let s=0;s<n.length;s+=1)n[s]&&n[s].m(t,null);C(t,r);for(let s=0;s<l.length;s+=1)l[s]&&l[s].m(t,null)},p(o,p){if(p&0){e=Array(S+N*2);let s;for(s=0;s<e.length;s+=1){const d=$n(o,e,s);n[s]?n[s].p(d,p):(n[s]=zn(d),n[s].c(),n[s].m(t,r))}for(;s<n.length;s+=1)n[s].d(1);n.length=e.length}if(p&0){a=Array(O);let s;for(s=0;s<a.length;s+=1){const d=pn(o,a,s);l[s]?l[s].p(d,p):(l[s]=Pn(d),l[s].c(),l[s].m(t,null))}for(;s<l.length;s+=1)l[s].d(1);l.length=a.length}},d(o){o&&h(t),q(n,o),q(l,o)}}}function el(f){let t,r;return t=new In({props:{f:f[3],delta:500}}),{c(){g(t.$$.fragment)},l(e){_(t.$$.fragment,e)},m(e,n){v(t,e,n),r=!0},p:j,i(e){r||(w(t.$$.fragment,e),r=!0)},o(e){k(t.$$.fragment,e),r=!1},d(e){x(t,e)}}}function Bn(f){let t;return{c(){t=I("rect"),this.h()},l(r){t=L(r,"rect",{x:!0,y:!0,width:!0,height:!0,class:!0,stroke:!0}),$(t).forEach(h),this.h()},h(){m(t,"x",2+f[6]*(b+5)),m(t,"y",2+f[8]*(b+5)),m(t,"width",b),m(t,"height",b),m(t,"class",f[6]<N||f[8]<N||f[6]>=S+N||f[8]>=S+N?"fill-white":"fill-slate-300"),m(t,"stroke","black")},m(r,e){c(r,t,e)},p:j,d(r){r&&h(t)}}}function En(f){let t,r=Array(S+N*2),e=[];for(let n=0;n<r.length;n+=1)e[n]=Bn(mn(f,r,n));return{c(){for(let n=0;n<e.length;n+=1)e[n].c();t=M()},l(n){for(let a=0;a<e.length;a+=1)e[a].l(n);t=M()},m(n,a){for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(n,a);c(n,t,a)},p(n,a){if(a&0){r=Array(S+N*2);let l;for(l=0;l<r.length;l+=1){const o=mn(n,r,l);e[l]?e[l].p(o,a):(e[l]=Bn(o),e[l].c(),e[l].m(t.parentNode,t))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){q(e,n),n&&h(t)}}}function Tn(f){let t,r,e;return{c(){t=I("circle"),this.h()},l(n){t=L(n,"circle",{cx:!0,cy:!0,r:!0,class:!0,stroke:!0}),$(t).forEach(h),this.h()},h(){m(t,"cx",r=2+(f[6]+f[1])*(b+5)+b/2),m(t,"cy",e=2+(f[8]+f[0])*(b+5)+b/2),m(t,"r",4),m(t,"class",f[8]<N||f[8]===N&&f[6]<N?"fill-red-400":"fill-none"),m(t,"stroke","black")},m(n,a){c(n,t,a)},p(n,a){a&2&&r!==(r=2+(n[6]+n[1])*(b+5)+b/2)&&m(t,"cx",r),a&1&&e!==(e=2+(n[8]+n[0])*(b+5)+b/2)&&m(t,"cy",e)},d(n){n&&h(t)}}}function Sn(f){let t,r=Array(O),e=[];for(let n=0;n<r.length;n+=1)e[n]=Tn(un(f,r,n));return{c(){for(let n=0;n<e.length;n+=1)e[n].c();t=M()},l(n){for(let a=0;a<e.length;a+=1)e[a].l(n);t=M()},m(n,a){for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(n,a);c(n,t,a)},p(n,a){if(a&3){r=Array(O);let l;for(l=0;l<r.length;l+=1){const o=un(n,r,l);e[l]?e[l].p(o,a):(e[l]=Tn(o),e[l].c(),e[l].m(t.parentNode,t))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){q(e,n),n&&h(t)}}}function tl(f){let t,r,e=Array(S+N*2),n=[];for(let o=0;o<e.length;o+=1)n[o]=En(cn(f,e,o));let a=Array(O),l=[];for(let o=0;o<a.length;o+=1)l[o]=Sn(hn(f,a,o));return{c(){t=I("svg");for(let o=0;o<n.length;o+=1)n[o].c();r=M();for(let o=0;o<l.length;o+=1)l[o].c();this.h()},l(o){t=L(o,"svg",{viewBox:!0});var p=$(t);for(let s=0;s<n.length;s+=1)n[s].l(p);r=M();for(let s=0;s<l.length;s+=1)l[s].l(p);p.forEach(h),this.h()},h(){m(t,"viewBox","0 0 180 180")},m(o,p){c(o,t,p);for(let s=0;s<n.length;s+=1)n[s]&&n[s].m(t,null);C(t,r);for(let s=0;s<l.length;s+=1)l[s]&&l[s].m(t,null)},p(o,p){if(p&0){e=Array(S+N*2);let s;for(s=0;s<e.length;s+=1){const d=cn(o,e,s);n[s]?n[s].p(d,p):(n[s]=En(d),n[s].c(),n[s].m(t,r))}for(;s<n.length;s+=1)n[s].d(1);n.length=e.length}if(p&3){a=Array(O);let s;for(s=0;s<a.length;s+=1){const d=hn(o,a,s);l[s]?l[s].p(d,p):(l[s]=Sn(d),l[s].c(),l[s].m(t,null))}for(;s<l.length;s+=1)l[s].d(1);l.length=a.length}},d(o){o&&h(t),q(n,o),q(l,o)}}}function nl(f){let t;return{c(){t=P("A")},l(r){t=B(r,"A")},m(r,e){c(r,t,e)},d(r){r&&h(t)}}}function ll(f){let t;return{c(){t=P("B")},l(r){t=B(r,"B")},m(r,e){c(r,t,e)},d(r){r&&h(t)}}}function il(f){let t,r;return t=new In({props:{f:f[3],delta:500}}),{c(){g(t.$$.fragment)},l(e){_(t.$$.fragment,e)},m(e,n){v(t,e,n),r=!0},p:j,i(e){r||(w(t.$$.fragment,e),r=!0)},o(e){k(t.$$.fragment,e),r=!1},d(e){x(t,e)}}}function Wn(f){let t;return{c(){t=I("rect"),this.h()},l(r){t=L(r,"rect",{x:!0,y:!0,width:!0,height:!0,class:!0,stroke:!0}),$(t).forEach(h),this.h()},h(){m(t,"x",2+f[6]*(b+5)),m(t,"y",2+f[8]*(b+5)),m(t,"width",b),m(t,"height",b),m(t,"class",f[6]<N||f[8]<N||f[6]>=S+N||f[8]>=S+N?"fill-white":"fill-slate-300"),m(t,"stroke","black")},m(r,e){c(r,t,e)},p:j,d(r){r&&h(t)}}}function Mn(f){let t,r=Array(S+N*2),e=[];for(let n=0;n<r.length;n+=1)e[n]=Wn(fn(f,r,n));return{c(){for(let n=0;n<e.length;n+=1)e[n].c();t=M()},l(n){for(let a=0;a<e.length;a+=1)e[a].l(n);t=M()},m(n,a){for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(n,a);c(n,t,a)},p(n,a){if(a&0){r=Array(S+N*2);let l;for(l=0;l<r.length;l+=1){const o=fn(n,r,l);e[l]?e[l].p(o,a):(e[l]=Wn(o),e[l].c(),e[l].m(t.parentNode,t))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){q(e,n),n&&h(t)}}}function Rn(f){let t,r,e;return{c(){t=I("circle"),this.h()},l(n){t=L(n,"circle",{cx:!0,cy:!0,r:!0,class:!0,stroke:!0}),$(t).forEach(h),this.h()},h(){m(t,"cx",r=2+(f[6]+f[1])*(b+5)+b/2),m(t,"cy",e=2+(f[8]+f[0])*(b+5)+b/2),m(t,"r",4),m(t,"class",f[8]<N||f[8]===N&&f[6]<=N?"fill-red-400":"fill-none"),m(t,"stroke","black")},m(n,a){c(n,t,a)},p(n,a){a&2&&r!==(r=2+(n[6]+n[1])*(b+5)+b/2)&&m(t,"cx",r),a&1&&e!==(e=2+(n[8]+n[0])*(b+5)+b/2)&&m(t,"cy",e)},d(n){n&&h(t)}}}function Dn(f){let t,r=Array(O),e=[];for(let n=0;n<r.length;n+=1)e[n]=Rn(an(f,r,n));return{c(){for(let n=0;n<e.length;n+=1)e[n].c();t=M()},l(n){for(let a=0;a<e.length;a+=1)e[a].l(n);t=M()},m(n,a){for(let l=0;l<e.length;l+=1)e[l]&&e[l].m(n,a);c(n,t,a)},p(n,a){if(a&3){r=Array(O);let l;for(l=0;l<r.length;l+=1){const o=an(n,r,l);e[l]?e[l].p(o,a):(e[l]=Rn(o),e[l].c(),e[l].m(t.parentNode,t))}for(;l<e.length;l+=1)e[l].d(1);e.length=r.length}},d(n){q(e,n),n&&h(t)}}}function rl(f){let t,r,e=Array(S+N*2),n=[];for(let o=0;o<e.length;o+=1)n[o]=Mn(sn(f,e,o));let a=Array(O),l=[];for(let o=0;o<a.length;o+=1)l[o]=Dn(on(f,a,o));return{c(){t=I("svg");for(let o=0;o<n.length;o+=1)n[o].c();r=M();for(let o=0;o<l.length;o+=1)l[o].c();this.h()},l(o){t=L(o,"svg",{viewBox:!0});var p=$(t);for(let s=0;s<n.length;s+=1)n[s].l(p);r=M();for(let s=0;s<l.length;s+=1)l[s].l(p);p.forEach(h),this.h()},h(){m(t,"viewBox","0 0 180 180")},m(o,p){c(o,t,p);for(let s=0;s<n.length;s+=1)n[s]&&n[s].m(t,null);C(t,r);for(let s=0;s<l.length;s+=1)l[s]&&l[s].m(t,null)},p(o,p){if(p&0){e=Array(S+N*2);let s;for(s=0;s<e.length;s+=1){const d=sn(o,e,s);n[s]?n[s].p(d,p):(n[s]=Mn(d),n[s].c(),n[s].m(t,r))}for(;s<n.length;s+=1)n[s].d(1);n.length=e.length}if(p&3){a=Array(O);let s;for(s=0;s<a.length;s+=1){const d=on(o,a,s);l[s]?l[s].p(d,p):(l[s]=Dn(d),l[s].c(),l[s].m(t,null))}for(;s<l.length;s+=1)l[s].d(1);l.length=a.length}},d(o){o&&h(t),q(n,o),q(l,o)}}}function ol(f){let t,r,e,n,a,l,o,p,s,d,W,G,D,H,V,K;return e=new jn({props:{x:30,y:40,radius:10,offset:4}}),n=new U({props:{x:"160",y:"200",width:"100",height:"30",text:"1x1 Conv",fontSize:"20px",class:"fill-blue-100"}}),a=new U({props:{x:"160",y:"120",width:"100",height:"30",text:"3x3 Conv",fontSize:"20px",class:"fill-red-100"}}),l=new U({props:{x:"160",y:"40",width:"100",height:"30",text:"1x1 Conv",fontSize:"20px",class:"fill-blue-100"}}),o=new Me({props:{data:[{x:30,y:220},{x:30,y:60}],strokeWidth:2,dashed:!0,strokeDashArray:"4 4",moving:!0,speed:"80"}}),p=new Me({props:{data:[{x:30,y:200},{x:100,y:200}],strokeWidth:2,dashed:!0,strokeDashArray:"4 4",moving:!0,speed:"80"}}),s=new Me({props:{data:[{x:160,y:180},{x:160,y:145}],strokeWidth:2,dashed:!0,strokeDashArray:"4 4",moving:!0,speed:"80"}}),d=new Me({props:{data:[{x:160,y:100},{x:160,y:65}],strokeWidth:2,dashed:!0,strokeDashArray:"4 4",moving:!0,speed:"80"}}),W=new Me({props:{data:[{x:110,y:40},{x:50,y:40}],strokeWidth:2,dashed:!0,strokeDashArray:"4 4",moving:!0,speed:"80"}}),G=new U({props:{x:"70",y:"180",width:"25",height:"25",text:"2h",fontSize:"15px"}}),D=new U({props:{x:"70",y:"60",width:"25",height:"25",text:"2h",fontSize:"15px"}}),H=new U({props:{x:"140",y:"80",width:"25",height:"25",text:"h",fontSize:"15px"}}),V=new U({props:{x:"140",y:"160",width:"25",height:"25",text:"h",fontSize:"15px"}}),{c(){t=I("svg"),r=I("g"),g(e.$$.fragment),g(n.$$.fragment),g(a.$$.fragment),g(l.$$.fragment),g(o.$$.fragment),g(p.$$.fragment),g(s.$$.fragment),g(d.$$.fragment),g(W.$$.fragment),g(G.$$.fragment),g(D.$$.fragment),g(H.$$.fragment),g(V.$$.fragment),this.h()},l(y){t=L(y,"svg",{viewBox:!0});var Y=$(t);r=L(Y,"g",{transform:!0});var R=$(r);_(e.$$.fragment,R),_(n.$$.fragment,R),_(a.$$.fragment,R),_(l.$$.fragment,R),_(o.$$.fragment,R),_(p.$$.fragment,R),_(s.$$.fragment,R),_(d.$$.fragment,R),_(W.$$.fragment,R),_(G.$$.fragment,R),_(D.$$.fragment,R),_(H.$$.fragment,R),_(V.$$.fragment,R),R.forEach(h),Y.forEach(h),this.h()},h(){m(r,"transform","translate(-5 -10)"),m(t,"viewBox","0 0 220 220")},m(y,Y){c(y,t,Y),C(t,r),v(e,r,null),v(n,r,null),v(a,r,null),v(l,r,null),v(o,r,null),v(p,r,null),v(s,r,null),v(d,r,null),v(W,r,null),v(G,r,null),v(D,r,null),v(H,r,null),v(V,r,null),K=!0},p:j,i(y){K||(w(e.$$.fragment,y),w(n.$$.fragment,y),w(a.$$.fragment,y),w(l.$$.fragment,y),w(o.$$.fragment,y),w(p.$$.fragment,y),w(s.$$.fragment,y),w(d.$$.fragment,y),w(W.$$.fragment,y),w(G.$$.fragment,y),w(D.$$.fragment,y),w(H.$$.fragment,y),w(V.$$.fragment,y),K=!0)},o(y){k(e.$$.fragment,y),k(n.$$.fragment,y),k(a.$$.fragment,y),k(l.$$.fragment,y),k(o.$$.fragment,y),k(p.$$.fragment,y),k(s.$$.fragment,y),k(d.$$.fragment,y),k(W.$$.fragment,y),k(G.$$.fragment,y),k(D.$$.fragment,y),k(H.$$.fragment,y),k(V.$$.fragment,y),K=!1},d(y){y&&h(t),x(e),x(n),x(a),x(l),x(o),x(p),x(s),x(d),x(W),x(G),x(D),x(H),x(V)}}}function al(f){let t,r,e,n,a,l,o,p,s;return r=new Me({props:{data:[{x:140,y:0},{x:140,y:190}],strokeWidth:2,dashed:!0,strokeDashArray:"4 4",moving:!0,speed:"80"}}),e=new U({props:{x:"140",y:"40",width:"150",height:"30",text:"7x7 Conv, Type 'A'",fontSize:"15px",class:"fill-blue-200"}}),n=new U({props:{x:"140",y:"80",width:"150",height:"30",text:"Skip Connections",fontSize:"15px",class:"fill-blue-200"}}),a=new U({props:{x:"20",y:"80",width:"25",height:"25",text:"7x",fontSize:"15px"}}),l=new U({props:{x:"140",y:"120",width:"150",height:"30",text:"1x1 Conv",fontSize:"15px",class:"fill-blue-200"}}),o=new U({props:{x:"20",y:"120",width:"25",height:"25",text:"2x",fontSize:"15px"}}),p=new U({props:{x:"140",y:"160",width:"150",height:"30",text:"256-way Softmax",class:"fill-blue-200",fontSize:"15px"}}),{c(){t=I("svg"),g(r.$$.fragment),g(e.$$.fragment),g(n.$$.fragment),g(a.$$.fragment),g(l.$$.fragment),g(o.$$.fragment),g(p.$$.fragment),this.h()},l(d){t=L(d,"svg",{viewBox:!0});var W=$(t);_(r.$$.fragment,W),_(e.$$.fragment,W),_(n.$$.fragment,W),_(a.$$.fragment,W),_(l.$$.fragment,W),_(o.$$.fragment,W),_(p.$$.fragment,W),W.forEach(h),this.h()},h(){m(t,"viewBox","0 0 220 200")},m(d,W){c(d,t,W),v(r,t,null),v(e,t,null),v(n,t,null),v(a,t,null),v(l,t,null),v(o,t,null),v(p,t,null),s=!0},p:j,i(d){s||(w(r.$$.fragment,d),w(e.$$.fragment,d),w(n.$$.fragment,d),w(a.$$.fragment,d),w(l.$$.fragment,d),w(o.$$.fragment,d),w(p.$$.fragment,d),s=!0)},o(d){k(r.$$.fragment,d),k(e.$$.fragment,d),k(n.$$.fragment,d),k(a.$$.fragment,d),k(l.$$.fragment,d),k(o.$$.fragment,d),k(p.$$.fragment,d),s=!1},d(d){d&&h(t),x(r),x(e),x(n),x(a),x(l),x(o),x(p)}}}function sl(f){let t,r,e,n,a,l,o,p,s,d,W,G,D,H,V,K,y,Y,R,Nt,Fe,J,At,X,zt,je,Z,Ke,xe,Ct,Ye,ee,Qe,ye,Pt,Je,be,Bt,Xe,te,Ze,Ne,Et,et,ne,tt,le,nt,F,Tt,ie,St,re,Wt,lt,oe,it,ae,rt,Ae,Mt,ot,se,Rt,Re,Dt,It,at,ce,st,ze,ft,Ce,Lt,ht,Pe,qt,ut,fe,ct,he,Ut,De,Ot,Gt,mt,me,pt,Be,dt,Ee,Ht,$t,Te,Vt,gt,ue,_t,Se,Ft,vt,pe,wt,We,jt,kt,de,$e,Yt,xt;return o=new bt({props:{$$slots:{default:[Yn]},$$scope:{ctx:f}}}),p=new Fn({props:{id:"1",type:"reference"}}),X=new bt({props:{$$slots:{default:[Qn]},$$scope:{ctx:f}}}),Z=new ke({props:{maxWidth:"120px",$$slots:{default:[Jn]},$$scope:{ctx:f}}}),ee=new ke({props:{maxWidth:"180px",$$slots:{default:[Xn]},$$scope:{ctx:f}}}),te=new ke({props:{maxWidth:"180px",$$slots:{default:[Zn]},$$scope:{ctx:f}}}),ne=new rn({props:{$$slots:{default:[el]},$$scope:{ctx:f}}}),le=new ke({props:{maxWidth:"180px",$$slots:{default:[tl]},$$scope:{ctx:f}}}),ie=new bt({props:{$$slots:{default:[nl]},$$scope:{ctx:f}}}),re=new bt({props:{$$slots:{default:[ll]},$$scope:{ctx:f}}}),oe=new rn({props:{$$slots:{default:[il]},$$scope:{ctx:f}}}),ae=new ke({props:{maxWidth:"180px",$$slots:{default:[rl]},$$scope:{ctx:f}}}),ce=new Kt({props:{code:`class MaskedConvolution(nn.Module):
    def __init__(
        self, in_channels, out_channels, kernel_size=(3, 3), mask_type="B", dilation=1
    ):
        super().__init__()

        assert mask_type in ["A", "B"]
        mask = torch.zeros(kernel_size)
        mask[: kernel_size[0] // 2, :] = 1
        if mask_type == "A":
            mask[kernel_size[0] // 2, : kernel_size[1] // 2] = 1
        elif mask_type == "B":
            mask[kernel_size[0] // 2, : kernel_size[1] // 2 + 1] = 1
        self.register_buffer("mask", mask)

        # add conv2d layer
        padding = tuple([dilation * (size - 1) // 2 for size in kernel_size])
        self.conv = nn.Conv2d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=kernel_size,
            dilation=dilation,
            padding=padding,
        )

    def forward(self, x):
        with torch.inference_mode():
            self.conv.weight *= self.mask
        return self.conv(x)
`}}),fe=new ke({props:{maxWidth:"250px",$$slots:{default:[ol]},$$scope:{ctx:f}}}),me=new Kt({props:{code:`class ResidualBlock(nn.Module):
    def __init__(self, hidden_dim, dilation=1):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(
                in_channels=hidden_dim * 2, out_channels=hidden_dim, kernel_size=1
            ),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(),
            MaskedConvolution(
                in_channels=hidden_dim, out_channels=hidden_dim, dilation=dilation
            ),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU(),
            nn.Conv2d(
                in_channels=hidden_dim, out_channels=hidden_dim * 2, kernel_size=1
            ),
            nn.BatchNorm2d(hidden_dim * 2),
            nn.ReLU(),
        )

    def forward(self, x):
        block = self.block(x)
        return x + block`}}),ue=new ke({props:{maxWidth:"300px",$$slots:{default:[al]},$$scope:{ctx:f}}}),pe=new Kt({props:{code:`class PixelCNN(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.layers = nn.Sequential(
            MaskedConvolution(
                in_channels=1,
                out_channels=hidden_dim * 2,
                kernel_size=(7, 7),
                mask_type="A",
            ),
            nn.BatchNorm2d(hidden_dim * 2),
            nn.ReLU(),
            ResidualBlock(hidden_dim, dilation=1),
            ResidualBlock(hidden_dim, dilation=2),
            ResidualBlock(hidden_dim, dilation=1),
            ResidualBlock(hidden_dim, dilation=3),
            ResidualBlock(hidden_dim, dilation=1),
            ResidualBlock(hidden_dim, dilation=2),
            ResidualBlock(hidden_dim, dilation=1),
            nn.Conv2d(hidden_dim * 2, hidden_dim * 2, kernel_size=1),
            nn.BatchNorm2d(hidden_dim * 2),
            nn.ReLU(),
            nn.Conv2d(hidden_dim * 2, 256, kernel_size=1),
        )

    def forward(self, x):
        x = self.layers(x)
        x = x.view(-1, 256, 1, 28, 28)
        return x`}}),{c(){t=E("h1"),r=P("PixelCNN"),e=A(),n=E("div"),a=A(),l=E("p"),g(o.$$.fragment),g(p.$$.fragment),s=P(` is an
    autoregressive generative image model that came out of DeepMind. The authors
    introduced 4 types of models simultaneously: RowLSTM, Diagonal BiLSTM, Multi-Scale
    PixelRNN and PixelCNN. While the models that were based on recurrent neural networks
    performed better originally, PixelCNN was a lot easier to parallelize. Over the
    next years a lot of improvement were done to PixelCNN, which resulted in a much
    better performance. In this section we will focus on the original PixelCNN implementation
    and look at some improvements in the coming sections.`),d=A(),W=E("p"),G=P("Our PyTorch implementation is inspired by "),D=E("a"),H=P("UvA Deep Learning Tutorials"),V=P(`. We recommend you check out their tutotorial if you want to get a deeper
    understanding of PixelCNN and Gated PixelCNN (will be covered in the next
    section).`),K=A(),y=E("div"),Y=A(),R=E("h2"),Nt=P("Masked Convolutions"),Fe=A(),J=E("p"),At=P(`Let's utilize a stylized example of a 4x4 image in order to understand what
    role `),g(X.$$.fragment),zt=P(" play and why they are necessary."),je=A(),g(Z.$$.fragment),Ke=A(),xe=E("p"),Ct=P(`We need to process the image in such a way, that the size (height and width)
    of the input and the output feature maps are identical. So given a 4x4 image
    and a 3x3 convolution, we need a padding of 1 on each side of the 2d image.`),Ye=A(),g(ee.$$.fragment),Qe=A(),ye=E("p"),Pt=P(`This is required, because we want to end up with a probability distribution
    for each pixel. For each of the 4x4 pixels we end up with a 256-way softmax
    layer. Each of the 256 numbers represents the probability of the pixel to be
    one of the 256 integer values between 0 and 255. We can use those
    probabilities to sample pixel values from the multinomial distribution. So
    in our example we would start with a greyscale image of shape 1x4x4 and end
    up with 256x1x4x4.`),Je=A(),be=E("p"),Bt=P(`Now if you look at the kernel below, as indicated by the red dots, you will
    hopefully see a problem in this type of calculation. The very first output
    contains knowledge about future pixels. Autoregressive generative models
    take in previous pixels to generate future pixels. If previous pixels
    contain knowledge about the future, that would be considered cheating and
    while our training process would look great, inference would produce
    garbage, because the model would not have learned how to generate pixels
    based solely on the past.`),Xe=A(),g(te.$$.fragment),Ze=A(),Ne=E("p"),Et=P(`To deal with this problem, we need to apply a mask to the kernel.
    Essentially we multiply the kernel values that would access future pixels
    with zeros, thereby zeroing out the weights of kernel positions that relate
    to future pixels.`),et=A(),g(ne.$$.fragment),tt=A(),g(le.$$.fragment),nt=A(),F=E("p"),Tt=P(`There are two types of kernel masks that are used for PixelRNNs. The above
    mask is of type `),g(ie.$$.fragment),St=P(`. A type A mask zeroes out all
    values up to the position we would like to produceIn the below example on
    the other hand we use a mask of type `),g(re.$$.fragment),Wt=P(`. A type B mask
    does not zero out the position in the input feature map that corresponds to
    the position in the output feature map.`),lt=A(),g(oe.$$.fragment),it=A(),g(ae.$$.fragment),rt=A(),Ae=E("p"),Mt=P(`The PixelCNN architecture uses type A masks for the input image, while type
    B masks are applied to all intermediary results. When we get the actual
    image as input and try to generate a pixel, we have to use mask A in order
    to hide the actual pixel the model tries to predict. So when we try to
    predict the very first pixel, the model can only look at zero padded values.
    After the first processing step with mask of type A the values do not
    contain actual information about the original pixel in that position, but
    only information about pixel values that surround the pixel we are trying to
    produce, so we can use mask B safely.`),ot=A(),se=E("p"),Rt=P("We create a special "),Re=E("code"),Dt=P("MaskedConvolution"),It=P(` module, that we can reuse
    in several places. The module implements a different mask depending on the type
    of the mask. The padding of the convolution operation is determined automatically
    based on the kernel size and dilations. Dilations are not explicitly mentioned
    in the research paper, but they seem to slightly imrove the quality of the generated
    images.`),at=A(),g(ce.$$.fragment),st=A(),ze=E("div"),ft=A(),Ce=E("h2"),Lt=P("Skip Connections"),ht=A(),Pe=E("p"),qt=P(`In order to facilitate training, PixelCNN utilizes skip connections, by
    constructing residual blocks. The residual block scales down the number of
    hidden features from 2h to h, before a masked 'B' convolution is applied.
    Afterwards the dimension is scaled up again and the original input to the
    block and the output are summed.`),ut=A(),g(fe.$$.fragment),ct=A(),he=E("p"),Ut=P("Additionally to the behaviour described above, we add "),De=E("code"),Ot=P("BatchNorm2d"),Gt=P(` before each activation function. This helps out with the training stability
    and overfitting.`),mt=A(),g(me.$$.fragment),pt=A(),Be=E("div"),dt=A(),Ee=E("h2"),Ht=P("Model"),$t=A(),Te=E("p"),Vt=P(`At this point we have all the ingredients to describe a PixelCNN
    architecture. We use a 7x7 masked convolutional layer of type 'A' to the
    input image. The output is followed up by 7 residual blocks, which utilize
    masked convolutions of type 'B'. The final outputs adjust the number of
    feature maps to the desired 256 and the softmax nonlinearity is applied.`),gt=A(),g(ue.$$.fragment),_t=A(),Se=E("p"),Ft=P(`We add different types of dialitions for each ResidialBlock to allow the
    model to attend to pixels, that are farther away from the current position.
    You can experiment with those values to see if you can achieve better
    results.`),vt=A(),g(pe.$$.fragment),wt=A(),We=E("p"),jt=P(`The qualityt of the generated images is far from optimal. Some of the images
    actually correspond to digits, others look 'digit-like', but overall there
    is room for improvement. Gated PixelCNNs will allow us to generate higher
    quality images. This is going to be the topic of the next section.`),kt=A(),de=E("div"),$e=E("img"),this.h()},l(i){t=T(i,"H1",{});var u=$(t);r=B(u,"PixelCNN"),u.forEach(h),e=z(i),n=T(i,"DIV",{class:!0}),$(n).forEach(h),a=z(i),l=T(i,"P",{});var ge=$(l);_(o.$$.fragment,ge),_(p.$$.fragment,ge),s=B(ge,` is an
    autoregressive generative image model that came out of DeepMind. The authors
    introduced 4 types of models simultaneously: RowLSTM, Diagonal BiLSTM, Multi-Scale
    PixelRNN and PixelCNN. While the models that were based on recurrent neural networks
    performed better originally, PixelCNN was a lot easier to parallelize. Over the
    next years a lot of improvement were done to PixelCNN, which resulted in a much
    better performance. In this section we will focus on the original PixelCNN implementation
    and look at some improvements in the coming sections.`),ge.forEach(h),d=z(i),W=T(i,"P",{});var _e=$(W);G=B(_e,"Our PyTorch implementation is inspired by "),D=T(_e,"A",{href:!0,target:!0,rel:!0});var Ie=$(D);H=B(Ie,"UvA Deep Learning Tutorials"),Ie.forEach(h),V=B(_e,`. We recommend you check out their tutotorial if you want to get a deeper
    understanding of PixelCNN and Gated PixelCNN (will be covered in the next
    section).`),_e.forEach(h),K=z(i),y=T(i,"DIV",{class:!0}),$(y).forEach(h),Y=z(i),R=T(i,"H2",{});var Le=$(R);Nt=B(Le,"Masked Convolutions"),Le.forEach(h),Fe=z(i),J=T(i,"P",{});var ve=$(J);At=B(ve,`Let's utilize a stylized example of a 4x4 image in order to understand what
    role `),_(X.$$.fragment,ve),zt=B(ve," play and why they are necessary."),ve.forEach(h),je=z(i),_(Z.$$.fragment,i),Ke=z(i),xe=T(i,"P",{});var qe=$(xe);Ct=B(qe,`We need to process the image in such a way, that the size (height and width)
    of the input and the output feature maps are identical. So given a 4x4 image
    and a 3x3 convolution, we need a padding of 1 on each side of the 2d image.`),qe.forEach(h),Ye=z(i),_(ee.$$.fragment,i),Qe=z(i),ye=T(i,"P",{});var Ue=$(ye);Pt=B(Ue,`This is required, because we want to end up with a probability distribution
    for each pixel. For each of the 4x4 pixels we end up with a 256-way softmax
    layer. Each of the 256 numbers represents the probability of the pixel to be
    one of the 256 integer values between 0 and 255. We can use those
    probabilities to sample pixel values from the multinomial distribution. So
    in our example we would start with a greyscale image of shape 1x4x4 and end
    up with 256x1x4x4.`),Ue.forEach(h),Je=z(i),be=T(i,"P",{});var Oe=$(be);Bt=B(Oe,`Now if you look at the kernel below, as indicated by the red dots, you will
    hopefully see a problem in this type of calculation. The very first output
    contains knowledge about future pixels. Autoregressive generative models
    take in previous pixels to generate future pixels. If previous pixels
    contain knowledge about the future, that would be considered cheating and
    while our training process would look great, inference would produce
    garbage, because the model would not have learned how to generate pixels
    based solely on the past.`),Oe.forEach(h),Xe=z(i),_(te.$$.fragment,i),Ze=z(i),Ne=T(i,"P",{});var Ge=$(Ne);Et=B(Ge,`To deal with this problem, we need to apply a mask to the kernel.
    Essentially we multiply the kernel values that would access future pixels
    with zeros, thereby zeroing out the weights of kernel positions that relate
    to future pixels.`),Ge.forEach(h),et=z(i),_(ne.$$.fragment,i),tt=z(i),_(le.$$.fragment,i),nt=z(i),F=T(i,"P",{});var Q=$(F);Tt=B(Q,`There are two types of kernel masks that are used for PixelRNNs. The above
    mask is of type `),_(ie.$$.fragment,Q),St=B(Q,`. A type A mask zeroes out all
    values up to the position we would like to produceIn the below example on
    the other hand we use a mask of type `),_(re.$$.fragment,Q),Wt=B(Q,`. A type B mask
    does not zero out the position in the input feature map that corresponds to
    the position in the output feature map.`),Q.forEach(h),lt=z(i),_(oe.$$.fragment,i),it=z(i),_(ae.$$.fragment,i),rt=z(i),Ae=T(i,"P",{});var He=$(Ae);Mt=B(He,`The PixelCNN architecture uses type A masks for the input image, while type
    B masks are applied to all intermediary results. When we get the actual
    image as input and try to generate a pixel, we have to use mask A in order
    to hide the actual pixel the model tries to predict. So when we try to
    predict the very first pixel, the model can only look at zero padded values.
    After the first processing step with mask of type A the values do not
    contain actual information about the original pixel in that position, but
    only information about pixel values that surround the pixel we are trying to
    produce, so we can use mask B safely.`),He.forEach(h),ot=z(i),se=T(i,"P",{});var we=$(se);Rt=B(we,"We create a special "),Re=T(we,"CODE",{});var Ve=$(Re);Dt=B(Ve,"MaskedConvolution"),Ve.forEach(h),It=B(we,` module, that we can reuse
    in several places. The module implements a different mask depending on the type
    of the mask. The padding of the convolution operation is determined automatically
    based on the kernel size and dilations. Dilations are not explicitly mentioned
    in the research paper, but they seem to slightly imrove the quality of the generated
    images.`),we.forEach(h),at=z(i),_(ce.$$.fragment,i),st=z(i),ze=T(i,"DIV",{class:!0}),$(ze).forEach(h),ft=z(i),Ce=T(i,"H2",{});var Qt=$(Ce);Lt=B(Qt,"Skip Connections"),Qt.forEach(h),ht=z(i),Pe=T(i,"P",{});var Jt=$(Pe);qt=B(Jt,`In order to facilitate training, PixelCNN utilizes skip connections, by
    constructing residual blocks. The residual block scales down the number of
    hidden features from 2h to h, before a masked 'B' convolution is applied.
    Afterwards the dimension is scaled up again and the original input to the
    block and the output are summed.`),Jt.forEach(h),ut=z(i),_(fe.$$.fragment,i),ct=z(i),he=T(i,"P",{});var yt=$(he);Ut=B(yt,"Additionally to the behaviour described above, we add "),De=T(yt,"CODE",{});var Xt=$(De);Ot=B(Xt,"BatchNorm2d"),Xt.forEach(h),Gt=B(yt,` before each activation function. This helps out with the training stability
    and overfitting.`),yt.forEach(h),mt=z(i),_(me.$$.fragment,i),pt=z(i),Be=T(i,"DIV",{class:!0}),$(Be).forEach(h),dt=z(i),Ee=T(i,"H2",{});var Zt=$(Ee);Ht=B(Zt,"Model"),Zt.forEach(h),$t=z(i),Te=T(i,"P",{});var en=$(Te);Vt=B(en,`At this point we have all the ingredients to describe a PixelCNN
    architecture. We use a 7x7 masked convolutional layer of type 'A' to the
    input image. The output is followed up by 7 residual blocks, which utilize
    masked convolutions of type 'B'. The final outputs adjust the number of
    feature maps to the desired 256 and the softmax nonlinearity is applied.`),en.forEach(h),gt=z(i),_(ue.$$.fragment,i),_t=z(i),Se=T(i,"P",{});var tn=$(Se);Ft=B(tn,`We add different types of dialitions for each ResidialBlock to allow the
    model to attend to pixels, that are farther away from the current position.
    You can experiment with those values to see if you can achieve better
    results.`),tn.forEach(h),vt=z(i),_(pe.$$.fragment,i),wt=z(i),We=T(i,"P",{});var nn=$(We);jt=B(nn,`The qualityt of the generated images is far from optimal. Some of the images
    actually correspond to digits, others look 'digit-like', but overall there
    is room for improvement. Gated PixelCNNs will allow us to generate higher
    quality images. This is going to be the topic of the next section.`),nn.forEach(h),kt=z(i),de=T(i,"DIV",{class:!0});var ln=$(de);$e=T(ln,"IMG",{src:!0,alt:!0,class:!0}),ln.forEach(h),this.h()},h(){m(n,"class","separator"),m(D,"href","https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial12/Autoregressive_Image_Modeling.html"),m(D,"target","_blank"),m(D,"rel","noreferrer"),m(y,"class","separator"),m(ze,"class","separator"),m(Be,"class","separator"),Gn($e.src,Yt=Kn)||m($e,"src",Yt),m($e,"alt","Generated MNIST Images"),m($e,"class","w-96"),m(de,"class","flex justify-center items-center")},m(i,u){c(i,t,u),C(t,r),c(i,e,u),c(i,n,u),c(i,a,u),c(i,l,u),v(o,l,null),v(p,l,null),C(l,s),c(i,d,u),c(i,W,u),C(W,G),C(W,D),C(D,H),C(W,V),c(i,K,u),c(i,y,u),c(i,Y,u),c(i,R,u),C(R,Nt),c(i,Fe,u),c(i,J,u),C(J,At),v(X,J,null),C(J,zt),c(i,je,u),v(Z,i,u),c(i,Ke,u),c(i,xe,u),C(xe,Ct),c(i,Ye,u),v(ee,i,u),c(i,Qe,u),c(i,ye,u),C(ye,Pt),c(i,Je,u),c(i,be,u),C(be,Bt),c(i,Xe,u),v(te,i,u),c(i,Ze,u),c(i,Ne,u),C(Ne,Et),c(i,et,u),v(ne,i,u),c(i,tt,u),v(le,i,u),c(i,nt,u),c(i,F,u),C(F,Tt),v(ie,F,null),C(F,St),v(re,F,null),C(F,Wt),c(i,lt,u),v(oe,i,u),c(i,it,u),v(ae,i,u),c(i,rt,u),c(i,Ae,u),C(Ae,Mt),c(i,ot,u),c(i,se,u),C(se,Rt),C(se,Re),C(Re,Dt),C(se,It),c(i,at,u),v(ce,i,u),c(i,st,u),c(i,ze,u),c(i,ft,u),c(i,Ce,u),C(Ce,Lt),c(i,ht,u),c(i,Pe,u),C(Pe,qt),c(i,ut,u),v(fe,i,u),c(i,ct,u),c(i,he,u),C(he,Ut),C(he,De),C(De,Ot),C(he,Gt),c(i,mt,u),v(me,i,u),c(i,pt,u),c(i,Be,u),c(i,dt,u),c(i,Ee,u),C(Ee,Ht),c(i,$t,u),c(i,Te,u),C(Te,Vt),c(i,gt,u),v(ue,i,u),c(i,_t,u),c(i,Se,u),C(Se,Ft),c(i,vt,u),v(pe,i,u),c(i,wt,u),c(i,We,u),C(We,jt),c(i,kt,u),c(i,de,u),C(de,$e),xt=!0},p(i,u){const ge={};u&8388608&&(ge.$$scope={dirty:u,ctx:i}),o.$set(ge);const _e={};u&8388608&&(_e.$$scope={dirty:u,ctx:i}),X.$set(_e);const Ie={};u&8388608&&(Ie.$$scope={dirty:u,ctx:i}),Z.$set(Ie);const Le={};u&8388608&&(Le.$$scope={dirty:u,ctx:i}),ee.$set(Le);const ve={};u&8388608&&(ve.$$scope={dirty:u,ctx:i}),te.$set(ve);const qe={};u&8388608&&(qe.$$scope={dirty:u,ctx:i}),ne.$set(qe);const Ue={};u&8388611&&(Ue.$$scope={dirty:u,ctx:i}),le.$set(Ue);const Oe={};u&8388608&&(Oe.$$scope={dirty:u,ctx:i}),ie.$set(Oe);const Ge={};u&8388608&&(Ge.$$scope={dirty:u,ctx:i}),re.$set(Ge);const Q={};u&8388608&&(Q.$$scope={dirty:u,ctx:i}),oe.$set(Q);const He={};u&8388611&&(He.$$scope={dirty:u,ctx:i}),ae.$set(He);const we={};u&8388608&&(we.$$scope={dirty:u,ctx:i}),fe.$set(we);const Ve={};u&8388608&&(Ve.$$scope={dirty:u,ctx:i}),ue.$set(Ve)},i(i){xt||(w(o.$$.fragment,i),w(p.$$.fragment,i),w(X.$$.fragment,i),w(Z.$$.fragment,i),w(ee.$$.fragment,i),w(te.$$.fragment,i),w(ne.$$.fragment,i),w(le.$$.fragment,i),w(ie.$$.fragment,i),w(re.$$.fragment,i),w(oe.$$.fragment,i),w(ae.$$.fragment,i),w(ce.$$.fragment,i),w(fe.$$.fragment,i),w(me.$$.fragment,i),w(ue.$$.fragment,i),w(pe.$$.fragment,i),xt=!0)},o(i){k(o.$$.fragment,i),k(p.$$.fragment,i),k(X.$$.fragment,i),k(Z.$$.fragment,i),k(ee.$$.fragment,i),k(te.$$.fragment,i),k(ne.$$.fragment,i),k(le.$$.fragment,i),k(ie.$$.fragment,i),k(re.$$.fragment,i),k(oe.$$.fragment,i),k(ae.$$.fragment,i),k(ce.$$.fragment,i),k(fe.$$.fragment,i),k(me.$$.fragment,i),k(ue.$$.fragment,i),k(pe.$$.fragment,i),xt=!1},d(i){i&&h(t),i&&h(e),i&&h(n),i&&h(a),i&&h(l),x(o),x(p),i&&h(d),i&&h(W),i&&h(K),i&&h(y),i&&h(Y),i&&h(R),i&&h(Fe),i&&h(J),x(X),i&&h(je),x(Z,i),i&&h(Ke),i&&h(xe),i&&h(Ye),x(ee,i),i&&h(Qe),i&&h(ye),i&&h(Je),i&&h(be),i&&h(Xe),x(te,i),i&&h(Ze),i&&h(Ne),i&&h(et),x(ne,i),i&&h(tt),x(le,i),i&&h(nt),i&&h(F),x(ie),x(re),i&&h(lt),x(oe,i),i&&h(it),x(ae,i),i&&h(rt),i&&h(Ae),i&&h(ot),i&&h(se),i&&h(at),x(ce,i),i&&h(st),i&&h(ze),i&&h(ft),i&&h(Ce),i&&h(ht),i&&h(Pe),i&&h(ut),x(fe,i),i&&h(ct),i&&h(he),i&&h(mt),x(me,i),i&&h(pt),i&&h(Be),i&&h(dt),i&&h(Ee),i&&h($t),i&&h(Te),i&&h(gt),x(ue,i),i&&h(_t),i&&h(Se),i&&h(vt),x(pe,i),i&&h(wt),i&&h(We),i&&h(kt),i&&h(de)}}}function fl(f){let t,r,e,n,a,l;return e=new Hn({props:{$$slots:{default:[sl]},$$scope:{ctx:f}}}),a=new Vn({props:{references:f[2]}}),{c(){t=E("meta"),r=A(),g(e.$$.fragment),n=A(),g(a.$$.fragment),this.h()},l(o){const p=On("svelte-hl6non",document.head);t=T(p,"META",{name:!0,content:!0}),p.forEach(h),r=z(o),_(e.$$.fragment,o),n=z(o),_(a.$$.fragment,o),this.h()},h(){document.title="PixelCNN - World4AI",m(t,"name","description"),m(t,"content","PixelCNN is an anotregressive generative image model, that was developed by DeepMind. The model uses masked convolutions, thereby filtering out future pixels that the model should not have access to. At the time of the publishing the research at DeepMind produced state of the art results in image generation.")},m(o,p){C(document.head,t),c(o,r,p),v(e,o,p),c(o,n,p),v(a,o,p),l=!0},p(o,[p]){const s={};p&8388611&&(s.$$scope={dirty:p,ctx:o}),e.$set(s)},i(o){l||(w(e.$$.fragment,o),w(a.$$.fragment,o),l=!0)},o(o){k(e.$$.fragment,o),k(a.$$.fragment,o),l=!1},d(o){h(t),o&&h(r),x(e,o),o&&h(n),x(a,o)}}}const S=4,b=25,N=1,O=3;function hl(f,t,r){const e=[{author:"Oord, Aaron and Kalchbrenner, Nal and Kavukcuoglu, Koray",title:"Pixel Recurrent Neural Networks",year:"2016"}];let n=0,a=0;function l(){a<3?r(1,a+=1):a===3&&n<3?(r(1,a=0),r(0,n+=1)):r(1,a=r(0,n=0))}return[n,a,e,l]}class xl extends Ln{constructor(t){super(),qn(this,t,hl,fl,Un,{})}}export{xl as default};
