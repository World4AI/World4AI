<script>
  import Question from "$lib/Question.svelte";
</script>

<svelte:head>
  <title
    >World4AI | Reinforcement Learning | Exploration Exploitation Tradeoff</title
  >
  <meta
    name="description"
    content="The introduction into the topic of exploration and exploitation is usually done throught the means of bandits."
  />
</svelte:head>

<h1>Exploration Exploitation Trade-off</h1>
<Question
  >Why is there a dilemma when choosing between exploration and exploitation?</Question
>
<div class="separator" />

<div class="flex-center">
  <svg version="1.1" viewBox="0 0 500 100" xmlns="http://www.w3.org/2000/svg">
    <g fill="none" stroke="var(--text-color)" stroke-width="0.8px">
      <g stroke-linecap="round">
        <path d="m280 98.321h-60l30-51.962z" />
        <rect x="20" y="35" width="460" height="10" />
        <circle cx="45" cy="19" r="15" />
        <circle cx="80.402" cy="24" r="10" />
        <circle cx="469" cy="29" r="5" />
        <circle cx="452.21" cy="24" r="10" />
        <circle cx="430.54" cy="24" r="10" />
      </g>
      <g stroke-linecap="round">
        <rect x="95" y="24" width="25" height="10" />
        <rect x="105" y="13" width="25" height="10" />
        <rect x="275" y="24" width="20" height="10" />
        <rect x="380" y="24" width="30" height="10" />
      </g>
      <g stroke-linecap="round">
        <rect x="375" y="18" width="25" height="5" />
        <rect x="385" y="2" width="5" height="15" />
        <rect x="405" y="8" width="5" height="15" />
      </g>
    </g>
  </svg>
  <div class="separator" />
</div>

<p>
  When the model of the environment is not available or the model is too complex
  it becomes essential for the agent to explore the environment through
  interaction in order to learn the optimal policy. The necessity for
  interaction and exploration creates problems that are native to reinforcement
  learning, the so called exploration-exploitation dilemma. On the one hand the
  agent must be able to collect new (so far not seen) experiences, that is to
  explore the environment. On the other hand the agent must be able to use the
  already available knowledge to optimize the reward stream, that is to exploit
  the learned knowledge. Once the agent decides to exploit or to explore there
  is no turning back and the agent has to live with the consequences. This gives
  rise to the dilemma, which states that at each time step either exploration or
  exploitation is possible, but definitely not both. There is a tradeoff between
  exploration and exploitation and the agent must be able to balance the two. In
  this chapter we are going to delve into the balancing act that is the
  exploration-exploitation tradeoff.
</p>
<div class="separator" />
