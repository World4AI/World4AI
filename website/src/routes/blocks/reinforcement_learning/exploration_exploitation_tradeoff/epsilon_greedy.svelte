<script>
  import Question from "$lib/Question.svelte";
  import Latex from "$lib/Latex.svelte";
  import Algorithm from "$lib/algorithm/Algorithm.svelte";
  import AlgorithmState from "$lib/algorithm/AlgorithmState.svelte";
  import AlgorithmIf from "$lib/algorithm/AlgorithmIf.svelte";
  import AlgorithmForAll from "$lib/algorithm/AlgorithmForAll.svelte";
  import Code from "$lib/Code.svelte";
</script>

<svelte:head>
  <title>World4AI | Reinforcement Learning | Epsilon-Greedy</title>
  <meta
    name="description"
    content="Epsilon-greedy is a strategy to balance exploration and exploitation. With the probability of epsilon the agent selects a random action and with probability of 1 - epsilon the agent selects the greedy action."
  />
</svelte:head>

<h1>Epsilon-Greedy</h1>
<Question
  >What strategy is commonly used to balance exploration and exploitation?</Question
>
<div class="separator" />

<p>
  Epsilon-Greedy is on the one hand the easiest strategy to balance exploration
  and exploitation and on the other hand probably the most common one.
</p>

<p>
  With the probability of <Latex>{String.raw`\epsilon`}</Latex> the agent selects
  the greedy action and with the probability of <Latex
    >{String.raw`1 - \epsilon`}</Latex
  > the agent selects a random action. Often :math:`\epsilon` is not constant and
  starts with a relatively high value to encourage exploration when the agent knows
  nothing about the environment. The value is decreased over time and reaches a final
  minimal value after a designated number of steps. The minimal value often lies
  in the range between 0.01 and 0.1.
</p>

<Algorithm algoName={"Epsilon-Greedy"}>
  <AlgorithmState
    >Input: bandit, action set <Latex>{String.raw`\mathcal{A}`}</Latex>, number
    of episodes <Latex>N</Latex>, learning rate <Latex
      >{String.raw`\alpha`}</Latex
    >, epsilon <Latex>{String.raw`\epsilon`}</Latex>
  </AlgorithmState>
  <AlgorithmState
    >Initialize: <Latex>Q(a)</Latex> for all <Latex
      >{String.raw`a \in \mathcal{A}`}</Latex
    >
    with zeros</AlgorithmState
  >
  <AlgorithmForAll>
    <span slot="condition">Episodes <Latex>{String.raw`n \in N`}</Latex></span>
    <AlgorithmState
      ><Latex>{String.raw`r \leftarrow`}</Latex> random number between 0 and 1</AlgorithmState
    >
    <AlgorithmIf>
      <Latex slot="condition">{String.raw`r < \epsilon`}</Latex>
      <AlgorithmState
        ><Latex>{String.raw`a \leftarrow`}</Latex> random action</AlgorithmState
      >
    </AlgorithmIf>
    <AlgorithmIf>
      <Latex slot="condition">{String.raw`r > \epsilon`}</Latex>
      <AlgorithmState
        ><Latex>{String.raw`a \leftarrow \arg\max_aQ(a)`}</Latex>
      </AlgorithmState>
    </AlgorithmIf>
    <AlgorithmState
      ><Latex>{String.raw`r \leftarrow bandit(a)`}</Latex>></AlgorithmState
    >
    <AlgorithmState
      ><Latex>{String.raw`Q(a) \leftarrow Q(a) + \alpha[R - Q(a)]`}</Latex>
    </AlgorithmState>
  </AlgorithmForAll>
</Algorithm>

<Code
  code={`
bandit = Bandit(probs=[0.01, 0.5,  1], rewards=[1000, 10, 1])
A = [x for x in range(bandit.action_space)]
  `}
/>
<Code
  code={`
def bandit_algorithm(bandit, A, num_episodes=1000000, alpha=0.00001, epsilon=0.5):
    num_actions = len(A)
    Q = np.zeros(num_actions)
    
    for episode in range(num_episodes):
        
        if np.random.rand() < epsilon:
            action = np.random.choice(num_actions)
        else:
            action = Q.argmax()
        
        reward = bandit.step(action)
        
        Q[action] = Q[action] + alpha * (reward - Q[action])
        
        if episode % 100000 == 0:
            print(Q)
        
    return Q
  `}
/>
