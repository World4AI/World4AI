{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a879bdd-54a7-4d23-9668-a461b20a61a7",
   "metadata": {},
   "source": [
    "# PixelRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f160d8-3791-4da2-a1bb-7f5a6d395d48",
   "metadata": {},
   "source": [
    "Partially inspired by https://github.com/heechan95/PixelRNN-pytorch/blob/master/PixelRNN%20pytorch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b62d1b-ed3a-4d49-9724-ab1b2c906b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03975ce-4cf8-4d01-8109-012515fef359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "HIDDEN_DIM = 16\n",
    "LR = 1e-3\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0106ac-f3e3-4adf-a492-3d18f465c007",
   "metadata": {},
   "source": [
    "## Masked Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd644a-0672-43df-8e5c-40b029c7bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConvolution(nn.Module):\n",
    "    def __init__(self,\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(3,3),\n",
    "                mask_type='B'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # determine the mask\n",
    "        assert mask_type in ['A', 'B']\n",
    "        mask = torch.zeros(kernel_size)\n",
    "        mask[: kernel_size[0] // 2, :] = 1\n",
    "        if mask_type == 'A':\n",
    "            mask[kernel_size[0] // 2, : kernel_size[1] // 2] = 1\n",
    "        elif mask_type == 'B':\n",
    "            mask[kernel_size[0] // 2, : kernel_size[1] // 2 + 1] = 1\n",
    "        self.register_buffer('mask', mask)\n",
    "        \n",
    "        # add conv2d layer\n",
    "        padding = tuple([(size-1)//2 for size in kernel_size])\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              padding=padding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.inference_mode():\n",
    "            self.conv.weight *= self.mask \n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0fc0b-e455-44eb-8526-059c9d4bc58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the MaskedConvolution layer\n",
    "mc = MaskedConvolution(in_channels=1, out_channels=16, kernel_size=(3, 3), mask_type='B').to(DEVICE)\n",
    "data = torch.randn(1, 1, 28, 28, device=DEVICE)\n",
    "mc(data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95464eb-0d10-4529-a0da-a613cadbe38f",
   "metadata": {},
   "source": [
    "## RowLSMT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e268b8-97cf-495d-91ef-d14a724c00a9",
   "metadata": {},
   "source": [
    "The LSTM cell receives one cell at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f46be-f3f6-4265-8cda-fe35e01e8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowLSTMCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.conv_s_s = nn.Conv1d(in_channels=hidden_dim, \n",
    "                                out_channels=4 * hidden_dim,\n",
    "                                kernel_size=3,\n",
    "                                padding=1)\n",
    "\n",
    "    def forward(self, i_s, h_prev, c_prev):\n",
    "        s_s = self.conv_s_s(h_prev)\n",
    "        \n",
    "        o, f, i, g = torch.split(i_s + s_s, self.hidden_dim, 1)\n",
    "        o = torch.sigmoid(o)\n",
    "        f = torch.sigmoid(f)\n",
    "        i = torch.sigmoid(i)\n",
    "        g = torch.tanh(g)\n",
    "        \n",
    "        c = f * c_prev + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67edfe46-52c3-42c8-805e-a1b234022041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Cell\n",
    "row = torch.randn(1, 16, 28, device=DEVICE)\n",
    "i_s = torch.randn(1, 16*4, 28, device=DEVICE)\n",
    "prev_h = torch.randn(1, 16, 28, device=DEVICE)\n",
    "prev_c = torch.randn(1, 16, 28, device=DEVICE)\n",
    "\n",
    "cell = RowLSTMCell(16).to(DEVICE)\n",
    "h, c = cell(i_s, prev_h, prev_c)\n",
    "print(h.shape, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c9b74-01f2-4909-88e7-6ad149dbf7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.cell = RowLSTMCell(hidden_dim)\n",
    "        self.i_s = MaskedConvolution(in_channels=hidden_dim*2,\n",
    "                                    out_channels=hidden_dim*4,\n",
    "                                    kernel_size=(1, 3))\n",
    "        self.conv = nn.Conv2d(in_channels=hidden_dim,\n",
    "                              out_channels=hidden_dim*2,\n",
    "                              kernel_size=1)\n",
    "        self.h_prev = torch.randn(1, 16, 28, device=DEVICE)\n",
    "        self.c_prev = torch.randn(1, 16, 28, device=DEVICE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        i_s = self.i_s(x)\n",
    "        num_rows = 28\n",
    "        rows = []\n",
    "        \n",
    "        h_prev = self.h_prev\n",
    "        c_prev = self.c_prev\n",
    "        for row_idx in range(num_rows):\n",
    "            # batch_size, channels, height, width\n",
    "            is_row = i_s[:, :, row_idx, :]            \n",
    "            h_prev, c_prev = self.cell(is_row, h_prev, c_prev)\n",
    "            rows.append(h_prev.unsqueeze(dim=2))\n",
    "        out = torch.cat(rows, dim=2)\n",
    "        out = self.conv(out)\n",
    "        # skip connection\n",
    "        out += x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036463fb-eae5-406a-8793-d302a6027c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test row lstm\n",
    "image = torch.randn(1, 16*2, 28, 28, device=DEVICE)\n",
    "h_prev = torch.randn(1, 16, 28, device=DEVICE)\n",
    "c_prev = torch.randn(1, 16, 28, device=DEVICE)\n",
    "row_lstm = RowLSTM(16).to(DEVICE)\n",
    "row_lstm(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b38fe1-bbcc-47ea-8c8c-d6fdc2338a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                MaskedConvolution(in_channels=1, \n",
    "                                  out_channels=hidden_dim*2,\n",
    "                                  kernel_size=(7, 7),\n",
    "                                  mask_type='A'),\n",
    "                nn.ReLU(),\n",
    "                RowLSTM(hidden_dim),\n",
    "                RowLSTM(hidden_dim),\n",
    "                RowLSTM(hidden_dim),\n",
    "                RowLSTM(hidden_dim),\n",
    "                RowLSTM(hidden_dim),\n",
    "                RowLSTM(hidden_dim),\n",
    "                RowLSTM(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(hidden_dim*2, hidden_dim*2, kernel_size=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(hidden_dim*2, 256, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(BATCH_SIZE, 256, 1, 28, 28)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56925f7-b69a-48fa-9e12-714ab7fe3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = torch.randn(BATCH_SIZE, 1, 28, 28, device=DEVICE)\n",
    "model = PixelRNN(16).to(DEVICE)\n",
    "model(test_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fb017-7685-488f-96a6-ac4dd361f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='../datasets/', \n",
    "                                           train=True, \n",
    "                                           transform=T.PILToTensor(), \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../datasets/', \n",
    "                                           train=False, \n",
    "                                           transform=T.PILToTensor(), \n",
    "                                           download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ab1e6-f142-4eb4-a43b-d5c293cc272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28992ff-e41f-4478-aeec-d2072adac04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelRNN(HIDDEN_DIM).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2545fb-47fe-497f-979a-c2b99b4633f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        for features, _ in tqdm(train_dataloader, leave=False):\n",
    "            features = features.to(DEVICE)\n",
    "            logits = model(features.float() / 255)\n",
    "            loss = criterion(logits, features.long())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.cpu().item())\n",
    "        \n",
    "        # inference\n",
    "        with torch.inference_mode():\n",
    "            for features, _ in test_dataloader:\n",
    "                features = features.to(DEVICE)\n",
    "                logits = model(features.float() / 255)\n",
    "                loss = criterion(logits, features.long())\n",
    "                test_losses.append(loss.cpu().item())\n",
    "\n",
    "        ce_train = sum(train_losses)/len(train_losses)\n",
    "        ce_test = sum(test_losses)/len(test_losses)\n",
    "        print(f'Epoch: {epoch}/{NUM_EPOCHS}, Cross Entropy Train: {ce_train:.4f}, Cross Entropy Test: {ce_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907049b4-a617-44d8-b662-33c59924c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ec171-1ab6-4ef2-b3da-4cdf1a74e09b",
   "metadata": {},
   "source": [
    "## PixelCNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
