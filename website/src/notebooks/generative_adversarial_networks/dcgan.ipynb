{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4468ad7c-4a25-4da1-a74d-a6ad4ca9c475",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Networks (DCGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6355a2-147e-4ed4-a894-12294730c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5b2a7a-f65c-4eab-97aa-07bc263077a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd6ca80-773d-4305-9a15-c82a8d8c1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "LR = 2e-4\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LATENT_SIZE = 100\n",
    "IMG_SIZE = 28*28\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed79f81-3382-44fb-9d83-7960de4a8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=LATENT_SIZE, out_channels=1024, kernel_size=4, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=1, kernel_size=4, padding=1, stride=2, bias=True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.generator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41bfeeb8-be90-45aa-a94e-98eb034b1028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check generator\n",
    "gen = Generator().to(DEVICE)\n",
    "dummy_input = torch.randn(BATCH_SIZE, LATENT_SIZE, 1, 1, device=DEVICE)\n",
    "gen(dummy_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef004a4-0bdb-4f3e-9390-15722ba100a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=4, padding=1, stride=2, bias=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, padding=0, stride=1, bias=True),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f995d90-346a-4434-a462-c41c8bb835cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check discriminator\n",
    "dis = Discriminator()\n",
    "dummy_input = torch.randn(BATCH_SIZE, 1, 64, 64)\n",
    "dis(dummy_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4dc2df9-83fa-4839-8ab3-03aafa275474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and dataloader\n",
    "transform = T.Compose([T.Resize(64), T.ToTensor(), T.Normalize(mean=(0.5 , ), std=(0.5,)) ])\n",
    "dataset = datasets.MNIST(root='../datasets/', train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89594fc6-62d7-469e-a59c-6158b3ea4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(DEVICE)\n",
    "discriminator = Discriminator().to(DEVICE)\n",
    "gen_optim = optim.Adam(generator.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "dis_optim = optim.Adam(discriminator.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "writer = SummaryWriter('runs/dcgan_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b57e78a-5959-4f0e-98c4-5bbb75579eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this tensor is useful to track images that are created from a fixed latent variable\n",
    "# that way we can observe if the generator starts to create better images\n",
    "fixed_noise = torch.randn((BATCH_SIZE, LATENT_SIZE, 1, 1), device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf6258b-2686-4801-986c-8fbaec788442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 || Discriminator Loss: 0.3120 || Generator Loss: 6.8920\n",
      "Epoch 2/10 || Discriminator Loss: 0.8425 || Generator Loss: 2.2131\n",
      "Epoch 3/10 || Discriminator Loss: 0.5060 || Generator Loss: 3.5763\n",
      "Epoch 4/10 || Discriminator Loss: 0.4448 || Generator Loss: 4.0151\n",
      "Epoch 5/10 || Discriminator Loss: 0.3350 || Generator Loss: 4.4055\n",
      "Epoch 6/10 || Discriminator Loss: 0.2965 || Generator Loss: 4.7895\n",
      "Epoch 7/10 || Discriminator Loss: 0.3675 || Generator Loss: 4.5363\n",
      "Epoch 8/10 || Discriminator Loss: 0.1050 || Generator Loss: 6.3591\n",
      "Epoch 9/10 || Discriminator Loss: 0.0916 || Generator Loss: 9.0453\n",
      "Epoch 10/10 || Discriminator Loss: 0.0519 || Generator Loss: 7.5223\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    dis_loss_col = []\n",
    "    gen_loss_col = []\n",
    "    for batch_idx, (features, _) in enumerate(dataloader):\n",
    "        real_images = features.to(DEVICE)\n",
    "        \n",
    "        # generate fake images from standar normal distributed latent vector\n",
    "        latent_vector = torch.randn(BATCH_SIZE, LATENT_SIZE, 1, 1, device=DEVICE)\n",
    "        fake_imgs = generator(latent_vector)\n",
    "        \n",
    "        # calculate logits for true and fake images\n",
    "        fake_logits = discriminator(fake_imgs.detach())\n",
    "        real_logits = discriminator(real_images)\n",
    "        \n",
    "        # calculate discriminator loss\n",
    "        dis_real_loss = criterion(real_logits, torch.ones(BATCH_SIZE, 1, device=DEVICE))\n",
    "        dis_fake_loss = criterion(fake_logits, torch.zeros(BATCH_SIZE, 1, device=DEVICE))\n",
    "        dis_loss = dis_real_loss + dis_fake_loss\n",
    "        \n",
    "        # optimize the discriminator \n",
    "        dis_optim.zero_grad()\n",
    "        dis_loss.backward()\n",
    "        dis_optim.step()\n",
    "\n",
    "        # calculate generator loss\n",
    "        gen_loss = criterion(discriminator(fake_imgs), torch.ones(BATCH_SIZE, 1, device=DEVICE))\n",
    "        \n",
    "        # optimize the generator\n",
    "        gen_optim.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        gen_optim.step()\n",
    "        \n",
    "        dis_loss_col.append(dis_loss.cpu().item())\n",
    "        gen_loss_col.append(gen_loss.cpu().item())\n",
    "\n",
    "    dis_loss = sum(dis_loss_col) / len(dis_loss_col)\n",
    "    gen_loss = sum(gen_loss_col) / len(gen_loss_col)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS} || Discriminator Loss: {dis_loss:.4f} || Generator Loss: {gen_loss:.4f}')\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        fake_imgs = generator(fixed_noise)\n",
    "        grid = torchvision.utils.make_grid(fake_imgs, normalize=True)\n",
    "\n",
    "        writer.add_image(\n",
    "            \"MNIST DCGAN Generated Images\", grid, global_step=epoch+1\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
