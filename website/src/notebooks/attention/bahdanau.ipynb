{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa82834c-970e-4e04-8c8a-3d77f4d7ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a72721b-fe59-491f-84c2-1efcf59782a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2a006b-c673-4bd9-ac7b-9844cacf5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9376k  100 9376k    0     0   188k      0  0:00:49  0:00:49 --:--:--  318k0  173k\n",
      "/home/petruschka/repos/World4AI/website/src/notebooks/sequence_modelling\n"
     ]
    }
   ],
   "source": [
    "!cd ../datasets/ && { curl -O https://www.manythings.org/anki/deu-eng.zip ; cd -; }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b736cd28-baee-47d2-8290-79373465ed10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../datasets/deu-eng.zip\n",
      "  inflating: ../datasets/deu_eng/deu.txt  \n",
      "  inflating: ../datasets/deu_eng/_about.txt  \n"
     ]
    }
   ],
   "source": [
    "!rm -rf ../datasets/deu_eng/\n",
    "!unzip ../datasets/deu-eng.zip -d ../datasets/deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f02455d-6531-4fe3-8fa6-39439fc8e568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_about.txt  deu.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88ac5b9-8045-44f0-b175-18db6d86d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tGeh.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)\n",
      "Hi.\tHallo!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)\n",
      "Hi.\tGrüß Gott!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)\n",
      "Run!\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)\n",
      "Run.\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #941078 (Fingerhut)\n",
      "Wow!\tPotzdonner!\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #2122382 (Pfirsichbaeumchen)\n",
      "Wow!\tDonnerwetter!\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #2122391 (Pfirsichbaeumchen)\n",
      "Duck!\tKopf runter!\tCC-BY 2.0 (France) Attribution: tatoeba.org #280158 (CM) & #9968521 (wolfgangth)\n",
      "Fire!\tFeuer!\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #1958697 (Tamy)\n",
      "Help!\tHilfe!\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #575889 (MUIRIEL)\n"
     ]
    }
   ],
   "source": [
    "!head ../datasets/deu_eng/deu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0332a0a8-06ed-455a-93cf-b3eaa7299f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    return s\n",
    "\n",
    "def tokenizer(s):\n",
    "    s = normalize(s)\n",
    "    return s.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413bc681-ae4b-42c3-a507-20fbd07c0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pairs(max_len=30):\n",
    "    print(\"Reading lines...\")\n",
    "    en_seq = []\n",
    "    de_seq = []\n",
    "    with open('../datasets/deu_eng/deu.txt', 'r', encoding='utf-8') as file:\n",
    "        print(f\"Tokenizing and removing sentences larger than {max_len}\")\n",
    "        for line in file:\n",
    "            pairs = line.split('\\t')\n",
    "            if len(pairs[0]) <= max_len or len(pairs[1]) <= max_len:\n",
    "                en_seq.append(tokenizer(pairs[0]))\n",
    "                de_seq.append(tokenizer(pairs[1]))\n",
    "        print(f\"The dataset has {len(en_seq)} pairs\")\n",
    "        return en_seq, de_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff624e79-6813-49ba-b9b5-b377638a0ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Tokenizing and removing sentences larger than 30\n",
      "The dataset has 146276 pairs\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=30\n",
    "en_seq, de_seq = read_pairs(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2eb335-6871-4b64-b4e0-460589cc0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f4649d-692e-44ed-97d0-b126290cdd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate into train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a09cbf-53d4-4d11-8d94-dea170dd3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_frac = 0.8\n",
    "# val_frac = 0.1\n",
    "# test_frac = 0.1\n",
    "train_en, test_val_en, train_de, test_val_de = train_test_split(en_seq, de_seq, test_size=0.2)\n",
    "val_en, test_en, val_de, test_de = train_test_split(test_val_en, test_val_de, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8507c0a9-ef46-415e-ac9e-67f0f32fb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, en, de):\n",
    "        assert len(en) == len(de)\n",
    "        self.en = en\n",
    "        self.de = de\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.en)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.en[idx], self.de[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4ff779-6838-415f-bbbf-279ebbe11b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairDataset(train_en, train_de)\n",
    "val_dataset = PairDataset(val_en, val_de)\n",
    "test_dataset = PairDataset(test_en, test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99763d07-e766-47c5-8188-d1f6340f8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f5a425-969d-403c-acb2-272b5c0e83c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_counter = Counter()\n",
    "de_counter = Counter()\n",
    "\n",
    "for line in train_en:\n",
    "    en_counter.update(line)\n",
    "\n",
    "for line in train_de:\n",
    "    de_counter.update(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcda074a-8a8f-49a2-a5b0-604fa7d61550",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sorted_by_freq_tuples = sorted(en_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "en_ordered_dict = OrderedDict(en_sorted_by_freq_tuples)\n",
    "\n",
    "de_sorted_by_freq_tuples = sorted(de_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "de_ordered_dict = OrderedDict(de_sorted_by_freq_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af822cd1-11a2-4cca-a437-c8f23f7dc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "en_vocab = torchtext.vocab.vocab(en_ordered_dict, min_freq = 5, specials=['<pad>', '<unk>', '<sos>', '<eos>'], special_first = True)\n",
    "de_vocab = torchtext.vocab.vocab(de_ordered_dict, min_freq = 5, specials=['<pad>', '<unk>', '<sos>', '<eos>'], special_first = True)\n",
    "\n",
    "en_vocab.set_default_index(1)\n",
    "de_vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcb00ac-2d9a-4b43-9d63-fbdca0e5b289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab([\"<eos>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45a27008-f281-4842-9b40-632f69fa1581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 23, 6, 125, 8]\n",
      "[22, 337, 11, 7]\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab([\"what\", \"are\", \"you\", \"doing\", \"?\"]))\n",
    "print(de_vocab([\"was\", \"machst\", \"du\", \"?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6ac325-500d-426c-aea0-124dad650fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    en, de, seq_len = [], [], []\n",
    "    for en_token, de_token in batch:\n",
    "        # add <sos> at start and <eos> at end\n",
    "        for lang in [en_token, de_token]:\n",
    "            lang.append('<eos>')\n",
    "            lang.insert(0, '<sos>')\n",
    "        en.append(torch.tensor(en_vocab(en_token), dtype=torch.int64))\n",
    "        de.append(torch.tensor(de_vocab(de_token), dtype=torch.int64))\n",
    "        seq_len.append(len(en_token))\n",
    "\n",
    "    return nn.utils.rnn.pad_sequence(en, batch_first=True), nn.utils.rnn.pad_sequence(de, batch_first=True), torch.tensor(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d359ccf0-0c97-4ed5-bbe8-27d65a39cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2,\n",
    "                              drop_last=True,\n",
    "                              collate_fn=collate)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=2,\n",
    "                              drop_last=False,\n",
    "                              collate_fn=collate)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=2,\n",
    "                              drop_last=False,\n",
    "                              collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407af9ab-2874-449c-8b23-ef98fe922bd7",
   "metadata": {},
   "source": [
    "Just one layer for encoder and decoder to make the calculations simpler, but biderectional as in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a510fffd-d4ed-4f8f-bbc6-b4a6d8787b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        outputs, (h_n, c_n) = self.lstm(x)\n",
    "        return outputs, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "9491323b-ce70-4782-8e10-c909e87a1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm_cell = nn.LSTMCell(input_size=embedding_dim, hidden_size=hidden_size)\n",
    "        self.energy = nn.Linear(hidden_size*2, 1)\n",
    "        self.combine = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_embeddings)\n",
    "    \n",
    "    def forward(self, x, h, c, encoder_outputs):\n",
    "        embedding = self.embedding(x) \n",
    "        h, c = h.squeeze(0), c.squeeze(0)\n",
    "        \n",
    "        energy_input = h.unsqueeze(1).repeat(1, encoder_outputs.shape[1], 1)\n",
    "        energy_input = torch.cat((encoder_outputs, energy_input), dim=2)\n",
    "        energy = self.energy(energy_input).squeeze(2)\n",
    "        attention = torch.softmax(energy, dim=1)\n",
    "        \n",
    "        context = torch.bmm(attention.unsqueeze(1), encoder_outputs)\n",
    "        context = context.squeeze(1)\n",
    "        \n",
    "        x = self.combine(torch.cat((context, embedding), dim=1))\n",
    "        (h_n, c_n) = self.lstm_cell(x, (h, c))\n",
    "        logits = self.fc(h_n)\n",
    "        return logits, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "1813cbf7-3950-498e-a6c9-ea31ed38de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, teacher_forcing_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "    \n",
    "    def forward(self, en_sequence, de_sequence):\n",
    "        batch_size, sequence_len, num_de_embeddings = de_sequence.size()[0], de_sequence.size()[1], self.decoder.embedding.num_embeddings\n",
    "        \n",
    "        # minus 1 due to fewer predictions as inputs, we don't predict <sos>\n",
    "        outputs = torch.zeros(batch_size, sequence_len-1, num_de_embeddings, device=DEVICE)\n",
    "\n",
    "        encoder_outputs, h_n, c_n = self.encoder(en_sequence)\n",
    "        inp = de_sequence[:, 0]\n",
    "        for i in range(1, sequence_len):\n",
    "            logits, h_n, c_n = decoder(inp, h_n, c_n, encoder_outputs)\n",
    "            outputs[:, i-1] = logits\n",
    "            \n",
    "            force = random.random() < self.teacher_forcing_ratio\n",
    "            if force:\n",
    "                inp = de_sequence[:, i]\n",
    "            else:\n",
    "                inp = logits.argmax(dim=1)\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "b1104bc7-39e7-4043-8025-3ca27e08feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_performance(dataloader, model, criterion):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    num_iterations = 0\n",
    "\n",
    "    # no need to calculate gradients\n",
    "    with torch.inference_mode():\n",
    "        for en_sequence, de_sequence, _ in dataloader:\n",
    "            en_sequence = en_sequence.to(DEVICE)\n",
    "            de_sequence = de_sequence.to(DEVICE)\n",
    "\n",
    "            logits = model(en_sequence, de_sequence)\n",
    "            \n",
    "            # we don't actually predict the <sos> token\n",
    "            labels = de_sequence[:, 1:]\n",
    "            # we need to reshape in order to be able to use these tensors with CrossEntropyLoss\n",
    "            logits = logits.reshape(-1, logits.size()[2])\n",
    "            labels = labels.reshape(-1)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss_sum += loss.cpu().item()\n",
    "            num_iterations+=1\n",
    "\n",
    "    # we return the average loss and the accuracy\n",
    "    return loss_sum/num_iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8eedecc2-1f89-4aa6-90b9-12f78bf885e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, train_dataloader, val_dataloader, model, optimizer, criterion, scheduler=None):\n",
    "    min_loss = float(\"inf\")\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "        for en_sequence, de_sequence, _ in train_dataloader:\n",
    "            model.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            en_sequence = en_sequence.to(DEVICE)\n",
    "            de_sequence = de_sequence.to(DEVICE)\n",
    "\n",
    "            logits = model(en_sequence, de_sequence)\n",
    "            # we don't actually predict the <sos> token\n",
    "            labels = de_sequence[:, 1:]\n",
    "\n",
    "            # we need to reshape in order to be able to use these tensors with CrossEntropyLoss\n",
    "            logits = logits.reshape(-1, logits.size()[2])\n",
    "            labels = labels.reshape(-1)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_sum += loss.cpu().item()\n",
    "            num_iterations += 1\n",
    "        train_loss=loss_sum/num_iterations\n",
    "        val_loss = track_performance(val_dataloader, model, criterion)\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        print(f'Epoch: {epoch+1:>2}/{num_epochs} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f}')\n",
    "        \n",
    "        if val_loss < min_loss:\n",
    "            print(\"Saving Weights!\")\n",
    "            min_loss = val_loss\n",
    "            torch.save({'encoder_weights': encoder.state_dict(), 'decoder_weights': decoder.state_dict()}, f='../temp/encoder_decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1f711e59-f852-4ed4-87f7-4149509c04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(num_embeddings=len(en_vocab), embedding_dim=256, hidden_size=256)\n",
    "decoder = Decoder(num_embeddings=len(de_vocab), embedding_dim=256, hidden_size=256)\n",
    "seq2seq = EncoderDecoder(encoder, decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "701cb41f-3f2f-4fce-a898-ad0944684f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='min',\n",
    "                                                       patience=2,\n",
    "                                                       verbose=True)\n",
    "\n",
    "num_epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "579c5e78-8445-4a7e-be90-ec3354e7a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(num_epochs, train_dataloader, val_dataloader, seq2seq, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6b07358a-1e25-4d56-80f7-c99fc2ba35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('../temp/encoder_decoder.pt')\n",
    "encoder_weights = weights['encoder_weights']\n",
    "decoder_weights = weights['decoder_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "2bde101c-c538-46fa-b019-2d9dd9f720bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(num_embeddings=len(en_vocab), embedding_dim=256, hidden_size=256).to(DEVICE)\n",
    "decoder = Decoder(num_embeddings=len(de_vocab), embedding_dim=256, hidden_size=256).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "21e58c7b-f938-47a2-beb7-46b2946f546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(encoder_weights)\n",
    "decoder.load_state_dict(decoder_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "dd4dee66-61d6-4d20-9e4e-df4707ab9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, vocab, encoder, decoder):\n",
    "    with torch.inference_mode():\n",
    "        outputs = []\n",
    "        \n",
    "        start_token = [\"<sos>\"]\n",
    "        end_token = [\"<eos>\"]\n",
    "        start_idx = vocab(start_token)[0]\n",
    "        end_idx = vocab(end_token)[0]\n",
    "                \n",
    "        encoder_outputs, h_n, c_n = encoder(sentence)\n",
    "        inp = torch.tensor([start_idx], device=DEVICE)\n",
    "        while True:\n",
    "            logits, h_n, c_n = decoder(inp, h_n, c_n, encoder_outputs)\n",
    "            h_n = h_n.unsqueeze(0)\n",
    "            c_n = c_n.unsqueeze(0)\n",
    "            inp = logits.argmax(dim=1)\n",
    "            outputs.append(inp.cpu().item())\n",
    "            if inp.item() == end_idx:\n",
    "                break\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "19010865-7d4f-402e-b4c6-7eb7de5d1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sequence, de_sequence, _ = next(iter(test_dataloader))\n",
    "en_sequence = en_sequence.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "d4938fd1-44e6-4c3d-805a-f750e02f44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'come', 'on', 'monday', 'if', 'you', 'can', '.', '<eos>', '<pad>']\n",
      "German Translation: ['<sos>', 'kommen', 'sie', 'am', 'montag,', 'wenn', 'sie', 'können', '.', '<eos>', '<pad>']\n",
      "Model Translation: ['komm', 'am', 'montag,', 'wenn', 'du', 'kannst', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'tom', 'is', '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'tom', 'ist', '<unk>', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['tom', 'ist', '<unk>', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', \"you're\", 'still', 'young', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'sie', 'sind', 'noch', 'jung', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['du', 'bist', 'noch', 'jung', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'who', 'do', 'you', 'think', 'did', 'that', '?', '<eos>', '<pad>']\n",
      "German Translation: ['<sos>', '<unk>', 'glaubst', 'du,', 'hat', 'das', 'getan', '?', '<eos>', '<pad>', '<pad>']\n",
      "Model Translation: ['wer', 'glaubt', 'ihr,', 'das', 'getan', 'hat', '?', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', \"it'll\", 'get', 'warmer', 'soon', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'es', 'wird', 'bald', 'wärmer', 'werden', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['es', 'wird', 'bald', 'bald', 'wärmer', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', \"who's\", 'eaten', 'all', 'the', 'cookies', '?', '<eos>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'wer', 'hat', 'die', 'ganzen', 'kekse', 'gegessen', '?', '<eos>', '<pad>', '<pad>']\n",
      "Model Translation: ['wer', 'hat', 'die', 'ganzen', 'kekse', 'gegessen', '?', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'stay', 'away', 'from', 'my', 'computer', '.', '<eos>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'finger', 'weg', 'von', 'meinem', 'rechner', '!', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['halte', 'mich', 'von', 'meinem', '<unk>', 'fern', '!', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'come', 'and', 'get', 'me', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'komm', 'und', 'hol', 'mich', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['komm', 'und', 'und', 'hol', 'mich', '!', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'we', 'went', 'out', 'for', 'some', 'drinks', '.', '<eos>', '<pad>']\n",
      "German Translation: ['<sos>', 'wir', 'sind', '<unk>', 'um', 'etwas', 'zu', 'trinken', '.', '<eos>', '<pad>']\n",
      "Model Translation: ['wir', 'sind', '<unk>', 'paar', 'einkaufen', 'gefahren', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'why', 'is', 'nobody', 'eating', '?', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'warum', 'isst', 'denn', 'niemand', 'etwas', '?', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['warum', 'ist', 'niemand', 'mehr', '?', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    en_sentence = en_sequence[i].unsqueeze(0)\n",
    "    de_sentence = de_sequence[i].unsqueeze(0)\n",
    "    translation = translate_sentence(en_sentence, en_vocab, encoder, decoder)\n",
    "    print('-'*130)\n",
    "    print(f'English Sentence: {en_vocab.lookup_tokens(en_sentence[0].cpu().tolist())}')\n",
    "    print(f'German Translation: {de_vocab.lookup_tokens(de_sentence[0].cpu().tolist())}')\n",
    "    print(f'Model Translation: {de_vocab.lookup_tokens(translation)}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
