{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24bca2d0-a741-4d0b-a591-0728cdd114a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7f4086-c001-41f3-b389-13396d4ec6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4\n",
    "SEQUENCE_LENGTH=5\n",
    "INPUT_SIZE=2\n",
    "HIDDEN_SIZE=3\n",
    "NUM_LAYERS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe2732d-e1ba-456f-b0c5-f77cbcc98426",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42bbd37f-1103-443d-a84d-65bcb61e356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input to hidden weights and biases\n",
    "w_ih = lstm.weight_ih_l0\n",
    "b_ih = lstm.bias_ih_l0\n",
    "\n",
    "w_ii = w_ih[0*HIDDEN_SIZE:1*HIDDEN_SIZE]\n",
    "w_if = w_ih[1*HIDDEN_SIZE:2*HIDDEN_SIZE]\n",
    "w_ig = w_ih[2*HIDDEN_SIZE:3*HIDDEN_SIZE]\n",
    "w_io = w_ih[3*HIDDEN_SIZE:]\n",
    "\n",
    "b_ii = b_ih[0*HIDDEN_SIZE:1*HIDDEN_SIZE]\n",
    "b_if = b_ih[1*HIDDEN_SIZE:2*HIDDEN_SIZE]\n",
    "b_ig = b_ih[2*HIDDEN_SIZE:3*HIDDEN_SIZE]\n",
    "b_io = b_ih[3*HIDDEN_SIZE:]\n",
    "\n",
    "# hidden to hidden weights and biases\n",
    "w_hh = lstm.weight_hh_l0\n",
    "b_hh = lstm.bias_hh_l0\n",
    "\n",
    "w_hi = w_hh[0*HIDDEN_SIZE:1*HIDDEN_SIZE]\n",
    "w_hf = w_hh[1*HIDDEN_SIZE:2*HIDDEN_SIZE]\n",
    "w_hg = w_hh[2*HIDDEN_SIZE:3*HIDDEN_SIZE]\n",
    "w_ho = w_hh[3*HIDDEN_SIZE:]\n",
    "\n",
    "b_hi = b_hh[0*HIDDEN_SIZE:1*HIDDEN_SIZE]\n",
    "b_hf = b_hh[1*HIDDEN_SIZE:2*HIDDEN_SIZE]\n",
    "b_hg = b_hh[2*HIDDEN_SIZE:3*HIDDEN_SIZE]\n",
    "b_ho = b_hh[3*HIDDEN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5408d0ac-82dd-4abd-97cf-7a12224b60d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inputs to the LSTM\n",
    "sequence = torch.randn(SEQUENCE_LENGTH, BATCH_SIZE, INPUT_SIZE)\n",
    "h_0 = torch.zeros(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)\n",
    "c_0 = torch.zeros(NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5520a91b-16ad-4a81-8921-6df86430d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (h_n, c_n) = lstm(sequence, (h_0, c_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bc319dd-8f83-42d1-ab5f-281cf1dd34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_lstm():\n",
    "    hidden = h_0.clone()\n",
    "    cell = c_0.clone()\n",
    "    output = torch.zeros(SEQUENCE_LENGTH, BATCH_SIZE, HIDDEN_SIZE)\n",
    "    with torch.inference_mode():\n",
    "        for idx, seq in enumerate(sequence):\n",
    "            f = torch.sigmoid(seq @ w_if.T + b_if + hidden[0] @ w_hf.T + b_hf)\n",
    "            i = torch.sigmoid(seq @ w_ii.T + b_ii + hidden[0] @ w_hi.T + b_hi)\n",
    "            o = torch.sigmoid(seq @ w_io.T + b_io + hidden[0] @ w_ho.T + b_ho)\n",
    "            g = torch.tanh(seq @ w_ig.T + b_ig + hidden[0] @ w_hg.T + b_hg)\n",
    "            \n",
    "            cell[0] = f * cell[0] + i * g\n",
    "            hidden[0] = o * torch.tanh(cell[0])\n",
    "            output[idx] = hidden[0]\n",
    "    return output, (hidden, cell)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
