{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91092fdf-0853-4beb-94d0-c609de719398",
   "metadata": {},
   "source": [
    "# Biderectional Recurrent Neural Network in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2679dc-8f64-4572-9f74-c6b4ef2d3dba",
   "metadata": {},
   "source": [
    "Turning a simple recurrent neuaral network into a biderectional neural network in PyTorch is extremely easy. All you have to do is to provide the `biderectional` parameter, which you set to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6821049d-29ff-4679-adc8-c76b1f385488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441406ca-cd55-46a0-8edc-c5220a6b6d7c",
   "metadata": {},
   "source": [
    "For the most part we require very similar paramters, but the `D` parameter (dimensionality) is new. We will use this parameter as a multiplier, when we will calculate certain dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91d3770-edb4-4eaf-93dc-656c8ba02561",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4\n",
    "SEQUENCE_LENGTH=5\n",
    "INPUT_SIZE=2\n",
    "HIDDEN_SIZE=3\n",
    "NUM_LAYERS=1\n",
    "BIDERECTIONAL=True\n",
    "D = 2 if BIDERECTIONAL == True else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f29cdb-ee85-4e3a-b720-72366f1f1e58",
   "metadata": {},
   "source": [
    "We set the `biderectional` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af487d1-c312-4299-928c-4a6bd990f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, bidirectional=BIDERECTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65737f01-7d4d-45ba-b40f-6c90c7abff51",
   "metadata": {},
   "source": [
    "This time we use just one layer, so that we only have `l_0` and no `l_1` set of weights, but we gain weights (and biases) which names end with `_reverse`. This are the weights and biases that we will use to calculate the hidden state when we traverse the sequence from finish to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2b17ec-b017-41be-8bbb-e5ae0406cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- #\n",
    "# weights forward\n",
    "# ---------------------------- #\n",
    "\n",
    "# input to hidden weights and biases\n",
    "w_ih_l0 = rnn.weight_ih_l0\n",
    "b_ih_l0 = rnn.bias_ih_l0\n",
    "\n",
    "# hidden to hidden weights and biases\n",
    "w_hh_l0 = rnn.weight_hh_l0\n",
    "b_hh_l0 = rnn.bias_hh_l0\n",
    "\n",
    "# ---------------------------- #\n",
    "# weights reverse\n",
    "# ---------------------------- #\n",
    "\n",
    "# input to hidden weights and biases\n",
    "w_r_ih_l0 = rnn.weight_ih_l0_reverse\n",
    "b_r_ih_l0 = rnn.bias_ih_l0_reverse\n",
    "\n",
    "# hidden to hidden weights and biases\n",
    "w_r_hh_l0 = rnn.weight_hh_l0_reverse\n",
    "b_r_hh_l0 = rnn.bias_hh_l0_reverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f7738-956c-46d0-a25d-f94b3eef5abf",
   "metadata": {},
   "source": [
    "The hidden state is going to contain an additional set of outputs due to the reverse traversing, therefore we scale initial hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5a0913-6d9f-4587-aa89-ac6f207abd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = torch.randn(SEQUENCE_LENGTH, BATCH_SIZE, INPUT_SIZE)\n",
    "h_0 = torch.zeros(D * NUM_LAYERS, BATCH_SIZE, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859e3a3d-2e10-4955-bc72-0e6d8e80cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    output, h_n = rnn(sequence, h_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea87dd-ceb9-4fd5-ba31-44a7550b4a1b",
   "metadata": {},
   "source": [
    "Once again we recommend you to work throught this manual implementation of a biderectional rnn. This will improve your understanding of the inner workings greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfbae8a3-8c61-42be-b151-d0da07ea6fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_rnn():\n",
    "    hidden = h_0.clone()\n",
    "    output = torch.zeros(SEQUENCE_LENGTH, BATCH_SIZE, D * HIDDEN_SIZE)\n",
    "    with torch.inference_mode():\n",
    "        for idx in range(SEQUENCE_LENGTH):\n",
    "            # use idx -> forward direction\n",
    "            hidden[0] = torch.tanh(sequence[idx] @ w_ih_l0.T + b_ih_l0 + hidden[0] @ w_hh_l0.T + b_hh_l0)\n",
    "            output[idx, :, :HIDDEN_SIZE] = hidden[0]\n",
    "            # use SEQUENCE_LENGTH - 1 -idx -> reverse direction\n",
    "            hidden[1] = torch.tanh(sequence[SEQUENCE_LENGTH - 1 -idx] @ w_r_ih_l0.T + b_r_ih_l0 + hidden[1] @ w_r_hh_l0.T + b_r_hh_l0)\n",
    "            output[SEQUENCE_LENGTH - 1 - idx, :, HIDDEN_SIZE:] = hidden[1]\n",
    "    return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b16545-790a-494c-9db3-78dfa02f215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_output, manual_h_n = manual_rnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee0c2a-325b-47b8-8fec-77968b29091a",
   "metadata": {},
   "source": [
    "We compare the results to make sure, that our implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef47a0f2-09d0-4e53-a87b-542854bfad38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6119,  0.7950,  0.5467,  0.2447, -0.6007,  0.2942],\n",
       "         [-0.3753,  0.1250,  0.7078,  0.1123,  0.1765, -0.0716],\n",
       "         [-0.0242,  0.7054,  0.8048,  0.2648, -0.1507,  0.6702],\n",
       "         [ 0.0957,  0.4837,  0.6330,  0.1857, -0.0234, -0.0326]],\n",
       "\n",
       "        [[-0.9501, -0.5405,  0.9671, -0.3674,  0.6894,  0.5082],\n",
       "         [-0.6360,  0.3203,  0.7740, -0.5183, -0.3718, -0.0748],\n",
       "         [-0.6780,  0.6467,  0.9565,  0.0843,  0.4808,  0.8144],\n",
       "         [-0.0305,  0.5113,  0.7426, -0.2721, -0.2520, -0.1512]],\n",
       "\n",
       "        [[-0.6581,  0.8128,  0.7064,  0.2179,  0.0232,  0.3551],\n",
       "         [-0.6379,  0.6315,  0.8972,  0.1088,  0.6091,  0.4488],\n",
       "         [ 0.1069,  0.8739,  0.8683,  0.6259,  0.3998,  0.5972],\n",
       "         [-0.8309, -0.1865,  0.8807, -0.2830,  0.5560, -0.2209]],\n",
       "\n",
       "        [[ 0.5591,  0.8903,  0.8370,  0.3448, -0.5082,  0.6432],\n",
       "         [ 0.1753,  0.6623,  0.7057,  0.1980, -0.2932, -0.1916],\n",
       "         [ 0.3917,  0.6472,  0.7297,  0.1548, -0.5782, -0.0358],\n",
       "         [ 0.8146,  0.9380, -0.0217,  0.3194, -0.7961, -0.4751]],\n",
       "\n",
       "        [[ 0.0027,  0.8121,  0.9247,  0.5688,  0.5199,  0.7585],\n",
       "         [ 0.8281,  0.8654,  0.5082,  0.4194, -0.6804, -0.0751],\n",
       "         [ 0.1160,  0.6814,  0.8117,  0.2579, -0.0431,  0.2809],\n",
       "         [ 0.2054, -0.0800,  0.7989, -0.0119, -0.2749, -0.0848]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d90fdbc-1962-4efd-a82b-666df4ee499a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6119,  0.7950,  0.5467,  0.2447, -0.6007,  0.2942],\n",
       "         [-0.3753,  0.1250,  0.7078,  0.1123,  0.1765, -0.0716],\n",
       "         [-0.0242,  0.7054,  0.8048,  0.2648, -0.1507,  0.6702],\n",
       "         [ 0.0957,  0.4837,  0.6330,  0.1857, -0.0234, -0.0326]],\n",
       "\n",
       "        [[-0.9501, -0.5405,  0.9671, -0.3674,  0.6894,  0.5082],\n",
       "         [-0.6360,  0.3203,  0.7740, -0.5183, -0.3718, -0.0748],\n",
       "         [-0.6780,  0.6467,  0.9565,  0.0843,  0.4808,  0.8144],\n",
       "         [-0.0305,  0.5113,  0.7426, -0.2721, -0.2520, -0.1512]],\n",
       "\n",
       "        [[-0.6581,  0.8128,  0.7064,  0.2179,  0.0232,  0.3551],\n",
       "         [-0.6379,  0.6315,  0.8972,  0.1088,  0.6091,  0.4488],\n",
       "         [ 0.1069,  0.8739,  0.8683,  0.6259,  0.3998,  0.5972],\n",
       "         [-0.8309, -0.1865,  0.8807, -0.2830,  0.5560, -0.2209]],\n",
       "\n",
       "        [[ 0.5591,  0.8903,  0.8370,  0.3448, -0.5082,  0.6432],\n",
       "         [ 0.1753,  0.6623,  0.7057,  0.1980, -0.2932, -0.1916],\n",
       "         [ 0.3917,  0.6472,  0.7297,  0.1548, -0.5782, -0.0358],\n",
       "         [ 0.8146,  0.9380, -0.0217,  0.3194, -0.7961, -0.4751]],\n",
       "\n",
       "        [[ 0.0027,  0.8121,  0.9247,  0.5688,  0.5199,  0.7585],\n",
       "         [ 0.8281,  0.8654,  0.5082,  0.4194, -0.6804, -0.0751],\n",
       "         [ 0.1160,  0.6814,  0.8117,  0.2579, -0.0431,  0.2809],\n",
       "         [ 0.2054, -0.0800,  0.7989, -0.0119, -0.2749, -0.0848]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7963d4f1-6efe-469b-8234-8fbae96c8ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0027,  0.8121,  0.9247],\n",
       "         [ 0.8281,  0.8654,  0.5082],\n",
       "         [ 0.1160,  0.6814,  0.8117],\n",
       "         [ 0.2054, -0.0800,  0.7989]],\n",
       "\n",
       "        [[ 0.2447, -0.6007,  0.2942],\n",
       "         [ 0.1123,  0.1765, -0.0716],\n",
       "         [ 0.2648, -0.1507,  0.6702],\n",
       "         [ 0.1857, -0.0234, -0.0326]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b5afda7-e91a-4704-8e4f-5fdf8e86edd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0027,  0.8121,  0.9247],\n",
       "         [ 0.8281,  0.8654,  0.5082],\n",
       "         [ 0.1160,  0.6814,  0.8117],\n",
       "         [ 0.2054, -0.0800,  0.7989]],\n",
       "\n",
       "        [[ 0.2447, -0.6007,  0.2942],\n",
       "         [ 0.1123,  0.1765, -0.0716],\n",
       "         [ 0.2648, -0.1507,  0.6702],\n",
       "         [ 0.1857, -0.0234, -0.0326]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_h_n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
