{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46bf153-29f9-4e41-93d8-aa4516252ca2",
   "metadata": {},
   "source": [
    "[PyTorch Tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa82834c-970e-4e04-8c8a-3d77f4d7ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a72721b-fe59-491f-84c2-1efcf59782a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2a006b-c673-4bd9-ac7b-9844cacf5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9376k  100 9376k    0     0   188k      0  0:00:49  0:00:49 --:--:--  318k0  173k\n",
      "/home/petruschka/repos/World4AI/website/src/notebooks/sequence_modelling\n"
     ]
    }
   ],
   "source": [
    "!cd ../datasets/ && { curl -O https://www.manythings.org/anki/deu-eng.zip ; cd -; }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b736cd28-baee-47d2-8290-79373465ed10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../datasets/deu-eng.zip\n",
      "  inflating: ../datasets/deu_eng/deu.txt  \n",
      "  inflating: ../datasets/deu_eng/_about.txt  \n"
     ]
    }
   ],
   "source": [
    "!rm -rf ../datasets/deu_eng/\n",
    "!unzip ../datasets/deu-eng.zip -d ../datasets/deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f02455d-6531-4fe3-8fa6-39439fc8e568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_about.txt  deu.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88ac5b9-8045-44f0-b175-18db6d86d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tGeh.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)\n",
      "Hi.\tHallo!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)\n",
      "Hi.\tGrüß Gott!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)\n",
      "Run!\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)\n",
      "Run.\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #941078 (Fingerhut)\n",
      "Wow!\tPotzdonner!\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #2122382 (Pfirsichbaeumchen)\n",
      "Wow!\tDonnerwetter!\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #2122391 (Pfirsichbaeumchen)\n",
      "Duck!\tKopf runter!\tCC-BY 2.0 (France) Attribution: tatoeba.org #280158 (CM) & #9968521 (wolfgangth)\n",
      "Fire!\tFeuer!\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #1958697 (Tamy)\n",
      "Help!\tHilfe!\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #575889 (MUIRIEL)\n"
     ]
    }
   ],
   "source": [
    "!head ../datasets/deu_eng/deu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0332a0a8-06ed-455a-93cf-b3eaa7299f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    return s\n",
    "\n",
    "def tokenizer(s):\n",
    "    s = normalize(s)\n",
    "    return s.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413bc681-ae4b-42c3-a507-20fbd07c0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pairs(max_len=30):\n",
    "    print(\"Reading lines...\")\n",
    "    en_seq = []\n",
    "    de_seq = []\n",
    "    with open('../datasets/deu_eng/deu.txt', 'r', encoding='utf-8') as file:\n",
    "        print(f\"Tokenizing and removing sentences larger than {max_len}\")\n",
    "        for line in file:\n",
    "            pairs = line.split('\\t')\n",
    "            if len(pairs[0]) <= max_len or len(pairs[1]) <= max_len:\n",
    "                en_seq.append(tokenizer(pairs[0]))\n",
    "                de_seq.append(tokenizer(pairs[1]))\n",
    "        print(f\"The dataset has {len(en_seq)} pairs\")\n",
    "        return en_seq, de_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff624e79-6813-49ba-b9b5-b377638a0ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Tokenizing and removing sentences larger than 30\n",
      "The dataset has 146276 pairs\n"
     ]
    }
   ],
   "source": [
    "en_seq, de_seq = read_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e2eb335-6871-4b64-b4e0-460589cc0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3f4649d-692e-44ed-97d0-b126290cdd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate into train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7a09cbf-53d4-4d11-8d94-dea170dd3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_frac = 0.8\n",
    "# val_frac = 0.1\n",
    "# test_frac = 0.1\n",
    "train_en, test_val_en, train_de, test_val_de = train_test_split(en_seq, de_seq, test_size=0.2)\n",
    "val_en, test_en, val_de, test_de = train_test_split(test_val_en, test_val_de, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8507c0a9-ef46-415e-ac9e-67f0f32fb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, en, de):\n",
    "        assert len(en) == len(de)\n",
    "        self.en = en\n",
    "        self.de = de\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.en)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.en[idx], self.de[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d4ff779-6838-415f-bbbf-279ebbe11b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairDataset(train_en, train_de)\n",
    "val_dataset = PairDataset(val_en, val_de)\n",
    "test_dataset = PairDataset(test_en, test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99763d07-e766-47c5-8188-d1f6340f8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f5a425-969d-403c-acb2-272b5c0e83c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_counter = Counter()\n",
    "de_counter = Counter()\n",
    "\n",
    "for line in train_en:\n",
    "    en_counter.update(line)\n",
    "\n",
    "for line in train_de:\n",
    "    de_counter.update(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcda074a-8a8f-49a2-a5b0-604fa7d61550",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sorted_by_freq_tuples = sorted(en_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "en_ordered_dict = OrderedDict(en_sorted_by_freq_tuples)\n",
    "\n",
    "de_sorted_by_freq_tuples = sorted(de_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "de_ordered_dict = OrderedDict(de_sorted_by_freq_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af822cd1-11a2-4cca-a437-c8f23f7dc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "en_vocab = torchtext.vocab.vocab(en_ordered_dict, min_freq = 5, specials=['<pad>', '<unk>', '<sos>', '<eos>'], special_first = True)\n",
    "de_vocab = torchtext.vocab.vocab(de_ordered_dict, min_freq = 5, specials=['<pad>', '<unk>', '<sos>', '<eos>'], special_first = True)\n",
    "\n",
    "en_vocab.set_default_index(1)\n",
    "de_vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edcb00ac-2d9a-4b43-9d63-fbdca0e5b289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab([\"<eos>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45a27008-f281-4842-9b40-632f69fa1581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 23, 6, 125, 8]\n",
      "[23, 342, 12, 7]\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab([\"what\", \"are\", \"you\", \"doing\", \"?\"]))\n",
    "print(de_vocab([\"was\", \"machst\", \"du\", \"?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d6ac325-500d-426c-aea0-124dad650fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    en, de, seq_len = [], [], []\n",
    "    for en_token, de_token in batch:\n",
    "        # add <sos> at start and <eos> at end\n",
    "        for lang in [en_token, de_token]:\n",
    "            lang.append('<eos>')\n",
    "            lang.insert(0, '<sos>')\n",
    "        en.append(torch.tensor(en_vocab(en_token), dtype=torch.int64))\n",
    "        de.append(torch.tensor(de_vocab(de_token), dtype=torch.int64))\n",
    "        seq_len.append(len(en_token))\n",
    "\n",
    "    return nn.utils.rnn.pad_sequence(en, batch_first=True), nn.utils.rnn.pad_sequence(de, batch_first=True), torch.tensor(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d359ccf0-0c97-4ed5-bbe8-27d65a39cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2,\n",
    "                              drop_last=True,\n",
    "                              collate_fn=collate)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=2,\n",
    "                              drop_last=False,\n",
    "                              collate_fn=collate)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=2,\n",
    "                              drop_last=False,\n",
    "                              collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a510fffd-d4ed-4f8f-bbc6-b4a6d8787b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size=128, lstm_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=lstm_layers, batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, c_n) = self.lstm(x)\n",
    "        return h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9491323b-ce70-4782-8e10-c909e87a1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size=128, lstm_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm_cell_list = nn.ModuleList([nn.LSTMCell(input_size=embedding_dim, hidden_size=hidden_size) for i in range(lstm_layers)])\n",
    "        self.fc = nn.Linear(hidden_size, num_embeddings)\n",
    "    \n",
    "    def forward(self, x, h, c):\n",
    "        x = self.embedding(x)\n",
    "        h_n, c_n = torch.zeros_like(h, device=DEVICE), torch.zeros_like(c, device=DEVICE)\n",
    "        for i, lstm_cell in enumerate(self.lstm_cell_list):\n",
    "            (h_n[i], c_n[i]) = lstm_cell(x, (h[i], c[i]))\n",
    "            x = h_n[i]\n",
    "        logits = self.fc(x)\n",
    "        return logits, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1813cbf7-3950-498e-a6c9-ea31ed38de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, teacher_forcing_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "    \n",
    "    def forward(self, en_sequence, de_sequence):\n",
    "        batch_size, sequence_len, num_de_embeddings = de_sequence.size()[0], de_sequence.size()[1], self.decoder.embedding.num_embeddings\n",
    "        \n",
    "        # minus 1 due to fewer predictions as inputs, we don't predict <sos>\n",
    "        outputs = torch.zeros(batch_size, sequence_len-1, num_de_embeddings, device=DEVICE)\n",
    "\n",
    "        h_n, c_n = self.encoder(en_sequence)\n",
    "        inp = de_batch[:, 0]\n",
    "        for i in range(1, sequence_len):\n",
    "            logits, h_n, c_n = decoder(de_batch[:, i-1], h_n, c_n)\n",
    "            outputs[:, i-1] = logits\n",
    "            \n",
    "            force = random.random() < self.teacher_forcing_ratio\n",
    "            if force:\n",
    "                inp = de_batch[:, i]\n",
    "            else:\n",
    "                inp = logits.argmax(dim=1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f711e59-f852-4ed4-87f7-4149509c04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(num_embeddings=len(en_vocab), embedding_dim=128)\n",
    "decoder = Decoder(num_embeddings=len(de_vocab), embedding_dim=128)\n",
    "seq2seq = EncoderDecoder(encoder, decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "faf31be1-ea93-45dc-9153-f514761852c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for debugging purposes\n",
    "# en_batch, de_batch, seq_len = next(iter(train_dataloader))\n",
    "# en_batch = en_batch.to(DEVICE)\n",
    "# de_batch = de_batch.to(DEVICE)\n",
    "# seq2seq(en_batch, de_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "701cb41f-3f2f-4fce-a898-ad0944684f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8eedecc2-1f89-4aa6-90b9-12f78bf885e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, dataloader, model, optimizer, criterion):\n",
    "    model.train()\n",
    "    for epoch, (en_sequence, de_sequence, _) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        en_sequence = en_batch.to(DEVICE)\n",
    "        de_sequence = de_batch.to(DEVICE)\n",
    "        \n",
    "        logits = model(en_sequence, de_sequence)\n",
    "        print(logits.shape)\n",
    "        # we don't actually predict the <sos> token\n",
    "        labels = de_sequence[:, 1:]\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "579c5e78-8445-4a7e-be90-ec3354e7a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 5804])\n",
      "tensor([[  13,    8,   56,   58,  339,    4,    3,    0,    0,    0],\n",
      "        [ 460,  290,   24,   13,  416,    4,    3,    0,    0,    0],\n",
      "        [   6,  629,  109,   38,    5,   20, 4909,    8,    4,    3],\n",
      "        [ 189,  110,    6,   10,   78,   15,   68,    4,    3,    0],\n",
      "        [  18,    8,   20,  228, 2417,    4,    3,    0,    0,    0],\n",
      "        [   6,   21,   31, 1828,   56,   44,    4,    3,    0,    0],\n",
      "        [ 137,    8,    9, 4894,    7,    3,    0,    0,    0,    0],\n",
      "        [  23,  429,  225,   38,   43,    1,    7,    3,    0,    0],\n",
      "        [  12,  181,   22, 2493,   32,   11,  532,    4,    3,    0],\n",
      "        [1126,    5,   40,    7,    3,    0,    0,    0,    0,    0],\n",
      "        [  76,    5,   88,   48,    7,    3,    0,    0,    0,    0],\n",
      "        [   6,   28, 1306,  127, 2571,    4,    3,    0,    0,    0],\n",
      "        [   5,   14,  172,   10, 1469,    4,    3,    0,    0,    0],\n",
      "        [   5,   14,   13,    4,    3,    0,    0,    0,    0,    0],\n",
      "        [1799,  279, 1045,   60,  991,    4,    3,    0,    0,    0],\n",
      "        [  18,   14,  147,    1,    4,    3,    0,    0,    0,    0],\n",
      "        [   6,  637,  230,  469,  626,    4,    3,    0,    0,    0],\n",
      "        [  37,    5,    9, 1168,    1,    7,    3,    0,    0,    0],\n",
      "        [   6,   21,    9,    1,    4,    3,    0,    0,    0,    0],\n",
      "        [  62, 1596,    5,   10,   16,    3,    0,    0,    0,    0],\n",
      "        [   5,   54,   75,   10,   84, 5149,    4,    3,    0,    0],\n",
      "        [   5,    8,  518,    1,   10,  155,    7,    3,    0,    0],\n",
      "        [  18,    1,   98, 3383,    4,    3,    0,    0,    0,    0],\n",
      "        [   6,   21,    1,   27,    1, 1472,  141,    4,    3,    0],\n",
      "        [   5,   24,   83,   73, 5094,    4,    3,    0,    0,    0],\n",
      "        [  82,   11,   13,   34,  145, 1198,    4,    3,    0,    0],\n",
      "        [   6,   28,  966,   94,   25,    4,    3,    0,    0,    0],\n",
      "        [   6, 2276,  109,   23,    6,  525,    4,    3,    0,    0],\n",
      "        [  14,   75,   19,    1,  244,    7,    3,    0,    0,    0],\n",
      "        [  59, 1264,  191,   26,  676,    4,    3,    0,    0,    0],\n",
      "        [   6,   63,   10, 1215,   23,   25,  166,  101,    4,    3],\n",
      "        [  11,  657,  476,  802,    4,    3,    0,    0,    0,    0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [32, 5804], got [32, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq2seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(num_epochs, dataloader, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     11\u001b[0m labels \u001b[38;5;241m=\u001b[39m de_sequence[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels)\n\u001b[0;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/modules/loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [32, 5804], got [32, 10]"
     ]
    }
   ],
   "source": [
    "train(10, train_dataloader, seq2seq, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3ed52-b92f-4439-b757-eec819f4924c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
