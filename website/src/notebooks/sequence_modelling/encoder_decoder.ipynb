{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46bf153-29f9-4e41-93d8-aa4516252ca2",
   "metadata": {},
   "source": [
    "[PyTorch Tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa82834c-970e-4e04-8c8a-3d77f4d7ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a72721b-fe59-491f-84c2-1efcf59782a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2a006b-c673-4bd9-ac7b-9844cacf5fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9376k  100 9376k    0     0   188k      0  0:00:49  0:00:49 --:--:--  318k0  173k\n",
      "/home/petruschka/repos/World4AI/website/src/notebooks/sequence_modelling\n"
     ]
    }
   ],
   "source": [
    "!cd ../datasets/ && { curl -O https://www.manythings.org/anki/deu-eng.zip ; cd -; }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b736cd28-baee-47d2-8290-79373465ed10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../datasets/deu-eng.zip\n",
      "  inflating: ../datasets/deu_eng/deu.txt  \n",
      "  inflating: ../datasets/deu_eng/_about.txt  \n"
     ]
    }
   ],
   "source": [
    "!rm -rf ../datasets/deu_eng/\n",
    "!unzip ../datasets/deu-eng.zip -d ../datasets/deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f02455d-6531-4fe3-8fa6-39439fc8e568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_about.txt  deu.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88ac5b9-8045-44f0-b175-18db6d86d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tGeh.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)\n",
      "Hi.\tHallo!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)\n",
      "Hi.\tGrüß Gott!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)\n",
      "Run!\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)\n",
      "Run.\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #941078 (Fingerhut)\n",
      "Wow!\tPotzdonner!\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #2122382 (Pfirsichbaeumchen)\n",
      "Wow!\tDonnerwetter!\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #2122391 (Pfirsichbaeumchen)\n",
      "Duck!\tKopf runter!\tCC-BY 2.0 (France) Attribution: tatoeba.org #280158 (CM) & #9968521 (wolfgangth)\n",
      "Fire!\tFeuer!\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #1958697 (Tamy)\n",
      "Help!\tHilfe!\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #575889 (MUIRIEL)\n"
     ]
    }
   ],
   "source": [
    "!head ../datasets/deu_eng/deu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0332a0a8-06ed-455a-93cf-b3eaa7299f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    return s\n",
    "\n",
    "def tokenizer(s):\n",
    "    s = normalize(s)\n",
    "    return s.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413bc681-ae4b-42c3-a507-20fbd07c0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pairs(max_len=30):\n",
    "    print(\"Reading lines...\")\n",
    "    en_seq = []\n",
    "    de_seq = []\n",
    "    with open('../datasets/deu_eng/deu.txt', 'r', encoding='utf-8') as file:\n",
    "        print(f\"Tokenizing and removing sentences larger than {max_len}\")\n",
    "        for line in file:\n",
    "            pairs = line.split('\\t')\n",
    "            if len(pairs[0]) <= max_len or len(pairs[1]) <= max_len:\n",
    "                en_seq.append(tokenizer(pairs[0]))\n",
    "                de_seq.append(tokenizer(pairs[1]))\n",
    "        print(f\"The dataset has {len(en_seq)} pairs\")\n",
    "        return en_seq, de_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff624e79-6813-49ba-b9b5-b377638a0ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Tokenizing and removing sentences larger than 30\n",
      "The dataset has 146276 pairs\n"
     ]
    }
   ],
   "source": [
    "en_seq, de_seq = read_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e2eb335-6871-4b64-b4e0-460589cc0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3f4649d-692e-44ed-97d0-b126290cdd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate into train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7a09cbf-53d4-4d11-8d94-dea170dd3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_frac = 0.8\n",
    "# val_frac = 0.1\n",
    "# test_frac = 0.1\n",
    "train_en, test_val_en, train_de, test_val_de = train_test_split(en_seq, de_seq, test_size=0.2)\n",
    "val_en, test_en, val_de, test_de = train_test_split(test_val_en, test_val_de, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8507c0a9-ef46-415e-ac9e-67f0f32fb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, en, de):\n",
    "        assert len(en) == len(de)\n",
    "        self.en = en\n",
    "        self.de = de\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.en)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.en[idx], self.de[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4ff779-6838-415f-bbbf-279ebbe11b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PairDataset(train_en, train_de)\n",
    "val_dataset = PairDataset(val_en, val_de)\n",
    "test_dataset = PairDataset(test_en, test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99763d07-e766-47c5-8188-d1f6340f8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f5a425-969d-403c-acb2-272b5c0e83c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_counter = Counter()\n",
    "de_counter = Counter()\n",
    "\n",
    "for line in train_en:\n",
    "    en_counter.update(line)\n",
    "\n",
    "for line in train_de:\n",
    "    de_counter.update(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcda074a-8a8f-49a2-a5b0-604fa7d61550",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sorted_by_freq_tuples = sorted(en_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "en_ordered_dict = OrderedDict(en_sorted_by_freq_tuples)\n",
    "\n",
    "de_sorted_by_freq_tuples = sorted(de_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "de_ordered_dict = OrderedDict(de_sorted_by_freq_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af822cd1-11a2-4cca-a437-c8f23f7dc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "en_vocab = torchtext.vocab.vocab(en_ordered_dict, min_freq = 5, specials=['<pad>', '<unk>', '<sos>', '<eos>'], special_first = True)\n",
    "de_vocab = torchtext.vocab.vocab(de_ordered_dict, min_freq = 5, specials=['<pad>', '<unk>', '<sos>', '<eos>'], special_first = True)\n",
    "\n",
    "en_vocab.set_default_index(1)\n",
    "de_vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcb00ac-2d9a-4b43-9d63-fbdca0e5b289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab([\"<eos>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45a27008-f281-4842-9b40-632f69fa1581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 23, 6, 124, 8]\n",
      "[22, 345, 12, 7]\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab([\"what\", \"are\", \"you\", \"doing\", \"?\"]))\n",
    "print(de_vocab([\"was\", \"machst\", \"du\", \"?\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6ac325-500d-426c-aea0-124dad650fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    en, de, seq_len = [], [], []\n",
    "    for en_token, de_token in batch:\n",
    "        # add <sos> at start and <eos> at end\n",
    "        for lang in [en_token, de_token]:\n",
    "            lang.append('<eos>')\n",
    "            lang.insert(0, '<sos>')\n",
    "        en.append(torch.tensor(en_vocab(en_token), dtype=torch.int64))\n",
    "        de.append(torch.tensor(de_vocab(de_token), dtype=torch.int64))\n",
    "        seq_len.append(len(en_token))\n",
    "\n",
    "    return nn.utils.rnn.pad_sequence(en, batch_first=True), nn.utils.rnn.pad_sequence(de, batch_first=True), torch.tensor(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d359ccf0-0c97-4ed5-bbe8-27d65a39cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2,\n",
    "                              drop_last=True,\n",
    "                              collate_fn=collate)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=2,\n",
    "                              drop_last=False,\n",
    "                              collate_fn=collate)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=2,\n",
    "                              drop_last=False,\n",
    "                              collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a510fffd-d4ed-4f8f-bbc6-b4a6d8787b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size=128, lstm_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=lstm_layers, batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, c_n) = self.lstm(x)\n",
    "        return h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "9491323b-ce70-4782-8e10-c909e87a1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size=128, lstm_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "        self.lstm_cell_list = nn.ModuleList([nn.LSTMCell(input_size=embedding_dim, hidden_size=hidden_size) for i in range(lstm_layers)])\n",
    "        self.fc = nn.Linear(hidden_size, num_embeddings)\n",
    "    \n",
    "    def forward(self, x, h, c):\n",
    "        x = self.embedding(x)\n",
    "        h_n, c_n = torch.zeros_like(h, device=DEVICE), torch.zeros_like(c, device=DEVICE)\n",
    "        for i, lstm_cell in enumerate(self.lstm_cell_list):\n",
    "            (h_n[i], c_n[i]) = lstm_cell(x, (h[i], c[i]))\n",
    "            x = h_n[i].clone()\n",
    "        logits = self.fc(x)\n",
    "        return logits, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "1813cbf7-3950-498e-a6c9-ea31ed38de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, teacher_forcing_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "    \n",
    "    def forward(self, en_sequence, de_sequence):\n",
    "        batch_size, sequence_len, num_de_embeddings = de_sequence.size()[0], de_sequence.size()[1], self.decoder.embedding.num_embeddings\n",
    "        \n",
    "        # minus 1 due to fewer predictions as inputs, we don't predict <sos>\n",
    "        outputs = torch.zeros(batch_size, sequence_len-1, num_de_embeddings, device=DEVICE)\n",
    "\n",
    "        h_n, c_n = self.encoder(en_sequence)\n",
    "        inp = de_sequence[:, 0]\n",
    "        for i in range(1, sequence_len):\n",
    "            logits, h_n, c_n = decoder(inp, h_n, c_n)\n",
    "            outputs[:, i-1] = logits\n",
    "            \n",
    "            force = random.random() < self.teacher_forcing_ratio\n",
    "            if force:\n",
    "                inp = de_sequence[:, i]\n",
    "            else:\n",
    "                inp = logits.argmax(dim=1)\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "b1104bc7-39e7-4043-8025-3ca27e08feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_performance(dataloader, model, criterion):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    num_iterations = 0\n",
    "\n",
    "    # no need to calculate gradients\n",
    "    with torch.inference_mode():\n",
    "        for en_sequence, de_sequence, _ in dataloader:\n",
    "            en_sequence = en_sequence.to(DEVICE)\n",
    "            de_sequence = de_sequence.to(DEVICE)\n",
    "\n",
    "            logits = model(en_sequence, de_sequence)\n",
    "            \n",
    "            # we don't actually predict the <sos> token\n",
    "            labels = de_sequence[:, 1:]\n",
    "            # we need to reshape in order to be able to use these tensors with CrossEntropyLoss\n",
    "            logits = logits.reshape(-1, logits.size()[2])\n",
    "            labels = labels.reshape(-1)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss_sum += loss.cpu().item()\n",
    "            num_iterations+=1\n",
    "\n",
    "    # we return the average loss and the accuracy\n",
    "    return loss_sum/num_iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "8eedecc2-1f89-4aa6-90b9-12f78bf885e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, train_dataloader, val_dataloader, model, optimizer, criterion, scheduler=None):\n",
    "    min_loss = float(\"inf\")\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "        for en_sequence, de_sequence, _ in train_dataloader:\n",
    "            model.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            en_sequence = en_sequence.to(DEVICE)\n",
    "            de_sequence = de_sequence.to(DEVICE)\n",
    "\n",
    "            logits = model(en_sequence, de_sequence)\n",
    "            # we don't actually predict the <sos> token\n",
    "            labels = de_sequence[:, 1:]\n",
    "\n",
    "            # we need to reshape in order to be able to use these tensors with CrossEntropyLoss\n",
    "            logits = logits.reshape(-1, logits.size()[2])\n",
    "            labels = labels.reshape(-1)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_sum += loss.cpu().item()\n",
    "            num_iterations += 1\n",
    "        train_loss=loss_sum/num_iterations\n",
    "        val_loss = track_performance(val_dataloader, model, criterion)\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        print(f'Epoch: {epoch+1:>2}/{num_epochs} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f}')\n",
    "        \n",
    "        if val_loss < min_loss:\n",
    "            print(\"Saving Weights!\")\n",
    "            min_loss = val_loss\n",
    "            torch.save({'encoder_weights': encoder.state_dict(), 'decoder_weights': decoder.state_dict()}, f='../temp/encoder_decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "1f711e59-f852-4ed4-87f7-4149509c04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(num_embeddings=len(en_vocab), embedding_dim=128)\n",
    "decoder = Decoder(num_embeddings=len(de_vocab), embedding_dim=128)\n",
    "seq2seq = EncoderDecoder(encoder, decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "701cb41f-3f2f-4fce-a898-ad0944684f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='min',\n",
    "                                                       patience=2,\n",
    "                                                       verbose=True)\n",
    "\n",
    "num_epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "579c5e78-8445-4a7e-be90-ec3354e7a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/25 | Train Loss: 4.32860 | Val Loss: 3.66370\n",
      "Saving Weights!\n",
      "Epoch:  2/25 | Train Loss: 3.37974 | Val Loss: 3.08622\n",
      "Saving Weights!\n",
      "Epoch:  3/25 | Train Loss: 2.90776 | Val Loss: 2.74637\n",
      "Saving Weights!\n",
      "Epoch:  4/25 | Train Loss: 2.56833 | Val Loss: 2.46569\n",
      "Saving Weights!\n",
      "Epoch:  5/25 | Train Loss: 2.29745 | Val Loss: 2.24828\n",
      "Saving Weights!\n",
      "Epoch:  6/25 | Train Loss: 2.08052 | Val Loss: 2.11049\n",
      "Saving Weights!\n",
      "Epoch:  7/25 | Train Loss: 1.90842 | Val Loss: 1.98390\n",
      "Saving Weights!\n",
      "Epoch:  8/25 | Train Loss: 1.76101 | Val Loss: 1.88213\n",
      "Saving Weights!\n",
      "Epoch:  9/25 | Train Loss: 1.65104 | Val Loss: 1.81226\n",
      "Saving Weights!\n",
      "Epoch: 10/25 | Train Loss: 1.54629 | Val Loss: 1.76212\n",
      "Saving Weights!\n",
      "Epoch: 11/25 | Train Loss: 1.47077 | Val Loss: 1.72599\n",
      "Saving Weights!\n",
      "Epoch: 12/25 | Train Loss: 1.38351 | Val Loss: 1.66042\n",
      "Saving Weights!\n",
      "Epoch: 13/25 | Train Loss: 1.32567 | Val Loss: 1.65936\n",
      "Saving Weights!\n",
      "Epoch: 14/25 | Train Loss: 1.26437 | Val Loss: 1.61570\n",
      "Saving Weights!\n",
      "Epoch: 15/25 | Train Loss: 1.21735 | Val Loss: 1.60283\n",
      "Saving Weights!\n",
      "Epoch: 16/25 | Train Loss: 1.16972 | Val Loss: 1.59491\n",
      "Saving Weights!\n",
      "Epoch: 17/25 | Train Loss: 1.13794 | Val Loss: 1.59152\n",
      "Saving Weights!\n",
      "Epoch: 18/25 | Train Loss: 1.09539 | Val Loss: 1.56621\n",
      "Saving Weights!\n",
      "Epoch: 19/25 | Train Loss: 1.06317 | Val Loss: 1.55894\n",
      "Saving Weights!\n",
      "Epoch: 20/25 | Train Loss: 1.02822 | Val Loss: 1.56154\n",
      "Epoch: 21/25 | Train Loss: 0.98798 | Val Loss: 1.55213\n",
      "Saving Weights!\n",
      "Epoch: 22/25 | Train Loss: 0.96342 | Val Loss: 1.56182\n",
      "Epoch: 23/25 | Train Loss: 0.93896 | Val Loss: 1.57817\n",
      "Epoch 00024: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch: 24/25 | Train Loss: 0.90440 | Val Loss: 1.57018\n",
      "Epoch: 25/25 | Train Loss: 0.79860 | Val Loss: 1.54019\n",
      "Saving Weights!\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs, train_dataloader, val_dataloader, seq2seq, optimizer, criterion, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "6b07358a-1e25-4d56-80f7-c99fc2ba35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('../temp/encoder_decoder.pt')\n",
    "encoder_weights = weights['encoder_weights']\n",
    "decoder_weights = weights['decoder_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "21e58c7b-f938-47a2-beb7-46b2946f546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(encoder_weights)\n",
    "decoder.load_state_dict(decoder_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "dd4dee66-61d6-4d20-9e4e-df4707ab9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, vocab, encoder, decoder):\n",
    "    with torch.inference_mode():\n",
    "        outputs = []\n",
    "        \n",
    "        start_token = [\"<sos>\"]\n",
    "        end_token = [\"<eos>\"]\n",
    "        start_idx = vocab(start_token)[0]\n",
    "        end_idx = vocab(end_token)[0]\n",
    "                \n",
    "        h_n, c_n = encoder(sentence)\n",
    "        inp = torch.tensor([start_idx], device=DEVICE)\n",
    "        while True:\n",
    "            logits, h_n, c_n = decoder(inp, h_n, c_n)\n",
    "            inp = logits.argmax(dim=1)\n",
    "            outputs.append(inp.cpu().item())\n",
    "            if inp.item() == end_idx:\n",
    "                break\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "19010865-7d4f-402e-b4c6-7eb7de5d1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sequence, de_sequence, _ = next(iter(test_dataloader))\n",
    "en_sequence = en_sequence.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "d4938fd1-44e6-4c3d-805a-f750e02f44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'control', 'yourself', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', '<unk>', 'dich', 'am', '<unk>', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['<unk>', 'dich', '!', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'my', 'son', 'is', 'playing', 'in', 'the', 'rain', '.', '<eos>', '<pad>']\n",
      "German Translation: ['<sos>', 'mein', 'sohn', 'spielt', 'im', 'regen', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['mein', 'sohn', 'ist', 'in', 'der', '<unk>', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'whose', 'handwriting', 'is', 'this', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'wessen', 'handschrift', 'ist', 'das', 'hier', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['wessen', '<unk>', 'ist', 'das', '?', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'tom', 'never', 'recovered', 'completely', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'tom', 'hat', 'sich', 'nie', 'ganz', 'erholt', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['tom', 'hat', 'sich', 'nie', 'ganz', 'erholt', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', \"he's\", 'missed', 'the', 'boat', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'der', 'zug', 'ist', 'abgefahren', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['er', 'hat', 'den', 'zug', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'i', 'was', 'really', 'curious', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'ich', 'war', 'sehr', 'neugierig', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['ich', 'war', 'wirklich', 'neugierig', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'tom', '<unk>', 'his', 'mouth', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'tom', '<unk>', 'seinen', 'mund', 'aus', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['tom', '<unk>', 'seinen', 'mund', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', \"i'm\", 'with', 'the', 'fbi', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'ich', 'bin', 'beim', 'fbi', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['ich', 'bin', 'mit', 'fbi', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'i', \"don't\", 'like', 'hot', 'coffee', '.', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'ich', 'mag', 'keinen', 'heißen', 'kaffee', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['ich', 'mag', 'es,', 'nicht', 'nicht', 'nicht', '.', '<eos>']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "English Sentence: ['<sos>', 'will', 'you', 'cook', 'something', 'for', 'me', '?', '<eos>', '<pad>', '<pad>']\n",
      "German Translation: ['<sos>', 'kochst', 'du', 'mir', 'etwas', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Model Translation: ['wirst', 'du', 'etwas', 'was', 'was', '?', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    en_sentence = en_sequence[i].unsqueeze(0)\n",
    "    de_sentence = de_sequence[i].unsqueeze(0)\n",
    "    translation = translate_sentence(en_sentence, en_vocab, encoder, decoder)\n",
    "    print('-'*130)\n",
    "    print(f'English Sentence: {en_vocab.lookup_tokens(en_sentence[0].cpu().tolist())}')\n",
    "    print(f'German Translation: {de_vocab.lookup_tokens(de_sentence[0].cpu().tolist())}')\n",
    "    print(f'Model Translation: {de_vocab.lookup_tokens(translation)}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
