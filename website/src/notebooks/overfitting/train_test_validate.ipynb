{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41a2ec5-a2f7-401a-9d22-8eb6db8acb44",
   "metadata": {},
   "source": [
    "# Train, Test and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53130492-83f5-48a3-94b0-3cef712d02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27bad5d-90ff-4808-8576-4da34e887819",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_dataset = MNIST(root=\"../datasets/\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = MNIST(root=\"../datasets\", train=False, download=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302d188b-f8e0-479d-bd12-2b0d10086834",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = stratify = train_validation_dataset.targets.numpy()\n",
    "train_idxs, val_idxs = train_test_split(\n",
    "                                range(len(train_validation_dataset)),\n",
    "                                stratify=stratify,\n",
    "                                test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d0ef41-67a8-4160-a509-3001a9720904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(train_validation_dataset, train_idxs)\n",
    "val_dataset = Subset(train_validation_dataset, val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346587a6-2bd9-42a1-8675-18c6dbc38829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "DEVICE = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCHS=15\n",
    "BATCH_SIZE=32\n",
    "\n",
    "NUM_LABELS = 10\n",
    "NUM_FEATURES = 28*28\n",
    "HIDDEN_SIZE_1 = 100\n",
    "HIDDEN_SIZE_2 = 50\n",
    "ALPHA = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e111024a-56c6-4046-ad3a-ba2a43631d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True,\n",
    "                              num_workers=4)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              drop_last=False,\n",
    "                              num_workers=4)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              drop_last=False,\n",
    "                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a279f3-6397-4e42-bbbf-f5ce6fe1270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.Linear(NUM_FEATURES, HIDDEN_SIZE_1),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(HIDDEN_SIZE_1, HIDDEN_SIZE_2),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(HIDDEN_SIZE_2, NUM_LABELS),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "            )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.layers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a44c5c97-b35e-476c-b396-985d463d27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(DEVICE)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=ALPHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2385dd8d-ab12-4170-b7f8-69852137cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        num_samples = 0\n",
    "        num_correct = 0\n",
    "        loss_sum = 0\n",
    "        batch_nums = 0\n",
    "\n",
    "        for batch_idx, (features, labels) in enumerate(dataloader):\n",
    "            features = features.view(-1, NUM_FEATURES).to(DEVICE)\n",
    "            labels = labels.to(DEVICE) \n",
    "            # ------ FORWARD PASS --------\n",
    "            # first linear transformation\n",
    "            probs = model(features)\n",
    "            loss = criterion(probs, labels)\n",
    "            batch_nums+=1\n",
    "            loss_sum+=loss.item()\n",
    "\n",
    "            predictions = probs.argmax(dim=1)\n",
    "            num_samples+=len(features)\n",
    "            num_correct+=(labels == predictions).sum().detach().cpu().item()\n",
    "            \n",
    "        accuracy = num_correct / num_samples\n",
    "        avg_loss = loss_sum / batch_nums\n",
    "        return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280072d5-cb55-423e-8397-ee9d08047aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 2.2977633476257324 Val Loss: 2.2910809618361454 Val Acc: 0.11233333333333333\n",
      "Epoch: 2 Train Loss: 2.2828972339630127 Val Loss: 2.2705571955822883 Val Acc: 0.132\n",
      "Epoch: 3 Train Loss: 2.2414958477020264 Val Loss: 2.195727276041153 Val Acc: 0.25983333333333336\n",
      "Epoch: 4 Train Loss: 2.0737404823303223 Val Loss: 1.9009435753873054 Val Acc: 0.3895\n",
      "Epoch: 5 Train Loss: 1.6885849237442017 Val Loss: 1.4897312420479796 Val Acc: 0.5618333333333333\n",
      "Epoch: 6 Train Loss: 1.3490146398544312 Val Loss: 1.2184961542804191 Val Acc: 0.6191666666666666\n",
      "Epoch: 7 Train Loss: 1.1020681858062744 Val Loss: 0.9872404203770009 Val Acc: 0.7121666666666666\n",
      "Epoch: 8 Train Loss: 0.9025840759277344 Val Loss: 0.8186617056105999 Val Acc: 0.7706666666666667\n",
      "Epoch: 9 Train Loss: 0.7653794884681702 Val Loss: 0.7026288542658725 Val Acc: 0.811\n",
      "Epoch: 10 Train Loss: 0.668033242225647 Val Loss: 0.6157765880702658 Val Acc: 0.8293333333333334\n",
      "Epoch: 11 Train Loss: 0.5973191857337952 Val Loss: 0.5537266347636568 Val Acc: 0.8475\n",
      "Epoch: 12 Train Loss: 0.5458375215530396 Val Loss: 0.5083135639891979 Val Acc: 0.8591666666666666\n",
      "Epoch: 13 Train Loss: 0.5070905089378357 Val Loss: 0.47384354749575575 Val Acc: 0.8705\n",
      "Epoch: 14 Train Loss: 0.4774303138256073 Val Loss: 0.44763330267147816 Val Acc: 0.8751666666666666\n",
      "Epoch: 15 Train Loss: 0.4533858895301819 Val Loss: 0.4251669091271593 Val Acc: 0.8813333333333333\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    loss_sum = 0\n",
    "    batch_nums = 0\n",
    "    model.train()\n",
    "    for batch_idx, (features, labels) in enumerate(train_dataloader):\n",
    "        \n",
    "        # reshape features and move to gpu\n",
    "        features = features.view(-1, NUM_FEATURES).to(DEVICE)\n",
    "        # move label to GPU\n",
    "        labels = labels.to(DEVICE)\n",
    "                \n",
    "        # ------ FORWARD PASS --------\n",
    "        # first linear transformation\n",
    "        probs = model(features)\n",
    "\n",
    "        # ------CALCULATE LOSS --------\n",
    "        #cross-entropy loss\n",
    "        loss = criterion(probs, labels)\n",
    "\n",
    "        # ------BACKPROPAGATION --------\n",
    "        loss.backward()\n",
    "\n",
    "        # ------GRADIENT DESCENT --------\n",
    "        optimizer.step()\n",
    "\n",
    "        # ------CLEAR GRADIENTS --------\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # ------TRACK LOSS --------\n",
    "        batch_nums += 1\n",
    "        loss_sum += loss.detach().cpu()\n",
    "    \n",
    "    val_loss, val_accuracy = validate_epoch(model, val_dataloader)\n",
    "    train_loss = loss_sum / batch_nums\n",
    "    print(f'Epoch: {epoch+1} Train Loss: {train_loss} Val Loss: {val_loss} Val Acc: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79de2852-9d04-48a9-bda6-6ec04d5c802a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.43093706736454185 Test Acc: 0.8737\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = validate_epoch(model, test_dataloader)\n",
    "print(f'Test Loss: {test_loss} Test Acc: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
