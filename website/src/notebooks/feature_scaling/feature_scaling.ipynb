{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a126f962-0038-49ff-b139-45e8bebe8314",
   "metadata": {},
   "source": [
    "# Feature Scaling in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998a91f-14f5-4cf2-b720-afe399378408",
   "metadata": {},
   "source": [
    "When you have to apply feature scaling to tabular data, you should use [sklearn](https://scikit-learn.org/). When you are dealing with text, you tokenize text and asign the tokens to one-hot vectors, which puts the tokens on the same scale (this probably does not make sense at the moment). Other type of sequential data, like weather forecasting, can be scaled when you construct your Dataset using the equations we learned in the previous section. When it comes to vision though, PyTorch provides scaling capabilities out of the box in `torchvision.transforms`. Below we are going to cover how we can apply those transforms and we are going to measure the performance of a neural network with and without scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54016013-c812-40dd-b452-d8957c93c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# it is relatively common to call the transforms namespace T\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e274b6d9-7d76-42a0-ace5-28a4e687ecc8",
   "metadata": {},
   "source": [
    "When we create a dataset using the `MNIST` class, we can pass a `transform` argument. As the name suggests we can apply a transform to images. For example if we use the `PILToTensor` transform, we transform the data from an `PIL` format to a tensor format. Often you will need to apply more than one transform. You can concatenate transforms by using `transforms.Compose([transform1,transform2,...])`. While torchvision provides a great number of transforms (see [Torchvision Docs](https://pytorch.org/vision/stable/transforms.html#)), sometimes you might want more control. `transforms.Lambda()` takes a Python lambda function, in which you can process images as you desire. Below we prepare two sets of transforms, that we will both apply to MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990bee53-17ba-4d7e-b8b3-e297e3d9081f",
   "metadata": {},
   "source": [
    "The first set of transforms first transforms the `PIL` image into a `Tensor` and then turns the `Tensor` into a float32 data format. Both steps are important, because PyTorch can only work with tensors and as we intend to use the GPU, float32 is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb3a23e-2be3-4447-87d7-edbf3b744daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.PILToTensor(), \n",
    "                       T.Lambda(lambda tensor : tensor.to(torch.float32))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd8000-a08b-458c-9069-fefae8eee3e5",
   "metadata": {},
   "source": [
    "Those transforms do not include any form of scaling, therefore we expect the training to be relatively slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee096a46-8198-49af-81fb-87cdd068bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = MNIST(root=\"../datasets/\", train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b9430-449b-40b5-bd33-db29b8f99da6",
   "metadata": {},
   "source": [
    "Below we calculate the mean and the standard deviation of the images pixel values. You will notice that there is only one mean and std and not 784 (28*28 pixels). That is because in computer vision the scaling is done per channel and not per pixel. If we were dealing with color images, we would have 3 channes and would therefore require 3 mean and std calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aebc296-a525-4612-8020-e6d7fd3935e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std\n",
    "# we will need this part later for normalization\n",
    "# we divide by 255.0, because the images will be transformed into the 0-1 range automatically\n",
    "mean = (dataset_orig.data.float() / 255.0).mean()\n",
    "std = (dataset_orig.data.float() / 255.0).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b25fab-6b36-4271-a313-7ee52c874429",
   "metadata": {},
   "source": [
    "The second set of transforms first applies `transforms.ToTensor` which turns the `PIL` image into a float32 `Tensor` and scales the image into a 0-1 range. The `transforms.Normalize` transform conducts what we call standardization, by subracting the mean and dividing by the standard deviation. If you have a color image with 3 channels, you need to provide a tuple of mean and std values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24695050-05d1-4128-853c-e8dca1964c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ce96f88-8ce4-4ce5-81a3-0cccd69f5fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_normalized = MNIST(root=\"../datasets/\", train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958ef145-7404-4cfd-9434-ffd2f563c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "DEVICE = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_EPOCHS=20\n",
    "BATCH_SIZE=32\n",
    "\n",
    "#number of hidden units in the first and second hidden layer\n",
    "HIDDEN_SIZE_1 = 100\n",
    "HIDDEN_SIZE_2 = 50\n",
    "NUM_LABELS = 10\n",
    "NUM_FEATURES = 28*28\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a78bde-86a8-4ea1-b59c-25fae0a37212",
   "metadata": {},
   "source": [
    "Based on the datasets we have two dataloaders: `dataloader_orig` without scaling and `dataloader_normalized` with scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a06d816-cd7e-46e2-aac7-75b97e021eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_orig = DataLoader(dataset=dataset_orig, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True,\n",
    "                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ae3c7fb-f0af-4fef-ab54-837334de5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_normalized = DataLoader(dataset=dataset_normalized, \n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True,\n",
    "                              num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727931c-4d06-4e8c-bf2b-834ccea1a69c",
   "metadata": {},
   "source": [
    "The `train` function is the same generic function that we used in the previous PyTorch tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150dcbab-f769-4540-87d1-98691b64bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, criterion, optimizer):\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loss_sum = 0\n",
    "        batch_nums = 0\n",
    "        for batch_idx, (features, labels) in enumerate(dataloader):\n",
    "            # move features and labels to GPU\n",
    "            features = features.view(-1, NUM_FEATURES).to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            # ------ FORWARD PASS --------\n",
    "            probs = model(features)\n",
    "\n",
    "            # ------CALCULATE LOSS --------\n",
    "            loss = criterion(probs, labels)\n",
    "\n",
    "            # ------BACKPROPAGATION --------\n",
    "            loss.backward()\n",
    "\n",
    "            # ------GRADIENT DESCENT --------\n",
    "            optimizer.step()\n",
    "\n",
    "            # ------CLEAR GRADIENTS --------\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # ------TRACK LOSS --------\n",
    "            batch_nums += 1\n",
    "            loss_sum += loss.detach().cpu()\n",
    "\n",
    "        print(f'Epoch: {epoch+1} Loss: {loss_sum / batch_nums}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648e5ed-4677-4236-a6f4-0a930ab6d40d",
   "metadata": {},
   "source": [
    "Same goes for the `model`. There is nothing new. Just a plain vanilla fully connected neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c0e65a-a845-4cd2-9646-0e730767edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.Linear(NUM_FEATURES, HIDDEN_SIZE_1),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(HIDDEN_SIZE_1, HIDDEN_SIZE_2),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(HIDDEN_SIZE_2, NUM_LABELS),\n",
    "            )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        return self.layers(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170d5e7-1adf-4bd2-8a62-ddd6a458c8ff",
   "metadata": {},
   "source": [
    "We first train on the non standardized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752d81d4-4782-48bb-9be7-da125745e431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.9535496234893799\n",
      "Epoch: 2 Loss: 0.7631136178970337\n",
      "Epoch: 3 Loss: 0.7229397296905518\n",
      "Epoch: 4 Loss: 0.7591567635536194\n",
      "Epoch: 5 Loss: 0.7013404965400696\n",
      "Epoch: 6 Loss: 0.7294915318489075\n",
      "Epoch: 7 Loss: 0.6799680590629578\n",
      "Epoch: 8 Loss: 0.6984747648239136\n",
      "Epoch: 9 Loss: 0.6679096221923828\n",
      "Epoch: 10 Loss: 0.6765357851982117\n",
      "Epoch: 11 Loss: 0.657106876373291\n",
      "Epoch: 12 Loss: 0.68031245470047\n",
      "Epoch: 13 Loss: 0.6622717380523682\n",
      "Epoch: 14 Loss: 0.5883834362030029\n",
      "Epoch: 15 Loss: 0.5738955736160278\n",
      "Epoch: 16 Loss: 0.5895755290985107\n",
      "Epoch: 17 Loss: 0.5575388669967651\n",
      "Epoch: 18 Loss: 0.5529080629348755\n",
      "Epoch: 19 Loss: 0.5125207901000977\n",
      "Epoch: 20 Loss: 0.5626105070114136\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=ALPHA)\n",
    "train(dataloader_orig, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8d14f-e264-4cac-9292-55fa787dbd80",
   "metadata": {},
   "source": [
    "We recreate the model with fresh weights and conduct the training on the standardized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecae947f-099e-43e5-a6a6-8f3a71d49fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.809180736541748\n",
      "Epoch: 2 Loss: 0.2534318268299103\n",
      "Epoch: 3 Loss: 0.1727478802204132\n",
      "Epoch: 4 Loss: 0.13004107773303986\n",
      "Epoch: 5 Loss: 0.10386991500854492\n",
      "Epoch: 6 Loss: 0.08564582467079163\n",
      "Epoch: 7 Loss: 0.07254727929830551\n",
      "Epoch: 8 Loss: 0.06272272020578384\n",
      "Epoch: 9 Loss: 0.053299564868211746\n",
      "Epoch: 10 Loss: 0.04657835140824318\n",
      "Epoch: 11 Loss: 0.0407768115401268\n",
      "Epoch: 12 Loss: 0.03545976057648659\n",
      "Epoch: 13 Loss: 0.031082086265087128\n",
      "Epoch: 14 Loss: 0.027383966371417046\n",
      "Epoch: 15 Loss: 0.023808151483535767\n",
      "Epoch: 16 Loss: 0.021104995161294937\n",
      "Epoch: 17 Loss: 0.018414998427033424\n",
      "Epoch: 18 Loss: 0.01610402762889862\n",
      "Epoch: 19 Loss: 0.014298812486231327\n",
      "Epoch: 20 Loss: 0.012513038702309132\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=ALPHA)\n",
    "train(dataloader_normalized, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b387a7a-0567-4d19-927a-e263064361f8",
   "metadata": {},
   "source": [
    "You should notice the huge difference. The loss decreases at a much higher rate with a standardised dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
