{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/World4AI/World4AI/blob/main/website/src/notebooks/convolutional_neural_networks/resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60be13a7-d5e8-46bb-9218-8795fb6ad2d9",
      "metadata": {
        "id": "60be13a7-d5e8-46bb-9218-8795fb6ad2d9"
      },
      "source": [
        "# ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2e0f612c-efa0-4f5c-b173-a84eccbf87f3",
      "metadata": {
        "id": "2e0f612c-efa0-4f5c-b173-a84eccbf87f3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import zipfile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "-HlFg4_y9CuA"
      },
      "id": "-HlFg4_y9CuA",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "YAF6zX6v9Gp2",
        "outputId": "23dc764a-a209-4dba-ac65-547ea659eb98"
      },
      "id": "YAF6zX6v9Gp2",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4568643f-46bc-4513-b2a3-37d1d1ce66b6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4568643f-46bc-4513-b2a3-37d1d1ce66b6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "wxyLLhND9NSV"
      },
      "id": "wxyLLhND9NSV",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -p /content/datasets  -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rENfPNMF9S0u",
        "outputId": "d3ed9ff0-65b2-4fe1-8587-6d7fef1d2569"
      },
      "id": "rENfPNMF9S0u",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content/datasets\n",
            " 97% 790M/812M [00:03<00:00, 314MB/s]\n",
            "100% 812M/812M [00:03<00:00, 271MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = pathlib.Path('/content/datasets')"
      ],
      "metadata": {
        "id": "t47eX4f13azE"
      },
      "id": "t47eX4f13azE",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(root / 'dogs-vs-cats'):\n",
        "  with zipfile.ZipFile(root / 'dogs-vs-cats.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall(root / 'dogs-vs-cats')\n",
        "      \n",
        "  with zipfile.ZipFile(root / 'dogs-vs-cats/train.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall(root / 'dogs-vs-cats')\n"
      ],
      "metadata": {
        "id": "JB-Q5qNe9mAn"
      },
      "id": "JB-Q5qNe9mAn",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_path = root / 'dogs-vs-cats'\n",
        "new_path = root / 'dogs_vs_cats_prepared'"
      ],
      "metadata": {
        "id": "m8XuLRrz9whX"
      },
      "id": "m8XuLRrz9whX",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare list of files\n",
        "file_names = os.listdir(original_path / 'train')\n",
        "test_file_names = file_names[0:5000]\n",
        "val_file_names = file_names[5000:10000]\n",
        "train_file_names = file_names[10000:]"
      ],
      "metadata": {
        "id": "b4TMMIv590if"
      },
      "id": "b4TMMIv590if",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare dirs\n",
        "for directory in [\"train\", \"test\", \"val\"]:\n",
        "    for category in [\"cat\", \"dog\"]:\n",
        "        new_dir = new_path / directory / category\n",
        "        if os.path.exists(new_dir):\n",
        "            shutil.rmtree(new_dir)\n",
        "        os.makedirs(new_dir)"
      ],
      "metadata": {
        "id": "YBnb6vsQ93Pn"
      },
      "id": "YBnb6vsQ93Pn",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_files(old_dir, new_dir, files_list):\n",
        "    for idx, filename in enumerate(files_list):\n",
        "        src = old_dir / filename\n",
        "        if filename.startswith('cat'):\n",
        "            dst = new_dir / 'cat' / filename\n",
        "        elif filename.startswith('dog'):\n",
        "            dst = new_dir / 'dog' / filename\n",
        "        else:\n",
        "            continue\n",
        "            \n",
        "        shutil.copyfile(src=src, dst=dst)"
      ],
      "metadata": {
        "id": "fBJH7WL09-rg"
      },
      "id": "fBJH7WL09-rg",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(old_dir=original_path / \"train\", new_dir=new_path / 'train', files_list=train_file_names)\n",
        "copy_files(old_dir=original_path / \"train\", new_dir=new_path / 'val', files_list=val_file_names)\n",
        "copy_files(old_dir=original_path / \"train\", new_dir=new_path / 'test', files_list=test_file_names)"
      ],
      "metadata": {
        "id": "qk6aEURe-Gmf"
      },
      "id": "qk6aEURe-Gmf",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = new_path"
      ],
      "metadata": {
        "id": "2cKjgU0A-rWh"
      },
      "id": "2cKjgU0A-rWh",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a23f9841-beef-4cc9-8364-986b7efeff6f",
      "metadata": {
        "id": "a23f9841-beef-4cc9-8364-986b7efeff6f"
      },
      "outputs": [],
      "source": [
        "train_transform = T.Compose([T.Resize((256, 256)), \n",
        "                             T.RandomCrop(size=(224, 224)),\n",
        "                             T.ToTensor()])\n",
        "\n",
        "test_transform = T.Compose([T.Resize((224, 224)), \n",
        "                                T.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f1edae3d-4a8a-409b-83dc-1e36cdd4d3d3",
      "metadata": {
        "id": "f1edae3d-4a8a-409b-83dc-1e36cdd4d3d3"
      },
      "outputs": [],
      "source": [
        "train_dataset = ImageFolder(root=root / 'train', transform=train_transform)\n",
        "val_dataset = ImageFolder(root=root / 'val', transform=test_transform)\n",
        "test_dataset = ImageFolder(root=root / 'test', transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fb603d5a-8ec3-45b4-bc55-1aff5a0404ed",
      "metadata": {
        "id": "fb603d5a-8ec3-45b4-bc55-1aff5a0404ed"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "94e2f15c-6934-4a6a-be93-b56c9c267279",
      "metadata": {
        "id": "94e2f15c-6934-4a6a-be93-b56c9c267279"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels,\n",
        "               out_channels):\n",
        "    super().__init__()\n",
        "    \n",
        "    first_stride=1\n",
        "    if out_channels != in_channels:\n",
        "      first_stride=2\n",
        "\n",
        "    self.residual = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, \n",
        "                  out_channels, \n",
        "                  kernel_size=3, \n",
        "                  stride=first_stride, \n",
        "                  padding=1, \n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, \n",
        "                  out_channels, \n",
        "                  kernel_size=3, \n",
        "                  stride=1, \n",
        "                  padding=1, \n",
        "                  bias=False),\n",
        "        nn.BatchNorm2d(out_channels))\n",
        "\n",
        "    self.downsampling = None\n",
        "    if out_channels != in_channels:\n",
        "      self.downsampling = nn.Sequential(\n",
        "          nn.Conv2d(in_channels, \n",
        "                    out_channels,\n",
        "                    kernel_size=1,\n",
        "                    stride=2,\n",
        "                    bias=False),\n",
        "          nn.BatchNorm2d(out_channels))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "    if self.downsampling:\n",
        "      identity = self.downsampling(identity)\n",
        "    \n",
        "    x = self.residual(x)\n",
        "    return torch.relu(x + identity)"
      ],
      "metadata": {
        "id": "DlK8wXnCoXyS"
      },
      "id": "DlK8wXnCoXyS",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = [64, 64, 64,\n",
        "       128, 128, 128, 128,\n",
        "       256, 256, 256, 256, 256, 256, \n",
        "       512, 512, 512]"
      ],
      "metadata": {
        "id": "J8b_IAOWCCVl"
      },
      "id": "J8b_IAOWCCVl",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  \n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.relu1 = nn.ReLU(inplace=True)\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "    self.blocks = self._create_network()\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(cfg[-1], 1))\n",
        "\n",
        "  def _create_network(self):\n",
        "    blocks = []\n",
        "    prev_channels = 64\n",
        "    for channels in self.cfg:\n",
        "      blocks += [BasicBlock(prev_channels, channels)]\n",
        "      prev_channels = channels\n",
        "    return nn.Sequential(*blocks)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.blocks(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "KzuUX7ih-aDa"
      },
      "id": "KzuUX7ih-aDa",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "57fecbb1-a793-4010-af93-580dfb4f9cad",
      "metadata": {
        "id": "57fecbb1-a793-4010-af93-580dfb4f9cad"
      },
      "outputs": [],
      "source": [
        "def track_performance(dataloader, model, criterion):\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    num_samples = 0\n",
        "    num_correct = 0\n",
        "    loss_sum = 0\n",
        "    \n",
        "    # no need to calculate gradients\n",
        "    with torch.inference_mode():\n",
        "        for batch_idx, (features, labels) in enumerate(dataloader):\n",
        "            features = features.to(DEVICE)\n",
        "            labels = labels.to(DEVICE).view(-1, 1).float()\n",
        "            logits = model(features)\n",
        "            probs = torch.sigmoid(logits)\n",
        "                        \n",
        "            predictions = (probs > 0.5).float()\n",
        "            num_correct += (predictions == labels).sum().item()\n",
        "            \n",
        "            loss = criterion(logits, labels)\n",
        "            loss_sum += loss.cpu().item()\n",
        "            num_samples += len(features)\n",
        "    \n",
        "    # we return the average loss and the accuracy\n",
        "    return loss_sum/num_samples, num_correct/num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "46bb261c-d53e-4dce-9383-a59e5b735116",
      "metadata": {
        "id": "46bb261c-d53e-4dce-9383-a59e5b735116"
      },
      "outputs": [],
      "source": [
        "def train(num_epochs, train_dataloader, val_dataloader, model, criterion, optimizer, scheduler=None):\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "    \n",
        "    model.to(DEVICE)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_idx, (features, labels) in enumerate(train_dataloader):\n",
        "            model.train()\n",
        "            features = features.to(DEVICE)\n",
        "            labels = labels.to(DEVICE).view(-1, 1).float()\n",
        "            \n",
        "            # Empty the gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward Pass\n",
        "            logits = model(features)\n",
        "            \n",
        "            # Calculate Loss\n",
        "            loss = criterion(logits, labels)\n",
        "            \n",
        "            # Backward Pass\n",
        "            loss.backward()\n",
        "            \n",
        "            # Gradient Descent\n",
        "            optimizer.step()\n",
        "            \n",
        "        train_loss, train_acc = track_performance(train_dataloader, model, criterion)\n",
        "        val_loss, val_acc = track_performance(val_dataloader, model, criterion)\n",
        "\n",
        "        if scheduler:\n",
        "          scheduler.step(val_loss)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f'Epoch: {epoch+1:>2}/{num_epochs} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}')\n",
        "    return history            \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "eeb60772-d8ce-4806-8747-8e29674a7c56",
      "metadata": {
        "id": "eeb60772-d8ce-4806-8747-8e29674a7c56"
      },
      "outputs": [],
      "source": [
        "model = Model(cfg)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       patience=2,\n",
        "                                                       verbose=True)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1703b920-923d-4914-a97a-0dc4f45c7901",
      "metadata": {
        "id": "1703b920-923d-4914-a97a-0dc4f45c7901",
        "outputId": "2c7c200e-7a7c-4efc-85e6-3012848719eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1/10 | Train Loss: 0.00500 | Val Loss: 0.00511 | Train Acc: 0.633 | Val Acc: 0.641\n",
            "Epoch:  2/10 | Train Loss: 0.00745 | Val Loss: 0.00771 | Train Acc: 0.538 | Val Acc: 0.529\n",
            "Epoch:  3/10 | Train Loss: 0.00434 | Val Loss: 0.00467 | Train Acc: 0.753 | Val Acc: 0.746\n",
            "Epoch:  4/10 | Train Loss: 0.00444 | Val Loss: 0.00463 | Train Acc: 0.714 | Val Acc: 0.709\n",
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch:  5/10 | Train Loss: 0.00270 | Val Loss: 0.00304 | Train Acc: 0.845 | Val Acc: 0.825\n",
            "Epoch:  6/10 | Train Loss: 0.00186 | Val Loss: 0.00219 | Train Acc: 0.899 | Val Acc: 0.876\n",
            "Epoch:  7/10 | Train Loss: 0.00190 | Val Loss: 0.00228 | Train Acc: 0.895 | Val Acc: 0.872\n",
            "Epoch 00008: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch:  8/10 | Train Loss: 0.00172 | Val Loss: 0.00211 | Train Acc: 0.908 | Val Acc: 0.888\n",
            "Epoch:  9/10 | Train Loss: 0.00149 | Val Loss: 0.00196 | Train Acc: 0.920 | Val Acc: 0.896\n",
            "Epoch: 10/10 | Train Loss: 0.00145 | Val Loss: 0.00195 | Train Acc: 0.924 | Val Acc: 0.898\n"
          ]
        }
      ],
      "source": [
        "history = train(10, train_dataloader, val_dataloader, model, criterion, optimizer, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "364cf801-ef43-40f8-b1ac-5a5dd1e46363",
      "metadata": {
        "id": "364cf801-ef43-40f8-b1ac-5a5dd1e46363"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0bc92354-a148-4742-86e7-8b87ef2dadd9",
      "metadata": {
        "id": "0bc92354-a148-4742-86e7-8b87ef2dadd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725bc0bb-131e-48af-df0b-ada21cf3cf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
          ]
        }
      ],
      "source": [
        "model = resnet34(weights='DEFAULT', progress=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "992051b2-9201-499b-b809-1b8d59bb878d",
      "metadata": {
        "id": "992051b2-9201-499b-b809-1b8d59bb878d"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5b6e22c3-65ec-43c0-91b5-f61a0d5a4877",
      "metadata": {
        "id": "5b6e22c3-65ec-43c0-91b5-f61a0d5a4877"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(in_features=512, out_features=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c8e59d40-3604-489d-8f53-a42739be20e4",
      "metadata": {
        "id": "c8e59d40-3604-489d-8f53-a42739be20e4"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       patience=2,\n",
        "                                                       verbose=True)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1877e046-4ce9-4913-bab3-76a6ff2bc46c",
      "metadata": {
        "id": "1877e046-4ce9-4913-bab3-76a6ff2bc46c",
        "outputId": "67a129a5-d777-4585-d153-26c0ad15daec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1/10 | Train Loss: 0.00087 | Val Loss: 0.00101 | Train Acc: 0.972 | Val Acc: 0.968\n",
            "Epoch:  2/10 | Train Loss: 0.00058 | Val Loss: 0.00070 | Train Acc: 0.980 | Val Acc: 0.974\n",
            "Epoch:  3/10 | Train Loss: 0.00046 | Val Loss: 0.00057 | Train Acc: 0.984 | Val Acc: 0.979\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch:  4/10 | Train Loss: 0.00044 | Val Loss: 0.00056 | Train Acc: 0.982 | Val Acc: 0.978\n",
            "Epoch:  5/10 | Train Loss: 0.00042 | Val Loss: 0.00052 | Train Acc: 0.983 | Val Acc: 0.980\n",
            "Epoch:  6/10 | Train Loss: 0.00041 | Val Loss: 0.00051 | Train Acc: 0.984 | Val Acc: 0.980\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch:  7/10 | Train Loss: 0.00041 | Val Loss: 0.00050 | Train Acc: 0.984 | Val Acc: 0.979\n",
            "Epoch:  8/10 | Train Loss: 0.00041 | Val Loss: 0.00050 | Train Acc: 0.984 | Val Acc: 0.979\n",
            "Epoch:  9/10 | Train Loss: 0.00040 | Val Loss: 0.00050 | Train Acc: 0.984 | Val Acc: 0.980\n",
            "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 10/10 | Train Loss: 0.00040 | Val Loss: 0.00052 | Train Acc: 0.985 | Val Acc: 0.980\n"
          ]
        }
      ],
      "source": [
        "history = train(10, train_dataloader, val_dataloader, model, criterion, optimizer, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ezi46SpJDjbl"
      },
      "id": "ezi46SpJDjbl",
      "execution_count": 30,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "ResNet",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}