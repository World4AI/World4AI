{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/World4AI/World4AI/blob/main/website/src/notebooks/convolutional_neural_networks/mobilenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60be13a7-d5e8-46bb-9218-8795fb6ad2d9",
      "metadata": {
        "id": "60be13a7-d5e8-46bb-9218-8795fb6ad2d9"
      },
      "source": [
        "# MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2e0f612c-efa0-4f5c-b173-a84eccbf87f3",
      "metadata": {
        "id": "2e0f612c-efa0-4f5c-b173-a84eccbf87f3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import zipfile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "-HlFg4_y9CuA"
      },
      "id": "-HlFg4_y9CuA",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "YAF6zX6v9Gp2",
        "outputId": "c547f071-a0b3-4e13-9eca-02a5c0267362"
      },
      "id": "YAF6zX6v9Gp2",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c53b548-90ce-42f3-a163-432ac62166dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c53b548-90ce-42f3-a163-432ac62166dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "wxyLLhND9NSV"
      },
      "id": "wxyLLhND9NSV",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -p /content/datasets  -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rENfPNMF9S0u",
        "outputId": "58b7a94d-bb96-4028-961b-4ef880b5a1ea"
      },
      "id": "rENfPNMF9S0u",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content/datasets\n",
            " 98% 796M/812M [00:04<00:00, 158MB/s]\n",
            "100% 812M/812M [00:04<00:00, 178MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root = pathlib.Path('/content/datasets')"
      ],
      "metadata": {
        "id": "t47eX4f13azE"
      },
      "id": "t47eX4f13azE",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(root / 'dogs-vs-cats'):\n",
        "  with zipfile.ZipFile(root / 'dogs-vs-cats.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall(root / 'dogs-vs-cats')\n",
        "      \n",
        "  with zipfile.ZipFile(root / 'dogs-vs-cats/train.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall(root / 'dogs-vs-cats')\n"
      ],
      "metadata": {
        "id": "JB-Q5qNe9mAn"
      },
      "id": "JB-Q5qNe9mAn",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_path = root / 'dogs-vs-cats'\n",
        "new_path = root / 'dogs_vs_cats_prepared'"
      ],
      "metadata": {
        "id": "m8XuLRrz9whX"
      },
      "id": "m8XuLRrz9whX",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare list of files\n",
        "file_names = os.listdir(original_path / 'train')\n",
        "test_file_names = file_names[0:5000]\n",
        "val_file_names = file_names[5000:10000]\n",
        "train_file_names = file_names[10000:]"
      ],
      "metadata": {
        "id": "b4TMMIv590if"
      },
      "id": "b4TMMIv590if",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare dirs\n",
        "for directory in [\"train\", \"test\", \"val\"]:\n",
        "    for category in [\"cat\", \"dog\"]:\n",
        "        new_dir = new_path / directory / category\n",
        "        if os.path.exists(new_dir):\n",
        "            shutil.rmtree(new_dir)\n",
        "        os.makedirs(new_dir)"
      ],
      "metadata": {
        "id": "YBnb6vsQ93Pn"
      },
      "id": "YBnb6vsQ93Pn",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_files(old_dir, new_dir, files_list):\n",
        "    for idx, filename in enumerate(files_list):\n",
        "        src = old_dir / filename\n",
        "        if filename.startswith('cat'):\n",
        "            dst = new_dir / 'cat' / filename\n",
        "        elif filename.startswith('dog'):\n",
        "            dst = new_dir / 'dog' / filename\n",
        "        else:\n",
        "            continue\n",
        "            \n",
        "        shutil.copyfile(src=src, dst=dst)"
      ],
      "metadata": {
        "id": "fBJH7WL09-rg"
      },
      "id": "fBJH7WL09-rg",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(old_dir=original_path / \"train\", new_dir=new_path / 'train', files_list=train_file_names)\n",
        "copy_files(old_dir=original_path / \"train\", new_dir=new_path / 'val', files_list=val_file_names)\n",
        "copy_files(old_dir=original_path / \"train\", new_dir=new_path / 'test', files_list=test_file_names)"
      ],
      "metadata": {
        "id": "qk6aEURe-Gmf"
      },
      "id": "qk6aEURe-Gmf",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = new_path"
      ],
      "metadata": {
        "id": "2cKjgU0A-rWh"
      },
      "id": "2cKjgU0A-rWh",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a23f9841-beef-4cc9-8364-986b7efeff6f",
      "metadata": {
        "id": "a23f9841-beef-4cc9-8364-986b7efeff6f"
      },
      "outputs": [],
      "source": [
        "train_transform = T.Compose([T.Resize((256, 256)), \n",
        "                             T.RandomCrop(size=(224, 224)),\n",
        "                             T.ToTensor()])\n",
        "\n",
        "test_transform = T.Compose([T.Resize((224, 224)), \n",
        "                                T.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f1edae3d-4a8a-409b-83dc-1e36cdd4d3d3",
      "metadata": {
        "id": "f1edae3d-4a8a-409b-83dc-1e36cdd4d3d3"
      },
      "outputs": [],
      "source": [
        "train_dataset = ImageFolder(root=root / 'train', transform=train_transform)\n",
        "val_dataset = ImageFolder(root=root / 'val', transform=test_transform)\n",
        "test_dataset = ImageFolder(root=root / 'test', transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE=128"
      ],
      "metadata": {
        "id": "nRoYCJFyogif"
      },
      "id": "nRoYCJFyogif",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "94e2f15c-6934-4a6a-be93-b56c9c267279",
      "metadata": {
        "id": "94e2f15c-6934-4a6a-be93-b56c9c267279"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=False)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# standard convolution for the first layer\n",
        "def conv_std(in_channels, out_channels, stride):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "      nn.BatchNorm2d(num_features=out_channels),\n",
        "      nn.ReLU(inplace=True)) "
      ],
      "metadata": {
        "id": "DlK8wXnCoXyS"
      },
      "id": "DlK8wXnCoXyS",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# depthwise separable convolution\n",
        "def conv_ds(in_channels, out_channels, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
        "        nn.BatchNorm2d(num_features=in_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "        nn.BatchNorm2d(num_features=out_channels),\n",
        "        nn.ReLU(inplace=True)     \n",
        "      ) "
      ],
      "metadata": {
        "id": "J8b_IAOWCCVl"
      },
      "id": "J8b_IAOWCCVl",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        conv_std(3, 32, 2),\n",
        "        conv_ds(32, 64, 1),\n",
        "        conv_ds(64, 128, 2),\n",
        "        conv_ds(128, 128, 1),\n",
        "        conv_ds(128, 256, 2), \n",
        "        conv_ds(256, 256, 1),        \n",
        "        conv_ds(256, 512, 2), \n",
        "        conv_ds(512, 512, 1),   \n",
        "        conv_ds(512, 512, 1),   \n",
        "        conv_ds(512, 512, 1),   \n",
        "        conv_ds(512, 512, 1),   \n",
        "        conv_ds(512, 512, 1), \n",
        "        conv_ds(512, 1024, 2),  \n",
        "        # bug in the paper?\n",
        "        conv_ds(1024, 1024, 1),  \n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(1024, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "KzuUX7ih-aDa"
      },
      "id": "KzuUX7ih-aDa",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "57fecbb1-a793-4010-af93-580dfb4f9cad",
      "metadata": {
        "id": "57fecbb1-a793-4010-af93-580dfb4f9cad"
      },
      "outputs": [],
      "source": [
        "def track_performance(dataloader, model, criterion):\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "    num_samples = 0\n",
        "    num_correct = 0\n",
        "    loss_sum = 0\n",
        "    \n",
        "    # no need to calculate gradients\n",
        "    with torch.inference_mode():\n",
        "        for batch_idx, (features, labels) in enumerate(dataloader):\n",
        "            features = features.to(DEVICE)\n",
        "            labels = labels.to(DEVICE).view(-1, 1).float()\n",
        "            logits = model(features)\n",
        "            probs = torch.sigmoid(logits)\n",
        "                        \n",
        "            predictions = (probs > 0.5).float()\n",
        "            num_correct += (predictions == labels).sum().item()\n",
        "            \n",
        "            loss = criterion(logits, labels)\n",
        "            loss_sum += loss.cpu().item()\n",
        "            num_samples += len(features)\n",
        "    \n",
        "    # we return the average loss and the accuracy\n",
        "    return loss_sum/num_samples, num_correct/num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "46bb261c-d53e-4dce-9383-a59e5b735116",
      "metadata": {
        "id": "46bb261c-d53e-4dce-9383-a59e5b735116"
      },
      "outputs": [],
      "source": [
        "def train(num_epochs, train_dataloader, val_dataloader, model, criterion, optimizer, scheduler=None):\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "    \n",
        "    model.to(DEVICE)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_idx, (features, labels) in enumerate(train_dataloader):\n",
        "            model.train()\n",
        "            features = features.to(DEVICE)\n",
        "            labels = labels.to(DEVICE).view(-1, 1).float()\n",
        "            \n",
        "            # Empty the gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward Pass\n",
        "            logits = model(features)\n",
        "            \n",
        "            # Calculate Loss\n",
        "            loss = criterion(logits, labels)\n",
        "            \n",
        "            # Backward Pass\n",
        "            loss.backward()\n",
        "            \n",
        "            # Gradient Descent\n",
        "            optimizer.step()\n",
        "            \n",
        "        train_loss, train_acc = track_performance(train_dataloader, model, criterion)\n",
        "        val_loss, val_acc = track_performance(val_dataloader, model, criterion)\n",
        "\n",
        "        if scheduler:\n",
        "          scheduler.step(val_loss)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f'Epoch: {epoch+1:>2}/{num_epochs} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}')\n",
        "    return history            \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "eeb60772-d8ce-4806-8747-8e29674a7c56",
      "metadata": {
        "id": "eeb60772-d8ce-4806-8747-8e29674a7c56"
      },
      "outputs": [],
      "source": [
        "model = Model()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       patience=2,\n",
        "                                                       verbose=True)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1703b920-923d-4914-a97a-0dc4f45c7901",
      "metadata": {
        "id": "1703b920-923d-4914-a97a-0dc4f45c7901",
        "outputId": "b9c7f22f-2488-41e1-eea1-5bbaf8c3873f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1/10 | Train Loss: 0.00451 | Val Loss: 0.00478 | Train Acc: 0.700 | Val Acc: 0.694\n",
            "Epoch:  2/10 | Train Loss: 0.00392 | Val Loss: 0.00419 | Train Acc: 0.759 | Val Acc: 0.758\n",
            "Epoch:  3/10 | Train Loss: 0.00375 | Val Loss: 0.00422 | Train Acc: 0.765 | Val Acc: 0.744\n",
            "Epoch:  4/10 | Train Loss: 0.00474 | Val Loss: 0.00502 | Train Acc: 0.735 | Val Acc: 0.715\n",
            "Epoch:  5/10 | Train Loss: 0.00290 | Val Loss: 0.00327 | Train Acc: 0.833 | Val Acc: 0.813\n",
            "Epoch:  6/10 | Train Loss: 0.00267 | Val Loss: 0.00327 | Train Acc: 0.845 | Val Acc: 0.808\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch:  7/10 | Train Loss: 0.00241 | Val Loss: 0.00298 | Train Acc: 0.872 | Val Acc: 0.844\n",
            "Epoch:  8/10 | Train Loss: 0.00168 | Val Loss: 0.00234 | Train Acc: 0.913 | Val Acc: 0.872\n",
            "Epoch:  9/10 | Train Loss: 0.00158 | Val Loss: 0.00221 | Train Acc: 0.917 | Val Acc: 0.883\n",
            "Epoch 00010: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 10/10 | Train Loss: 0.00149 | Val Loss: 0.00219 | Train Acc: 0.922 | Val Acc: 0.885\n"
          ]
        }
      ],
      "source": [
        "history = train(10, train_dataloader, val_dataloader, model, criterion, optimizer, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "364cf801-ef43-40f8-b1ac-5a5dd1e46363",
      "metadata": {
        "id": "364cf801-ef43-40f8-b1ac-5a5dd1e46363"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V2, progress=False)"
      ],
      "metadata": {
        "id": "Eu2k_9zCn4V1"
      },
      "id": "Eu2k_9zCn4V1",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "992051b2-9201-499b-b809-1b8d59bb878d",
      "metadata": {
        "id": "992051b2-9201-499b-b809-1b8d59bb878d"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "5b6e22c3-65ec-43c0-91b5-f61a0d5a4877",
      "metadata": {
        "id": "5b6e22c3-65ec-43c0-91b5-f61a0d5a4877"
      },
      "outputs": [],
      "source": [
        "model.classifier[3] = nn.Linear(in_features=1280, out_features=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "c8e59d40-3604-489d-8f53-a42739be20e4",
      "metadata": {
        "id": "c8e59d40-3604-489d-8f53-a42739be20e4"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       patience=2,\n",
        "                                                       verbose=True)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "1877e046-4ce9-4913-bab3-76a6ff2bc46c",
      "metadata": {
        "id": "1877e046-4ce9-4913-bab3-76a6ff2bc46c",
        "outputId": "00290203-ac64-4f11-f640-fa8556b61457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1/10 | Train Loss: 0.00124 | Val Loss: 0.00136 | Train Acc: 0.970 | Val Acc: 0.967\n",
            "Epoch:  2/10 | Train Loss: 0.00095 | Val Loss: 0.00107 | Train Acc: 0.971 | Val Acc: 0.967\n",
            "Epoch:  3/10 | Train Loss: 0.00075 | Val Loss: 0.00087 | Train Acc: 0.974 | Val Acc: 0.969\n",
            "Epoch 00004: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch:  4/10 | Train Loss: 0.00067 | Val Loss: 0.00077 | Train Acc: 0.973 | Val Acc: 0.971\n",
            "Epoch:  5/10 | Train Loss: 0.00066 | Val Loss: 0.00076 | Train Acc: 0.975 | Val Acc: 0.972\n",
            "Epoch:  6/10 | Train Loss: 0.00066 | Val Loss: 0.00075 | Train Acc: 0.973 | Val Acc: 0.972\n",
            "Epoch 00007: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch:  7/10 | Train Loss: 0.00066 | Val Loss: 0.00075 | Train Acc: 0.973 | Val Acc: 0.972\n",
            "Epoch:  8/10 | Train Loss: 0.00065 | Val Loss: 0.00075 | Train Acc: 0.975 | Val Acc: 0.972\n",
            "Epoch:  9/10 | Train Loss: 0.00066 | Val Loss: 0.00074 | Train Acc: 0.974 | Val Acc: 0.972\n",
            "Epoch 00010: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 10/10 | Train Loss: 0.00066 | Val Loss: 0.00074 | Train Acc: 0.974 | Val Acc: 0.972\n"
          ]
        }
      ],
      "source": [
        "history = train(10, train_dataloader, val_dataloader, model, criterion, optimizer, scheduler)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "MobileNet",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}