{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60be13a7-d5e8-46bb-9218-8795fb6ad2d9",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0f612c-efa0-4f5c-b173-a84eccbf87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23f9841-beef-4cc9-8364-986b7efeff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([T.Resize((256, 256)), \n",
    "                             T.RandomCrop(size=(224, 224)),\n",
    "                             T.ToTensor()])\n",
    "\n",
    "test_transform = T.Compose([T.Resize((224, 224)), \n",
    "                                T.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1edae3d-4a8a-409b-83dc-1e36cdd4d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root=\"../datasets/dogs_vs_cats_prepared/train/\", transform=train_transform)\n",
    "val_dataset = ImageFolder(root=\"../datasets/dogs_vs_cats_prepared/val/\", transform=test_transform)\n",
    "test_dataset = ImageFolder(root=\"../datasets/dogs_vs_cats_prepared/test/\", transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb603d5a-8ec3-45b4-bc55-1aff5a0404ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94e2f15c-6934-4a6a-be93-b56c9c267279",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d3bfc3-aec8-4378-997c-1b935eba120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.LocalResponseNorm(k=2, size=5, alpha=1e-4, beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.LocalResponseNorm(k=2, size=5, alpha=1e-4, beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features):\n",
    "        return self.classifier(self.feature_extractor(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fecbb1-a793-4010-af93-580dfb4f9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_performance(dataloader, model, criterion):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    loss_sum = 0\n",
    "    \n",
    "    # no need to calculate gradients\n",
    "    with torch.inference_mode():\n",
    "        for batch_idx, (features, labels) in enumerate(dataloader):\n",
    "            features = features.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).view(-1, 1).float()\n",
    "            logits = model(features)\n",
    "            probs = torch.sigmoid(logits)\n",
    "                        \n",
    "            predictions = (probs > 0.5).float()\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            loss_sum += loss.cpu().item()\n",
    "            num_samples += len(features)\n",
    "    \n",
    "    # we return the average loss and the accuracy\n",
    "    return loss_sum/num_samples, num_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46bb261c-d53e-4dce-9383-a59e5b735116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, train_dataloader, val_dataloader, model, criterion, optimizer):\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (features, labels) in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            features = features.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).view(-1, 1).float()\n",
    "            \n",
    "            # Empty the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass\n",
    "            logits = model(features)\n",
    "            \n",
    "            # Calculate Loss\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            # Backward Pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient Descent\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss, train_acc = track_performance(train_dataloader, model, criterion)\n",
    "        val_loss, val_acc = track_performance(val_dataloader, model, criterion)\n",
    "        \n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:>2}/{num_epochs} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}')\n",
    "    return history            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb60772-d8ce-4806-8747-8e29674a7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1703b920-923d-4914-a97a-0dc4f45c7901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/10 | Train Loss: 0.00513 | Val Loss: 0.00527 | Train Acc: 0.601 | Val Acc: 0.591\n",
      "Epoch:  2/10 | Train Loss: 0.00492 | Val Loss: 0.00504 | Train Acc: 0.650 | Val Acc: 0.648\n",
      "Epoch:  3/10 | Train Loss: 0.00449 | Val Loss: 0.00460 | Train Acc: 0.700 | Val Acc: 0.697\n",
      "Epoch:  4/10 | Train Loss: 0.00399 | Val Loss: 0.00415 | Train Acc: 0.743 | Val Acc: 0.740\n",
      "Epoch:  5/10 | Train Loss: 0.00315 | Val Loss: 0.00337 | Train Acc: 0.816 | Val Acc: 0.801\n",
      "Epoch:  6/10 | Train Loss: 0.00300 | Val Loss: 0.00335 | Train Acc: 0.823 | Val Acc: 0.802\n",
      "Epoch:  7/10 | Train Loss: 0.00243 | Val Loss: 0.00279 | Train Acc: 0.864 | Val Acc: 0.844\n",
      "Epoch:  8/10 | Train Loss: 0.00209 | Val Loss: 0.00251 | Train Acc: 0.891 | Val Acc: 0.863\n",
      "Epoch:  9/10 | Train Loss: 0.00202 | Val Loss: 0.00240 | Train Acc: 0.895 | Val Acc: 0.871\n",
      "Epoch: 10/10 | Train Loss: 0.00198 | Val Loss: 0.00257 | Train Acc: 0.893 | Val Acc: 0.864\n"
     ]
    }
   ],
   "source": [
    "history = train(10, train_dataloader, val_dataloader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364cf801-ef43-40f8-b1ac-5a5dd1e46363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet, AlexNet_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bc92354-a148-4742-86e7-8b87ef2dadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1, progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08623e90-693c-44d7-8570-158898e3837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "992051b2-9201-499b-b809-1b8d59bb878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bf7ab15-f210-4853-979f-baf304352fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[1].requires_grad = True\n",
    "model.classifier[4].requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b6e22c3-65ec-43c0-91b5-f61a0d5a4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9874366d-f003-445e-a5a4-8309dbb90617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8e59d40-3604-489d-8f53-a42739be20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1877e046-4ce9-4913-bab3-76a6ff2bc46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/10 | Train Loss: 0.00259 | Val Loss: 0.00269 | Train Acc: 0.884 | Val Acc: 0.874\n",
      "Epoch:  2/10 | Train Loss: 0.00211 | Val Loss: 0.00227 | Train Acc: 0.900 | Val Acc: 0.894\n",
      "Epoch:  3/10 | Train Loss: 0.00191 | Val Loss: 0.00211 | Train Acc: 0.906 | Val Acc: 0.897\n",
      "Epoch:  4/10 | Train Loss: 0.00180 | Val Loss: 0.00203 | Train Acc: 0.910 | Val Acc: 0.896\n",
      "Epoch:  5/10 | Train Loss: 0.00171 | Val Loss: 0.00196 | Train Acc: 0.915 | Val Acc: 0.903\n",
      "Epoch:  6/10 | Train Loss: 0.00167 | Val Loss: 0.00193 | Train Acc: 0.915 | Val Acc: 0.903\n",
      "Epoch:  7/10 | Train Loss: 0.00161 | Val Loss: 0.00189 | Train Acc: 0.918 | Val Acc: 0.905\n",
      "Epoch:  8/10 | Train Loss: 0.00158 | Val Loss: 0.00188 | Train Acc: 0.919 | Val Acc: 0.905\n",
      "Epoch:  9/10 | Train Loss: 0.00155 | Val Loss: 0.00182 | Train Acc: 0.923 | Val Acc: 0.910\n",
      "Epoch: 10/10 | Train Loss: 0.00152 | Val Loss: 0.00182 | Train Acc: 0.922 | Val Acc: 0.910\n"
     ]
    }
   ],
   "source": [
    "history = train(10, train_dataloader, val_dataloader, model, criterion, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
