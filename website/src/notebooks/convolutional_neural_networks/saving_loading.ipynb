{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60be13a7-d5e8-46bb-9218-8795fb6ad2d9",
   "metadata": {},
   "source": [
    "# Saving and Loading in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88567a-82a1-4452-bfa8-3126e29ad0ed",
   "metadata": {},
   "source": [
    "We have mentioned previously that we can load models that were pretrained on some other task and utilize those models for transfer learning. But there are many more reasons to save your PyTorch parameters. You might for example need to interrupt the training process and would like continue from your current checkpoint without restarting the whole training process at a later point. Whatever your reasons, it is essential to know what you need to save/load and how you can accomplish that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c925a4-ead2-4940-b5a3-9e376372dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6533f69-b0db-4158-99e3-dcfff6c7e9df",
   "metadata": {},
   "source": [
    "## torch.save() and torch.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f77c8c-192c-48ef-a9f3-4eb70cf442be",
   "metadata": {},
   "source": [
    "We will ease in and save a couple of simple tensors, before we discuss how we can save whole dictionaries of parameters. \n",
    "\n",
    "Leat's assume we have a simple tensor of ones, that we would like to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac41883-9a40-4b46-8fa6-bdaf3325acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(3, 3)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcfa491-d1c6-42c5-9ea8-64910de14f69",
   "metadata": {},
   "source": [
    "PyTorch `torch.save` function to deal with such a task. The function takes two arguments: `obj` which is the object we would like to save and `f`, which in our case is going to be a path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef578cb-a288-4f79-ad59-b39af2a80fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(t, '../temp/t.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f57b87-32d7-4d48-8029-9539343090cf",
   "metadata": {},
   "source": [
    "Essentially the save function uses the python pickle module to serialize an object. We save the object using the `pt` extension. This is a common convention that PyTorch practicioners use and we will use this convention throughout this block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24389186-220c-46a8-8826-bc3d0f4940ad",
   "metadata": {},
   "source": [
    "Similarly we can use the `torch.load()` function to load objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310a67f5-5d82-4a8a-82d0-92e791bd99bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "new_t = torch.load('../temp/t.pt')\n",
    "print(new_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedad861-cf2d-47dd-86d3-cb86eac0dd13",
   "metadata": {},
   "source": [
    "## Saving weights and dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3fbc3-80cc-49f5-a240-d56047f9e732",
   "metadata": {},
   "source": [
    "When we deal with neural networks, the amount of information that we need to save increases. To demonstrate that we will pretrain a convolutional neural network and save all the parameters we need to continue training at a later time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153f16d-c359-45c3-8cdf-5678704eb125",
   "metadata": {},
   "source": [
    "We use the basic convolutional neural network from the last section as our basis, therefore there is nothing new in terms of the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e0f612c-efa0-4f5c-b173-a84eccbf87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1f7a3-661e-47a2-bcf7-7ac12a5e081b",
   "metadata": {},
   "source": [
    "We set some the usual required parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb603d5a-8ec3-45b4-bc55-1aff5a0404ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d1d61-048e-4f64-957a-77bf4fcbc56e",
   "metadata": {},
   "source": [
    "And create the necessary datasets and dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e5465a-2606-4002-9160-c62bed549d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_dataset = MNIST(root=\"../datasets/\", train=True, download=True, transform=T.ToTensor())\n",
    "test_dataset = MNIST(root=\"../datasets/\", train=False, download=False, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ecc25de-7d3b-4beb-94f6-6273484f71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs, val_idxs = train_test_split(\n",
    "                                range(len(train_val_dataset)),\n",
    "                                test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6619cf3-7906-4831-a13a-843db7196eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_val_dataset.targets.numpy()\n",
    "indices = list(range(len(train_val_dataset)))\n",
    "train_idxs, val_idxs = train_test_split(indices,\n",
    "                                              test_size=0.1,\n",
    "                                              stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f73b367a-397e-4ee7-a7cb-39b359901e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(train_val_dataset, train_idxs)\n",
    "val_dataset = Subset(train_val_dataset, val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e2f15c-6934-4a6a-be93-b56c9c267279",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8d3bfc3-aec8-4378-997c-1b935eba120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        \n",
    "        shape = self.conv_layers(torch.zeros(1, 1, 28, 28)).shape\n",
    "        num_features = torch.prod(torch.tensor(shape)).item()\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_features, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "        \n",
    "    def get_features(self, input_features, layer=0):\n",
    "        with torch.inference_mode():\n",
    "            x = input_features\n",
    "            for i in range(layer+1):\n",
    "                x = self.conv_layers[i](x)\n",
    "            return x\n",
    "        \n",
    "    def forward(self, features):\n",
    "        features = self.conv_layers(features)\n",
    "        features = self.fc_layers(features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57fecbb1-a793-4010-af93-580dfb4f9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_performance(dataloader, model, criterion):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "    loss_sum = 0\n",
    "    \n",
    "    # no need to calculate gradients\n",
    "    with torch.inference_mode():\n",
    "        for batch_idx, (features, labels) in enumerate(dataloader):\n",
    "            features = features.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            logits = model(features)\n",
    "            \n",
    "            predictions = logits.max(dim=1)[1]\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            loss_sum += loss.cpu().item()\n",
    "            num_samples += len(features)\n",
    "    \n",
    "    # we return the average loss and the accuracy\n",
    "    return loss_sum/num_samples, num_correct/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46bb261c-d53e-4dce-9383-a59e5b735116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, train_dataloader, val_dataloader, model, criterion, optimizer, scheduler=None):\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "    model.to(DEVICE)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (features, labels) in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            features = features.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            # Empty the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass\n",
    "            logits = model(features)\n",
    "            \n",
    "            # Calculate Loss\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            # Backward Pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient Descent\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_loss, train_acc = track_performance(train_dataloader, model, criterion)\n",
    "        val_loss, val_acc = track_performance(val_dataloader, model, criterion)\n",
    "        \n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    \n",
    "        print(f'Epoch: {epoch+1:>2}/{num_epochs} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} | Train Acc: {train_acc:.3f} | Val Acc: {val_acc:.3f}')\n",
    "        \n",
    "        if scheduler:\n",
    "          scheduler.step(val_loss)\n",
    "    return history            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb60772-d8ce-4806-8747-8e29674a7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       factor=0.1,\n",
    "                                                       mode='max',\n",
    "                                                       patience=3,\n",
    "                                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1703b920-923d-4914-a97a-0dc4f45c7901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/10 | Train Loss: 0.00411 | Val Loss: 0.00421 | Train Acc: 0.959 | Val Acc: 0.954\n",
      "Epoch:  2/10 | Train Loss: 0.00336 | Val Loss: 0.00369 | Train Acc: 0.967 | Val Acc: 0.963\n",
      "Epoch:  3/10 | Train Loss: 0.00466 | Val Loss: 0.00598 | Train Acc: 0.957 | Val Acc: 0.945\n",
      "Epoch:  4/10 | Train Loss: 0.00276 | Val Loss: 0.00364 | Train Acc: 0.974 | Val Acc: 0.967\n",
      "Epoch:  5/10 | Train Loss: 0.00349 | Val Loss: 0.00421 | Train Acc: 0.966 | Val Acc: 0.960\n",
      "Epoch:  6/10 | Train Loss: 0.00343 | Val Loss: 0.00434 | Train Acc: 0.966 | Val Acc: 0.959\n",
      "Epoch:  7/10 | Train Loss: 0.00330 | Val Loss: 0.00429 | Train Acc: 0.969 | Val Acc: 0.961\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:  8/10 | Train Loss: 0.00145 | Val Loss: 0.00254 | Train Acc: 0.985 | Val Acc: 0.976\n",
      "Epoch:  9/10 | Train Loss: 0.00125 | Val Loss: 0.00240 | Train Acc: 0.987 | Val Acc: 0.978\n",
      "Epoch: 10/10 | Train Loss: 0.00120 | Val Loss: 0.00242 | Train Acc: 0.988 | Val Acc: 0.978\n"
     ]
    }
   ],
   "source": [
    "history = train(10, train_dataloader, val_dataloader, model, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a52ea-67d8-4e7d-bb7e-03260dfa4c9f",
   "metadata": {},
   "source": [
    "The model, optimizer and scheduler implement a dictionary called `state_dict`. Given that dictionary, we can reconstruct our objects. The model state_dict for example has to contain the layers and the corresponding weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d67dfaa4-dc79-4c0c-bba9-ea761a248bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_layers.0.weight: torch.Size([16, 1, 2, 2])\n",
      "  conv_layers.0.bias: torch.Size([16])\n",
      "conv_layers.3.weight: torch.Size([32, 16, 2, 2])\n",
      "  conv_layers.3.bias: torch.Size([32])\n",
      "conv_layers.6.weight: torch.Size([64, 32, 2, 2])\n",
      "  conv_layers.6.bias: torch.Size([64])\n",
      "  fc_layers.1.weight: torch.Size([100, 256])\n",
      "    fc_layers.1.bias: torch.Size([100])\n",
      "  fc_layers.3.weight: torch.Size([10, 100])\n",
      "    fc_layers.3.bias: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for key, value in model.state_dict().items():\n",
    "    print(f'{key:>20}: {value.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed4edc-601c-49dc-964c-6b7fa26a5475",
   "metadata": {},
   "source": [
    "All we have to do is to save those dictionaries and restore them at a later point. The `torch.save` function can save dictionaries without any trouble, so that is what we are going to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b159579a-1a86-43c4-845e-02ac1c93673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'weights': model.state_dict(),\n",
    "            'optim': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()},\n",
    "            f='../temp/testparams.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a6016-0db3-4458-bd49-65f59480d2a5",
   "metadata": {},
   "source": [
    "Now let' assume at a later point we would like to load the old state of our model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fea0b0-e72f-459d-aa03-4ac2fb5a7ce8",
   "metadata": {},
   "source": [
    "We load the pt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f3c4176-f5dc-4ba0-a622-7b877616cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load('../temp/testparams.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4322ce-4751-4b5c-aad6-af4185b5f3fb",
   "metadata": {},
   "source": [
    "We get the model state from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "732f1111-5bec-4b2e-918f-e4a0625a2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state = params['weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07925073-f759-44c8-857b-a83d408e4dd0",
   "metadata": {},
   "source": [
    "We create a brand new model with randomized weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2fc5a4c-bcbe-49d4-ad6e-198ecff728cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee737c-3ffc-4e03-9f55-d56c39d2e6f4",
   "metadata": {},
   "source": [
    "And finally we load the state dictionary into the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78e1855e-78c8-488c-bad7-8fe736ba6f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e437cf-2c7d-42cf-883a-8c6445501ad4",
   "metadata": {},
   "source": [
    "The accuracy on the test data is above 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c4da251-8e66-46d9-962e-6198cc329179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0021452212269392474, 0.9786)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_performance(test_dataloader, new_model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7068f7-1b81-4c24-9610-e7b640c5118c",
   "metadata": {},
   "source": [
    "Torchvision provides relatively easy access to pretrained computer vision models, so that you don't have to load the dictionaries yourself, but sooner or later you will have to deal with the process of saving and loading parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
