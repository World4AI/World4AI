{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0606ad8f-ece5-4925-9b7a-9aea0be47129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096063e7-395c-4aff-a6f4-583beb245f87",
   "metadata": {},
   "source": [
    "# Mathematical Operations with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e933863d-8c63-4913-9491-28166779c728",
   "metadata": {},
   "source": [
    "PyTorch, like other frameworks that work with arrays/tensors, is extremely efficient when it comes to matrix operations. These operations are done in parallel and can be transfered to the GPU if you have a cuda compatibale graphics card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201740e5-af72-43f1-b2b4-1daba562b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.ones(size=(2, 2), dtype=torch.float32)\n",
    "B = torch.tensor([[1, 2],[3, 4]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a129d66-715c-40df-8198-3779afdf0814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f63e14d-222b-4e2d-8d97-de8235041703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293ae019-8da2-4132-8d1b-00f6be0d3482",
   "metadata": {},
   "source": [
    "## Common Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb1686-c3ba-428b-9323-5ac19bb7fd2e",
   "metadata": {},
   "source": [
    "The addition operations works as expected: $ \\mathbf{A} + \\mathbf{B} $. Each cell in the matrix is added together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4451b7a-caf3-434b-9c6e-b55e04ceae0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13815b-8064-4547-ad7b-97eb1ef9cd50",
   "metadata": {},
   "source": [
    "The subtraction operations is similarly easy to grasp: $ \\mathbf{A} - \\mathbf{B} $. Each cell in the matrix is subtracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5407d8a3-7363-4a01-9795-cd3caf7e67ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., -1.],\n",
       "        [-2., -3.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A - B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e92053-1aa4-46e2-9c86-8ca845d44d20",
   "metadata": {},
   "source": [
    "The multiplication operator `*` should not be confused with matrix multiplication. When we multiply two matrices, the individual cells in the matrices are multiplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af9d4188-d6ae-4e9f-ab63-1203736db258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33792a9e-4ebf-4f42-8517-12b9516942a5",
   "metadata": {},
   "source": [
    "The same goes for the division operator `\\`. When we apply the operator, individual cells are divided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d553401-67e6-4d52-9cdf-8657649b7bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.5000],\n",
       "        [0.3333, 0.2500]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A / B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b7d87-ba1f-4981-b7d7-f0c8ae4c5431",
   "metadata": {},
   "source": [
    "Additionally to the above operators, PyTorch also provides methods for the same actions: `add()`, `subtract()`, `multiply()`, and `divide()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0fb495-0e63-41c6-9abc-60906ae9880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "tensor([[ 0., -1.],\n",
      "        [-2., -3.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1.0000, 0.5000],\n",
      "        [0.3333, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "print(A.add(B))\n",
    "print(A.subtract(B))\n",
    "print(A.multiply(B))\n",
    "print(A.divide(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e4673-f2c2-46d3-a2fb-88331c91106d",
   "metadata": {},
   "source": [
    "Each of the methods provides methods that change the tensor in place. These methods always end with a `_`: `add_()`, `subtract_()`, `multiply_()`, `divide_()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ce4e1e-3f2f-4620-9797-7d602263d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([[1, 2], [4, 4]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6444d89e-867c-4085-a3b6-28b90aef8024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "test.add_(A)\n",
    "# the test tensor was changed\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ddef56-6940-4972-9182-e50ebb465da3",
   "metadata": {},
   "source": [
    "If we want to apply matrix multiplication $ \\mathbf{A} * \\mathbf{B} $ we use the `mathmul` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7598fa4a-5d9b-4ffa-bb78-1ff4ad743a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 6.],\n",
       "        [4., 6.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.matmul(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ead363e6-a785-48cc-8af5-dce16ab2ddce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [7., 7.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.matmul(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fcba46d-3849-4a43-8346-cb66828aa174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 6.],\n",
       "        [4., 6.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5554d-9a80-440c-81da-c723be1e9d85",
   "metadata": {},
   "source": [
    "Alternatively we can use `@` as a convenient way to use matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5219103e-2644-43dc-865c-370fe4a6788f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 6.],\n",
       "        [4., 6.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d215ac-5b23-4872-ab40-2b1b559f39cb",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd77906-70b6-43c5-b972-b037ed90a4c4",
   "metadata": {},
   "source": [
    "Broadcasting is a technique, by which Tensors of different dimensions can still use mathematical operations like addition and subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fa55bad-789e-4b56-9f4f-b742dda0a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.ones(size=(2,), dtype=torch.float32)\n",
    "B = torch.tensor([[1, 2],[3, 4]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d378cfa-a0d7-412a-a7ed-c3792c9f2e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3519c0af-ed70-42d8-b003-9a6f3d6ab3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc763354-1a3b-4074-a165-ab8090eb3a69",
   "metadata": {},
   "source": [
    "The shapes of the two tensors are different, therefore the mathematical operation is not defined. Yet below we see that the addition still works in PyTorch. This is due to broadcasting. PyTorch \"duplicates\" the smaller tensor to match the dimensions of the larger tensor. Broadcasting is an advanced topic, but usually the operations and the mentioned \"duplication\" process works in a very intuitive way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a9d069-9f41-4273-b80a-716490ca551a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [4., 5.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a9c8d-7d0a-4de2-baf3-71f0788f1391",
   "metadata": {},
   "source": [
    "## Tensor Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b4f729-7f85-4736-b276-914cf10afd9c",
   "metadata": {},
   "source": [
    "PyTorch also provides a wide variaty of mathematical functions that can be applied to tensors. For example `exp()`, `log()`, `sin()` and `cos()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f1252a6-054e-4db8-8568-2c0f4eff1b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b03c9306-35e4-40d0-9954-2aa095d25647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.7183,  7.3891],\n",
       "        [20.0855, 54.5981]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4af8a68-417a-4404-a41d-a2a4225989f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6931],\n",
       "        [1.0986, 1.3863]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52daffc6-d71f-401b-8bb1-fec92a147273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5403, -0.4161],\n",
       "        [-0.9900, -0.6536]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.cos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18e113-1715-46f3-a1c2-c034c3a5eca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduction Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ae87f-8130-40e0-a1f6-81c0c056421f",
   "metadata": {},
   "source": [
    "Often in deep learing we need to reduce a matrix through certain operations. For example to find the maximum value in a Tensor or to calculate the average. Often we use the `dim` parameter to reduce the tensor along a specific dimension. Below we can see some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf40ac-2e14-4724-b03f-ce97ae7f712a",
   "metadata": {},
   "source": [
    "Below we look for the index that corresponds to the maximum value in a tensor using the `argmax(dim)` method: $ \\arg\\max A $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c609bda-edbc-49d9-90b9-d19ab8b06611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argmax, argmin return the index\n",
    "A = torch.tensor([[3, 4, 1, 22, 9, 2, 5], [3, 4, 1, 22, 9, 2, 88]])\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "646aa4c7-2090-4a32-9e96-73c34343305a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(A, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24aa6e6-3b84-41b4-a155-475b8f9c966e",
   "metadata": {},
   "source": [
    "Below we look for the maximum value in the Tensor `amax(dim)` method: $ \\max A $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "518586e5-ae8c-4d7d-a76d-d5b34b2f1214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 88])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amax, amin return the max, min value.\n",
    "A = torch.tensor([[3, 4, 1, 22, 9, 2, 5], [3, 4, 1, 22, 9, 2, 88]])\n",
    "torch.amax(A, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d164875-0803-4b4a-9be8-f19a55a48ce6",
   "metadata": {},
   "source": [
    "The `max(dim)` method combines the `max()` and the `argmax()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d95f18b-213e-453d-8de0-d2e0a54d072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([22, 88]),\n",
       "indices=tensor([3, 6]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max, min return both indices and values\n",
    "A = torch.tensor([[3, 4, 1, 22, 9, 2, 5], [3, 4, 1, 22, 9, 2, 88]])\n",
    "torch.max(A, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96718875-1597-46e6-b4d0-d85c030f77c3",
   "metadata": {},
   "source": [
    "PyTorch also provides `sum(dim)`, `mean(dim)` and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f77164fe-929b-4773-9a9f-18a4a6176b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44fbb9e4-b0f8-4fea-85ad-279f968a3d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b3d79ed-299c-43bd-b4c3-661bc45ef18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
