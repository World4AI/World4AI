{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a7dce8-48e3-46fc-9ad1-a4107846fa59",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a724c6-cb1c-4b69-84b2-bcb3644e2e99",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400145a7-9015-46e4-a4c9-5574168ebd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12b67a-6e6a-47b8-9d19-31e5a72a58c8",
   "metadata": {},
   "source": [
    "## Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca01845-3a98-4b1b-97ad-322c0c8c2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(obs_space, model, policy, theta, gamma):\n",
    "    # initialize value function with zeros\n",
    "    value_function = [0 for _ in obs_space]\n",
    "    \n",
    "    while True:\n",
    "        max_delta = 0\n",
    "        value_function_old = value_function.copy()\n",
    "        for obs in obs_space:\n",
    "            action = policy[obs]\n",
    "            v = 0\n",
    "            for prob, next_obs, reward, done in model[obs][action]:\n",
    "                v+=prob*(reward + gamma*value_function_old[next_obs] * (not done))\n",
    "            value_function[obs] = v\n",
    "            \n",
    "            delta = abs(v - value_function_old[obs])\n",
    "            if delta > max_delta:\n",
    "                max_delta = delta\n",
    "        \n",
    "        # break condition\n",
    "        if max_delta < theta:\n",
    "            break\n",
    "    \n",
    "    return value_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19081e3a-d2b5-4cd6-91f4-a2c5cd600ad8",
   "metadata": {},
   "source": [
    "## Policy Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c9cc4-6aa7-4f42-a6dc-1e22962a5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(obs_space, action_space, model, value_function, policy, gamma):\n",
    "    new_policy = policy.copy()\n",
    "    for obs in obs_space:\n",
    "        v_max = 0\n",
    "        argmax = 0\n",
    "        \n",
    "        for action in action_space:\n",
    "            v = 0\n",
    "            for prob, next_obs, reward, done in model[obs][action]:\n",
    "                v+=prob*(reward + gamma*value_function[next_obs] * (not done))\n",
    "            if v > v_max:\n",
    "                v_max = v\n",
    "                argmax = action\n",
    "        new_policy[obs] = argmax\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6dbd18-1d48-4740-86ae-0a026efe82ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Policy Iteration = Evaluation + Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03982af-9826-46fb-817e-84cc4d76c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(obs_space, action_space, model, policy, theta, gamma):\n",
    "    while True:\n",
    "        value_function = policy_evaluation(obs_space, model, policy, theta, gamma)\n",
    "        new_policy = policy_improvement(obs_space, action_space, model, value_function, policy, gamma)\n",
    "        \n",
    "        if policy==new_policy:\n",
    "            return value_function, policy\n",
    "        \n",
    "        policy = new_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55295b2c-1e62-407b-b30f-0188b1cb6b47",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f8008-464c-4cab-bd5d-12275cc7a88d",
   "metadata": {},
   "source": [
    "### Frozen Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f14cbe1-91c7-4ee5-b07a-465cb4914c5c",
   "metadata": {},
   "source": [
    "```\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "class FrozenLakeEnv(gym.envs.toy_text.discrete.DiscreteEnv)\n",
    " |  FrozenLakeEnv(desc=None, map_name='4x4', is_slippery=True)\n",
    " |  \n",
    " |  Winter is here. You and your friends were tossing around a frisbee at the\n",
    " |  park when you made a wild throw that left the frisbee out in the middle of\n",
    " |  the lake. The water is mostly frozen, but there are a few holes where the\n",
    " |  ice has melted. If you step into one of those holes, you'll fall into the\n",
    " |  freezing water. At this time, there's an international frisbee shortage, so\n",
    " |  it's absolutely imperative that you navigate across the lake and retrieve\n",
    " |  the disc. However, the ice is slippery, so you won't always move in the\n",
    " |  direction you intend.\n",
    " |  The surface is described using a grid like the following\n",
    " |  \n",
    " |      SFFF\n",
    " |      FHFH\n",
    " |      FFFH\n",
    " |      HFFG\n",
    " |  \n",
    " |  S : starting point, safe\n",
    " |  F : frozen surface, safe\n",
    " |  H : hole, fall to your doom\n",
    " |  G : goal, where the frisbee is located\n",
    " |  \n",
    " |  The episode ends when you reach the goal or fall in a hole.\n",
    " |  You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0f7c9-3616-40bd-a24d-37b5c896f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you would like to see the full description of the environment uncomment the help function below.\n",
    "# help(env.unwrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6060a-b359-4d30-a569-670f459c365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be009e-5152-43c9-b30d-1416893ca516",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = env.env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23396dbf-8147-4a07-b83b-a699039a8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_space = {obs for obs in range(env.observation_space.n)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4af9495-d40b-451c-808a-718ada12d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = {action for action in range(env.action_space.n)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe98c9-d225-4ebe-9f7b-732228be9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {obs:0 for obs in obs_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7a00e-3049-46c5-953a-5db37981e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_function, policy = policy_iteration(obs_space, action_space, model, policy, theta=0.0001, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c0e01-e134-4a4d-9423-43afb54c7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d31891-8c04-4440-9487-b613efb76e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(value_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
